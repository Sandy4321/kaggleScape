{"nbformat": 4, "cells": [{"cell_type": "markdown", "source": ["<h1>Lower Back Pain Classification Algorithm </h1>\n", "\n", "<p>This dataset contains the anthropometric measurements of the curvature of the spine to support the model towards a more accurate classification.\n", "<br />\n", "Lower back pain affects around 80% of individuals at some point in their life. If this model becomes robust enough, then these measurements may soon become predictive and treatable measures. \n", "<br /> \n", "<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.471.4845&rep=rep1&type=pdf\">This study</a> asserts the validity of the manual goniometer measurements as a valid clinical tool. </p>"], "metadata": {"_uuid": "5f689f6908c2f1162be1758da42eb3e019a82892", "_cell_guid": "858145c6-5614-e2a6-5c1c-e542c44cf7fe"}}, {"cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "import seaborn as sns\n", "\n", "# read data into dataset variable\n", "data = pd.read_csv(\"../input/Dataset_spine.csv\")\n", "\n", "# Drop the unnamed column in place (not a copy of the original)#\n", "data.drop('Unnamed: 13', axis=1, inplace=True)\n", "\n", "# Concatenate the original df with the dummy variables\n", "data = pd.concat([data, pd.get_dummies(data['Class_att'])], axis=1)\n", "\n", "# Drop unnecessary label column in place. \n", "data.drop(['Class_att','Normal'], axis=1, inplace=True)"], "metadata": {"_execution_state": "idle", "_uuid": "c9216d6c22612eca89a726cc57a7863c58f37198", "_cell_guid": "404d4f99-505b-c6ba-0700-d42db0d9ef36", "collapsed": true}, "outputs": [], "execution_count": 2}, {"cell_type": "code", "source": ["data.head()"], "metadata": {"_execution_state": "idle", "_uuid": "aca89c1650278ac4335835590f3231b432a989fe", "_cell_guid": "21ed290e-b96d-fe40-a174-e572a7391358"}, "outputs": [], "execution_count": 3}, {"cell_type": "code", "source": ["import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline"], "metadata": {"_execution_state": "idle", "_uuid": "38bafb8481eed9ddce74a618e40fdffd267b0f01", "_cell_guid": "2771308d-d37a-fe21-5ba7-e2de782e9ee7", "collapsed": true}, "outputs": [], "execution_count": 4}, {"cell_type": "markdown", "source": ["<h1>Exploratory Data Analysis </h1>"], "metadata": {"_uuid": "b80ae877f82a9e578ac4852a1674a858d5c2edf4", "_cell_guid": "779a9779-dd74-18ae-2ca8-e1d135bcfda8"}}, {"cell_type": "code", "source": ["data.columns = ['Pelvic Incidence','Pelvic Tilt','Lumbar Lordosis Angle','Sacral Slope','Pelvic Radius', \n", "                'Spondylolisthesis Degree', 'Pelvic Slope', 'Direct Tilt', 'Thoracic Slope', \n", "                'Cervical Tilt','Sacrum Angle', 'Scoliosis Slope','Outcome']\n", "\n", "corr = data.corr()\n", "\n", "# Set up the matplot figure\n", "f, ax = plt.subplots(figsize=(12,9))\n", "\n", "#Draw the heatmap using seaborn\n", "sns.heatmap(corr, cmap='inferno', annot=True)"], "metadata": {"_execution_state": "idle", "_uuid": "ae6c227c7230978a1900c8ef8edbbd34c2d64f3e", "_cell_guid": "6f8224da-58f4-5d4e-6723-21cf33cbf660"}, "outputs": [], "execution_count": 5}, {"cell_type": "code", "source": ["data.describe()"], "metadata": {"_execution_state": "idle", "_uuid": "f6fa6852b23eb3915f8ed3b9f3b0d27c823bc312", "_cell_guid": "20548bf9-41e2-470d-b774-d9a25ecaee2c"}, "outputs": [], "execution_count": 6}, {"cell_type": "code", "source": ["from pylab import *\n", "import copy\n", "outlier = data[[\"Spondylolisthesis Degree\", \"Outcome\"]]\n", "#print(outlier[outlier >200])\n", "abspond = outlier[outlier[\"Spondylolisthesis Degree\"]>15]\n", "print(\"1= Abnormal, 0=Normal\\n\",abspond[\"Outcome\"].value_counts())"], "metadata": {"_execution_state": "idle", "_uuid": "55c4d84b54de8dc4ca5e79d67f0474ed2c501b3b", "_cell_guid": "8598e4cc-c1d0-4443-be64-293d9cb6172d"}, "outputs": [], "execution_count": 7}, {"cell_type": "code", "source": ["#   Dropping Outlier\n", "data = data.drop(115,0)\n", "colr = copy.copy(data[\"Outcome\"])\n", "co = colr.map({1:0.44, 0:0.83})\n", "\n", "#   Plot scatter\n", "plt.scatter(data[\"Cervical Tilt\"], data[\"Spondylolisthesis Degree\"], c=co, cmap=plt.cm.RdYlGn)\n", "plt.xlabel(\"Cervical Tilt\")\n", "plt.ylabel(\"Spondylolisthesis Degree\")\n", "\n", "colors=[ 'c', 'y', 'm',]\n", "ab =data[\"Outcome\"].where(data[\"Outcome\"]==1)\n", "no = data[\"Outcome\"].where(data[\"Outcome\"]==0)\n", "plt.show()\n", "# UNFINISHED ----- OBJECTIVE: Color visual by Outcome - 0 for green, 1 for Red (example)"], "metadata": {"_uuid": "60f77534ae98f2d363b6193e0ff6084fa936ece3", "_cell_guid": "5f69a8d7-6575-4b87-b42f-ddb6e98b8435"}, "outputs": [], "execution_count": 8}, {"cell_type": "code", "source": ["#   Create the training dataset\n", "training = data.drop('Outcome', axis=1)\n", "testing = data['Outcome']"], "metadata": {"_execution_state": "idle", "_uuid": "986451a57b060a176c65d63d6f07055b4276b24e", "_cell_guid": "fcccdf79-d649-8ccb-94c2-4254fcff905c", "collapsed": true}, "outputs": [], "execution_count": 9}, {"cell_type": "code", "source": ["#   Import necessary ML packages\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.metrics import classification_report\n", "\n", "#   Split into training/testing datasets using Train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(training, testing, test_size=0.33, random_state=22, stratify=testing)"], "metadata": {"_execution_state": "idle", "_uuid": "ff09f370383c6916971a586c2e604b9321619191", "_cell_guid": "f2bf6558-1261-438c-b6ce-d53e6de822b7", "collapsed": true}, "outputs": [], "execution_count": 10}, {"cell_type": "markdown", "source": ["<h1> Convert DataFrame Object to a numpy array due to faster computation in modelling</h1>"], "metadata": {"_execution_state": "idle", "_uuid": "dd30e2f500e183126c29f2cd8c2c43f9943dce41", "_cell_guid": "373761ba-c10a-46ba-b139-fb7740547306"}}, {"cell_type": "code", "source": ["import numpy as np\n", "\n", "# convert to numpy.ndarray and dtype=float64 for optimal\n", "array_train = np.asarray(training)\n", "array_test = np.asarray(testing)\n", "print(array_train.shape)\n", "print(array_test.shape)\n", "\n", "#   Convert each pandas DataFrame object into a numpy array object. \n", "array_XTrain, array_XTest, array_ytrain, array_ytest = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)"], "metadata": {"_execution_state": "idle", "_uuid": "3a2c5944d93783afd20e6354dcaab69ed176b715", "_cell_guid": "b747abd2-ec17-de05-149d-37a9ed8e510e"}, "outputs": [], "execution_count": 11}, {"cell_type": "markdown", "source": ["<h1> Employing Support Vector Machine as a Classifier - 85% </h1>"], "metadata": {"_execution_state": "idle", "_uuid": "c2409f6ee8da93a43a9cc10269a49e75ae4b01bb", "_cell_guid": "575740d0-e70b-4617-93ab-c77e7600e034"}}, {"cell_type": "code", "source": ["#    Import Necessary Packages\n", "from sklearn import svm\n", "from sklearn.metrics import accuracy_score\n", "\n", "#   Instantiate the classifier\n", "clf = svm.SVC(kernel='linear')\n", "\n", "#   Fit the model to the training data\n", "clf.fit(array_XTrain, array_ytrain)\n", "\n", "#   Generate a prediction and store it in 'pred'\n", "pred = clf.predict(array_XTest)\n", "\n", "#   Print the accuracy score/percent correct\n", "svmscore = accuracy_score(array_ytest, pred)\n", "print(\"Support Vector Machines are \", svmscore*100, \"accurate\")\n"], "metadata": {"_execution_state": "idle", "_uuid": "2b2726b4581aa64bd23ac269571c712c5dfdc0f5", "_cell_guid": "16dedd0c-65c5-1ab3-0bec-5a9a60a3ca6f"}, "outputs": [], "execution_count": 12}, {"cell_type": "markdown", "source": ["<h1> That's it! </h1>\n", "<p>~85% prediction accuracy with Support Vector Machines!  To increase the accuracy of the model, feature engineering is a suitable solution - as well as creating new variables based on domain knowledge.</p>"], "metadata": {"_uuid": "1697fc38841d9885d8cfe209cae04b8be371acf4", "_cell_guid": "33d3be64-17bc-79fd-b886-f04bbf85325d"}}, {"cell_type": "markdown", "source": ["<h2> Next Steps</h2>\n", "<li> Since we've done no feature engineering or any parameter tuning, there is a lot of room for improvement. </li>\n", "<li>Specifically, an ANN has been shown to acheive a 93% accuracy score when predicting low back pain from this study</li>\n"], "metadata": {"_execution_state": "idle", "_uuid": "e91816a2a4c54c13f9b081ffaa47deb83ee65c1c", "_cell_guid": "9c07b6ad-40d2-0f84-1f1e-89dac46a7cea", "collapsed": true}}, {"cell_type": "code", "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Activation\n", "import keras"], "metadata": {"_uuid": "3385864e7eb303ad65169820cb4c8c52f292f1ef", "_cell_guid": "78fdaf47-26f1-48c0-8fad-dc67339dc435"}, "outputs": [], "execution_count": 13}, {"cell_type": "code", "source": ["print(array_XTrain.shape)\n", "print(array_ytrain.shape)"], "metadata": {"_uuid": "3672e6b66a659c151a2e12da390bd394d49da6c5", "_cell_guid": "589f4fa6-5f3c-46a2-a37f-be6df6d082eb"}, "outputs": [], "execution_count": 14}, {"cell_type": "code", "source": ["#  Define our model\n", "model = Sequential()\n", "model.add(Dense(32, activation='tanh', input_dim=12))\n", "model.add(Dense(10, activation='softmax'))\n", "model.compile(optimizer='rmsprop',\n", "              loss='categorical_crossentropy',\n", "              metrics=['accuracy'])\n", "\n", "one_hot_labels = keras.utils.to_categorical(array_ytrain, num_classes=10)\n", "\n", "history = model.fit(array_XTrain, one_hot_labels,epochs=1000, batch_size=30)\n", "weights = model.layers[0].get_weights()[0]\n", "biases = model.layers[0].get_weights()[1]"], "metadata": {"_uuid": "a36ad6ba7c30da9f491c5be43c987793cdc7bf39", "_cell_guid": "342d4659-a790-4e41-ae80-3d1e73abc634", "_kg_hide-output": true, "scrolled": true}, "outputs": [], "execution_count": 15}, {"cell_type": "code", "source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "plt.plot(history.history['loss'])\n", "plt.xlabel(\"Epochs (Batches)\")\n", "plt.ylabel(\"Loss\")\n", "plt.title(\"Training an Artificial Neural Net\")"], "metadata": {"_uuid": "3f7a9f796d13661181e9e497044babd80c56058d", "_cell_guid": "21125588-477e-4127-a67d-f4a32bda39a9"}, "outputs": [], "execution_count": 16}, {"cell_type": "markdown", "source": ["<h3>A Little Note About Input Shapes</h3>\n", "\n", "The input dimension on the input layer of a Neural Net (NN) seems to always cause me issues. It begins with me thinking that dimensions refer to the length of the input data. Although I still want to confirm, this is a misconception on my part. Input dimension (or shape) refers to the number of fields in the input data. \n", "\n", "\"Fields\", in this case, refers to the variables within the input data. The number of Fields, Features or Dimension should be the value of the input shape. "], "metadata": {"_uuid": "9444996e9fdb54d7996c24ca2ed6ea78a8354413", "_cell_guid": "55a28439-c3f1-4b4e-ba8b-1b1bdeae3b99"}}, {"cell_type": "markdown", "source": ["<p> After we've set up the model's parameters we must choose both a loss function and define the learning rate. An analogy to understand learning rate is to imagine a bowl. To find the lowest (or highest) point of the bowl, you take a small 'leap' from your current position to a random location. \n", "\n", "* If the jump is too large, you risk making too large a step and stepping over the most optimal position. \n", "* If the jump is too small, you risk increasing the computational cost. I believe the standard is to set it to 0.1 as a 'default'. "], "metadata": {"_uuid": "e155b897743573a6e7dd42327e7f061e8c01219b", "_cell_guid": "36870a5a-b964-491c-8cb3-ad5a31ded5f5"}}], "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3", "version": "3.6.3", "nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "_is_fork": false, "_change_revision": 0}, "nbformat_minor": 1}