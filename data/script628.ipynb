{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "adca26eb-84cc-13c3-697e-7e1a0de62df9"
      },
      "source": [
        "Data behind the story\n",
        "---------------------\n",
        "\n",
        "[Be Suspicious Of Online Movie Ratings, Especially Fandango\u2019s][1]\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "`fandango_score_comparison.csv` contains every film that has a Rotten Tomatoes rating, a RT User rating, a Metacritic score, a Metacritic User score, and IMDb score, and at least 30 fan reviews on Fandango. The data from Fandango was pulled on Aug. 24, 2015.\n",
        "\n",
        "  [1]: https://fivethirtyeight.com/features/fandango-movies-ratings/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "34de91c0-c707-f916-c73b-15e29abeda71"
      },
      "source": [
        "Column | Definition\n",
        "-------------------\n",
        "\n",
        "**FILM** | The film in question\n",
        "\n",
        "**RottenTomatoes** | The Rotten Tomatoes Tomatometer score  for the film \n",
        "\n",
        "**RottenTomatoes_User** | The Rotten Tomatoes user score for the film \n",
        "\n",
        "**Metacritic** | The Metacritic critic score for the film\n",
        "\n",
        "**Metacritic_User** | The Metacritic user score for the film\n",
        "\n",
        "**IMDB** | The IMDb user score for the film\n",
        "\n",
        "**Fandango_Stars** | The number of stars the film had on its Fandango movie page\n",
        "\n",
        "**Fandango_Ratingvalue** | The Fandango ratingValue for the film, as pulled from the HTML of each page. This is the actual average score the movie obtained. \n",
        "\n",
        "**RT_norm** | The Rotten Tomatoes Tomatometer score  for the film , normalized to a 0 to 5 point system\n",
        "\n",
        "**RT_user_norm** | The Rotten Tomatoes user score for the film , normalized to a 0 to 5 point system\n",
        "\n",
        "**Metacritic_norm** | The Metacritic critic score for the film, normalized to a 0 to 5 point system\n",
        "\n",
        "**Metacritic_user_nom** | The Metacritic user score for the film, normalized to a 0 to 5 point system\n",
        "\n",
        "**IMDB_norm** | The IMDb user score for the film, normalized to a 0 to 5 point system\n",
        "\n",
        "**RT_norm_round** | The Rotten Tomatoes Tomatometer score  for the film , normalized to a 0 to 5 point system and rounded to the nearest half-star\n",
        "\n",
        "**RT_user_norm_round** | The Rotten Tomatoes user score for the film , normalized to a 0 to 5 point system and rounded to the nearest half-star\n",
        "\n",
        "**Metacritic_norm_round** | The Metacritic critic score for the film, normalized to a 0 to 5 point system and rounded to the nearest half-star\n",
        "\n",
        "**Metacritic_user_norm_round** | The Metacritic user score for the film, normalized to a 0 to 5 point system and rounded to the nearest half-star\n",
        "\n",
        "**IMDB_norm_round** | The IMDb user score for the film, normalized to a 0 to 5 point system and rounded to the nearest half-star\n",
        "\n",
        "**Metacritic_user_vote_count** | The number of user votes the film had on Metacritic\n",
        "\n",
        "**IMDB_user_vote_count** | The number of user votes the film had on IMDb\n",
        "\n",
        "**Fandango_votes** | The number of user votes the film had on Fandango\n",
        "\n",
        "**Fandango_Difference** | The difference between the presented Fandango_Stars and the actual Fandango_Ratingvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "38ec6124-ce9e-f2b7-e5fa-fbf25616186c"
      },
      "source": [
        "# Preamble #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "070d2a5a-611e-3896-5d24-dac64088652d"
      },
      "outputs": [],
      "source": [
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "# from subprocess import check_output\n",
        "# print(check_output([\"ls\", \"../input/data\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "# Basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# File related\n",
        "import zipfile\n",
        "from subprocess import check_output\n",
        "\n",
        "# Machine Learning\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "import tensorflow as tf\n",
        "\n",
        "# Plotting\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.rcParams['axes.labelsize'] = 20\n",
        "plt.rcParams['axes.titlesize'] = 20\n",
        "plt.rcParams['xtick.labelsize'] = 18\n",
        "plt.rcParams['ytick.labelsize'] = 18\n",
        "plt.rcParams['legend.fontsize'] = 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a7d66039-3abb-99e1-cfef-5f0b13118d80"
      },
      "source": [
        "# Read data #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94e4a007-6309-3e29-e31c-bd3e781d4bb5"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('../input/data/fandango.zip','r') as z: z.extractall('.')\n",
        "    \n",
        "print(check_output([\"ls\", \"fandango\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a4bb8779-1b68-91ae-68f0-d40d920f3748"
      },
      "outputs": [],
      "source": [
        "fandango = pd.read_csv('fandango/fandango_score_comparison.csv')\n",
        "fandango.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bdd68530-6f41-d64e-6530-d74691ea74fb"
      },
      "outputs": [],
      "source": [
        "# %%% List of films alphabetically sorted %%%\n",
        "\n",
        "films_sorted = sorted(fandango['FILM'])\n",
        "\n",
        "print(films_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bb7e09ea-eccb-7030-77a4-c61c2e3b832b"
      },
      "outputs": [],
      "source": [
        "# Display list of keys (column names)\n",
        "\n",
        "fandango.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bfdc845c-6ab9-17a0-9b31-f18b9ca8d664"
      },
      "outputs": [],
      "source": [
        "# WATCH OUT for the following typo: 'Metacritic_user_nom'\n",
        "\n",
        "# Rename key\n",
        "\n",
        "fandango.rename(columns={'Metacritic_user_nom':'Metacritic_user_norm'}, inplace=True)\n",
        "\n",
        "fandango.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bab94c26-cd7a-8911-3305-81d0183153ab"
      },
      "outputs": [],
      "source": [
        "# Set index\n",
        "fandango.set_index('FILM')\n",
        "\n",
        "# Sort by index\n",
        "fandango.sort_values(by='FILM', ascending=True, inplace=True)\n",
        "\n",
        "# Reset numerical index\n",
        "fandango.reset_index(drop=True, inplace=True)\n",
        "\n",
        "fandango.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a2f041f3-6320-1b42-e93f-30e3667c03e1"
      },
      "source": [
        "# Reviewing FiveThirtyEight's analysis #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9cea37af-06fe-5cb2-55de-cb555a01531b"
      },
      "source": [
        "### [1] Fandango's Lopsided Ratings Curve ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ce017cd0-d374-0c16-d02e-61b167a79fd2"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=3, sharex=True, sharey=True, figsize=(8.,6.))\n",
        "plt.subplots_adjust(hspace=0.2)\n",
        "\n",
        "fandango['Fandango_Stars'].plot.hist(\n",
        "                                alpha=0.5,\n",
        "                                bins=5,\n",
        "                                label='Fandango_Stars',\n",
        "                                ax=axes[0]\n",
        "                                )\n",
        "\n",
        "fandango['IMDB_norm'].plot.hist(\n",
        "                            alpha=0.5,\n",
        "                            bins=10,\n",
        "                            label='IMDB_norm',\n",
        "                            ax=axes[0]\n",
        "                            )\n",
        "\n",
        "axes[0].legend(loc='upper left')\n",
        "axes[0].set_xlabel('Stars')\n",
        "axes[0].set_xlim([0.,5.])\n",
        "axes[0].set_ylim([0.,60.])\n",
        "\n",
        "fandango['RT_user_norm'].plot.hist(\n",
        "                            alpha=0.5,\n",
        "                            bins=10,\n",
        "                            label='RT_user_norm',\n",
        "                            ax=axes[1]\n",
        "                            )\n",
        "\n",
        "fandango['RT_norm'].plot.hist(\n",
        "                        alpha=0.5,\n",
        "                        bins=10,\n",
        "                        label='RT_norm',\n",
        "                        ax=axes[1]\n",
        "                        )\n",
        "\n",
        "axes[1].legend(loc='upper left')\n",
        "axes[1].set_title(' ')\n",
        "\n",
        "fandango['Metacritic_user_norm'].plot.hist(\n",
        "                                    alpha=0.5,\n",
        "                                    bins=10,\n",
        "                                    label='Metacritic_user_norm',\n",
        "                                    ax=axes[2]\n",
        "                                    )\n",
        "\n",
        "fandango['Metacritic_norm'].plot.hist(\n",
        "                                alpha=0.5,\n",
        "                                bins=10,\n",
        "                                label='Metacritic_norm',\n",
        "                                ax=axes[2]\n",
        "                                )\n",
        "\n",
        "axes[2].legend(loc='upper left')\n",
        "axes[2].set_title(' ')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c01b80ec-7803-6a72-30a0-dd2b55451410"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "rankings_lst = ['Fandango_Stars',\n",
        "                'RT_user_norm',\n",
        "                'RT_norm',\n",
        "                'IMDB_norm',\n",
        "                'Metacritic_user_norm',\n",
        "                'Metacritic_norm']\n",
        "\n",
        "fandango[rankings_lst].boxplot(vert=False)\n",
        "\n",
        "axes.set_xlabel('Stars')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "88fd47d7-f338-ad40-2603-e0f888d49323"
      },
      "source": [
        "As we see, from the above box plots, Fandango ('Fandango_Stars') and IMDB ('IMDB_norm', normalized to 5 stars) seems to be biased towards ratings above 3 stars.\n",
        "\n",
        "If you want to know what a **box plot** is, check out a nice graphical representation of the [concept][1].\n",
        "\n",
        "\n",
        "  [1]: https://commons.wikimedia.org/wiki/File:Boxplot_vs_PDF.svg#/media/File:Boxplot_vs_PDF.svg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "147c2f23-8798-bdbc-bf1c-880e4a70d57a"
      },
      "source": [
        "\n",
        "\n",
        "### [2] Fandango's Ratings Are Inflated By Rounding ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "320a4df7-e686-b4f5-4167-f9de5c021885"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "fandango['Fandango_Stars'].plot.hist(\n",
        "                                alpha=0.5,\n",
        "                                bins=5,\n",
        "                                label='Fandango_Stars',\n",
        "                                ax=axes\n",
        "                                )\n",
        "\n",
        "fandango['Fandango_Ratingvalue'].plot.hist(\n",
        "                                    alpha=0.5,\n",
        "                                    bins=10,\n",
        "                                    label='Fandango_Ratingvalue',\n",
        "                                    ax=axes\n",
        "                                    )\n",
        "\n",
        "axes.legend(loc='upper left')\n",
        "axes.set_xlabel('Stars')\n",
        "axes.set_xlim([0.,5.])\n",
        "axes.set_ylim([0.,60.])\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5ff1c38-cec1-053f-f559-372493279b8e"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "fandango[['Fandango_Stars', 'Fandango_Ratingvalue']].boxplot(vert=False)\n",
        "\n",
        "axes.set_xlabel('Stars')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3834dba2-e97a-40d4-0311-74dc16378481"
      },
      "source": [
        "Conclusion: Fandango is not only biased toward greater stars, it overrates due to rounding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1d0e8c39-f32a-842a-8c2a-a8037b1a8c7b"
      },
      "source": [
        "# Going beyond FiveThrityEight analysis #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "65b50f93-3027-5617-8aac-0d500017ca47"
      },
      "source": [
        "### [1] Best movies only ###\n",
        "\n",
        "Restrict the analysis to the best movies only, let us say a Rotten Tomatoes critic rating of 4 stars and beyond."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a3d310a7-ea66-5aeb-6928-d457dc2d505f"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "only_rt_80 = fandango['RT_norm'] >= 4.\n",
        "rankings_lst = ['Fandango_Stars',\n",
        "                'RT_user_norm',\n",
        "                'IMDB_norm',\n",
        "                'Metacritic_user_norm',\n",
        "                'Metacritic_norm']\n",
        "\n",
        "with matplotlib.style.context('fivethirtyeight'):\n",
        "    fandango[rankings_lst].boxplot(vert=False)\n",
        "\n",
        "with matplotlib.style.context('ggplot'):\n",
        "    fandango[only_rt_80][rankings_lst].boxplot(vert=False)\n",
        "\n",
        "axes.set_xlabel('Stars')\n",
        "\n",
        "plt.title('Red boxes: RT best movies only')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "39a3afe9-1f73-942c-7419-abeab7af5571"
      },
      "source": [
        "Answer: Fandango becomes even more biased and also highly skewed to the right (median 4.5). Furthermore, the rating systems Metacritic and IMDB seems to be more compatible than before, concerning their spread."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3a88503e-b14b-d01e-ee6c-ed0c564fbd6d"
      },
      "source": [
        "### [2] Correlation matrix ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9370ae14-216c-0856-9f96-15c5da662255"
      },
      "source": [
        "We are going to compute  **Pearson correlation coefficients** and build a full **correlation matrix**.\n",
        "\n",
        "References: \n",
        "\n",
        " 1. [Pearson correlation coefficient from Wikipedia][1]\n",
        "    \n",
        "   \n",
        " 2. [Correlation Coefficient from Wolfram MathWorld][2]\n",
        "\n",
        "  [1]: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
        "  [2]: http://mathworld.wolfram.com/CorrelationCoefficient.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "141a19a7-1390-559b-9e40-89df7cc21aac"
      },
      "outputs": [],
      "source": [
        "rankings_lst = ['Fandango_Stars',\n",
        "                'RT_user_norm',\n",
        "                'RT_norm',\n",
        "                'IMDB_norm',\n",
        "                'Metacritic_user_norm',\n",
        "                'Metacritic_norm']\n",
        "\n",
        "def plot_heatmap(df):\n",
        "    \n",
        "    import seaborn as sns\n",
        "    \n",
        "    fig, axes = plt.subplots()\n",
        "\n",
        "    sns.heatmap(df, annot=True)\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    \n",
        "plot_heatmap(fandango[rankings_lst].corr(method='pearson'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e7f14e9a-55ca-e9dd-6e93-1595b6d6b5cb"
      },
      "source": [
        "### [3] Correlation matrix for RT best movies only ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c69b0c4a-6c9a-99ac-b743-305c43e4a9d3"
      },
      "outputs": [],
      "source": [
        "plot_heatmap(fandango[only_rt_80][rankings_lst].corr(method='pearson'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2533a2c6-c062-e823-1bdc-74bfeda4e0e8"
      },
      "source": [
        "The correlations decreased, when only considering movies for which RT rating is greater or equal to 4 stars. Furthermore, we have obtained negative correlation (i.e. anticorrelation) between Fandango and Metacritic, although a small number (-0.23).\n",
        "\n",
        "What does it mean? For \"good movies\" (according to RT), the rating systems agree less. Moreover, Fandango became so much biased toward high ratings, that Metacritic is tending to follow the opposite direction (anticorrelated), although very weakly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8db8ba69-ef06-7418-9eb3-29f6e9a16999"
      },
      "source": [
        "### [4] Scatter plots ###\n",
        "\n",
        "Let us take a look into how some pairs of variables correlate visually in scatter plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a005af9a-cf2f-3c24-eb7d-65f87890d8d4"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=4, sharex=True, sharey=True, figsize=(8.,6.))\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "axes[0].scatter(\n",
        "            fandango['RT_norm'],\n",
        "            fandango['RT_user_norm'],\n",
        "            color='black',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[0].scatter(\n",
        "            fandango[only_rt_80]['RT_norm'],\n",
        "            fandango[only_rt_80]['RT_user_norm'],\n",
        "            color='red',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[0].set_ylabel('Stars')\n",
        "axes[0].set_xlim([0.,5.])\n",
        "axes[0].set_ylim([0.,5.5])\n",
        "axes[0].set_title('RT versus RT users')\n",
        "\n",
        "axes[1].scatter(\n",
        "            fandango['RT_norm'],\n",
        "            fandango['Metacritic_norm'],\n",
        "            color='black',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[1].scatter(\n",
        "            fandango[only_rt_80]['RT_norm'],\n",
        "            fandango[only_rt_80]['Metacritic_norm'],\n",
        "            color='red',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[1].set_ylabel('Stars')\n",
        "axes[1].set_title('RT versus Metacritic')\n",
        "\n",
        "axes[2].scatter(\n",
        "            fandango['RT_norm'],\n",
        "            fandango['IMDB_norm'],\n",
        "            color='black',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[2].scatter(\n",
        "            fandango[only_rt_80]['RT_norm'],\n",
        "            fandango[only_rt_80]['IMDB_norm'],\n",
        "            color='red',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[2].set_ylabel('Stars')\n",
        "axes[2].set_title('RT versus IMDB')\n",
        "\n",
        "axes[3].scatter(\n",
        "            fandango['Metacritic_norm'],\n",
        "            fandango['Fandango_Stars'],\n",
        "            color='black',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[3].scatter(\n",
        "            fandango[only_rt_80]['Metacritic_norm'],\n",
        "            fandango[only_rt_80]['Fandango_Stars'],\n",
        "            color='red',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[3].set_ylabel('Stars')\n",
        "axes[3].set_xlabel('Stars')\n",
        "axes[3].set_title('Metacritic versus Fandango')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "32188474-4527-0eb2-90c7-7ac59ebd5bf6"
      },
      "source": [
        "In the scatter plots above, gray colors correspond to the points from the full dataset, and red colors the points for which RT ratings are greater or equal to 4 stars. \n",
        "\n",
        "We notice that the negative correlation outlined in the previous plots is indeed very week, between Metacritic and Fandango, when restricting the dataset to good movies only. An eyeball analysis would  suggest zero correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d383bace-214e-235d-4215-2627e7a26ed1"
      },
      "source": [
        "# Machine learning #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "67a9050c-b0be-58ca-6e69-c954d7a56ccd"
      },
      "source": [
        "Hey! Most of the scatter plots in [4] look pretty linear to me. It would give a great linear regression solution, except for the fact that the sample is pretty small...\n",
        "\n",
        "Let's try it without 'Fandango_Stars'. The features will be\n",
        "\n",
        "'RT_user_norm', 'RT_norm', 'Metacritic_user_norm', 'Metacritic_norm'\n",
        "\n",
        "and the response will be\n",
        "\n",
        "'IMDB_norm'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3fff2a41-dfc7-d2d0-6a8b-ae0d8f682e4c"
      },
      "source": [
        "### [1] Linear regression with `scikit-learn` ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "30faf415-b83c-51db-1fa8-2770870d461d"
      },
      "outputs": [],
      "source": [
        "# create a feature matrix 'X' by selecting two DataFrame columns\n",
        "feature_cols = ['RT_user_norm', 'RT_norm', 'Metacritic_user_norm', 'Metacritic_norm']\n",
        "X = fandango.loc[:, feature_cols]\n",
        "\n",
        "# create a response vector 'y' by selecting a Series\n",
        "y = fandango['IMDB_norm']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=43)\n",
        "# Change 'random_state' value to obtain different final results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bfa40223-ab9c-f7d9-2b26-a3bcb0862eab"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "91bfd61f-71d2-fb79-6d0f-cfd6ed33b155"
      },
      "outputs": [],
      "source": [
        "# Best-fit coefficients of the linear regression\n",
        "reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1440e0e2-5504-48cc-4ffd-e2d179f15a52"
      },
      "outputs": [],
      "source": [
        "# 'intercept' coefficient, i.e. independent coefficient\n",
        "reg.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "01456bc1-3c92-37ce-66aa-f9b0cdedc136"
      },
      "outputs": [],
      "source": [
        "# Use the fitted model to make predictions for the testing set\n",
        "y_pred = reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93452421-61f1-d019-f796-6533a8f465f6"
      },
      "outputs": [],
      "source": [
        "learnt_df = X_test.copy(deep=True)\n",
        "\n",
        "learnt_df.insert(loc=0,\n",
        "                 column='IMDB_norm_predicted',\n",
        "                 value=pd.Series(data=y_pred, index=learnt_df.index)\n",
        "                )\n",
        "\n",
        "learnt_df.insert(loc=0,\n",
        "                 column='IMDB_norm_actual',\n",
        "                 value=y_test\n",
        "                )\n",
        "\n",
        "learnt_df[['IMDB_norm_actual', 'IMDB_norm_predicted']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2b8f45c-4f8d-627c-cf5b-c2d25f1a36f2"
      },
      "outputs": [],
      "source": [
        "# CHECK if predicition column is consistent with best-fit parameters\n",
        "\n",
        "test_pred = sum(reg.coef_ * learnt_df.loc[45, :].values[2:]) + reg.intercept_\n",
        "\n",
        "print('Prediction (index=45): ' + str(test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d22931d-8cd9-925b-fe67-c5274b2f3eed"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=4, sharex=True, sharey=True, figsize=(8.,6.))\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "dot1 = axes[0].scatter(\n",
        "                fandango['Metacritic_norm'],\n",
        "                fandango['IMDB_norm'],\n",
        "                color='blue',\n",
        "                alpha=0.5\n",
        "                )\n",
        "\n",
        "dot2 = axes[0].scatter(\n",
        "                learnt_df['Metacritic_norm'],\n",
        "                learnt_df['IMDB_norm_predicted'],\n",
        "                color='red',\n",
        "                alpha=0.5\n",
        "                )\n",
        "\n",
        "axes[0].set_ylabel('Stars')\n",
        "axes[0].set_xlim([0.,5.])\n",
        "axes[0].set_ylim([0.,5.5])\n",
        "axes[0].set_title('Metacritic versus IMDB')\n",
        "axes[0].legend((dot1, dot2),\n",
        "           ('full dataset', 'predicted'),\n",
        "           scatterpoints=1,\n",
        "           loc='lower right',\n",
        "           ncol=3\n",
        "           )\n",
        "\n",
        "axes[1].scatter(\n",
        "            fandango['Metacritic_user_norm'],\n",
        "            fandango['IMDB_norm'],\n",
        "            color='blue',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[1].scatter(\n",
        "            learnt_df['Metacritic_user_norm'],\n",
        "            learnt_df['IMDB_norm_predicted'],\n",
        "            color='red',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[1].set_ylabel('Stars')\n",
        "axes[1].set_title('Metacritic users versus IMDB')\n",
        "\n",
        "axes[2].scatter(\n",
        "            fandango['RT_norm'],\n",
        "            fandango['IMDB_norm'],\n",
        "            color='blue',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[2].scatter(\n",
        "            learnt_df['RT_norm'],\n",
        "            learnt_df['IMDB_norm_predicted'],\n",
        "            color='red',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[2].set_ylabel('Stars')\n",
        "axes[2].set_title('RT versus IMDB')\n",
        "\n",
        "axes[3].scatter(\n",
        "            fandango['RT_user_norm'],\n",
        "            fandango['IMDB_norm'],\n",
        "            color='blue',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[3].scatter(\n",
        "            learnt_df['RT_user_norm'],\n",
        "            learnt_df['IMDB_norm_predicted'],\n",
        "            color='red',\n",
        "            alpha=0.5\n",
        "            )\n",
        "\n",
        "axes[3].set_ylabel('Stars')\n",
        "axes[3].set_title('RT users versus IMDB')\n",
        "axes[3].set_xlabel('Stars')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9df4642b-049f-ced8-9151-857baf0566b8"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "axes.scatter(y_test, y_pred, color='red', alpha=0.5)\n",
        "axes.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', lw=1)\n",
        "axes.set_xlabel('Actual')\n",
        "axes.set_ylabel('Predicted')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42329e9f-bac8-7f56-a430-f2ffc726635a"
      },
      "outputs": [],
      "source": [
        "# %%% Measuring the quality of the regression %%%\n",
        "\n",
        "# Minimum of chi-squared obtained in the regression\n",
        "min_chi2 = ((y_test - y_pred)**2).values\n",
        "\n",
        "# Number of degrees of freedom for 'len(feature_cols)' parameters\n",
        "n_degrees = len(y_test) - len(feature_cols)\n",
        "\n",
        "def func_p_value(c,n):\n",
        "    \"\"\"\n",
        "    \n",
        "    c : chi-squared value\n",
        "    n : number of degree of freedom (d.o.f.), \n",
        "        i.e. number of points subtracted by number of parameters\n",
        "    \n",
        "    Notice: p=0 is considered the worst possible fit and p=1 is\n",
        "    considered to be the perfect fit. For example,\n",
        "    \n",
        "    In[235]: print(func_p_value(0, 45))\n",
        "    Out[235]: 1.0\n",
        "    \n",
        "    In[236]: print(func_p_value(100, 45))\n",
        "    Out[236]: 4.67686463534e-06   \n",
        "  \n",
        "    \"\"\"\n",
        "    return (1. - stats.chi2.cdf(c, n))\n",
        "\n",
        "# p-value\n",
        "p_value = func_p_value(sum(min_chi2), n_degrees)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "279f1f48-d299-c8c2-2b93-a96e0cff8a87"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "markerline, stemlines, baseline = plt.stem(y_test, min_chi2)\n",
        "plt.setp(markerline, linewidth=1, color='red', alpha=0.5)\n",
        "plt.setp(stemlines, linewidth=1, color='red', alpha=0.5)\n",
        "plt.setp(baseline, linewidth=0, color='gray', alpha=0.5)\n",
        "\n",
        "axes.set_xlabel('Stars')\n",
        "axes.set_ylabel(r'$\\chi^2$ ')\n",
        "axes.set_ylim(ymin=-0.01)\n",
        "\n",
        "axes.set_title(r'$\\chi^2_{\\mathrm{total}} =$' + str(sum(min_chi2)) +\n",
        "               r' ,  d.o.f.$=$' + str(n_degrees) + '\\n'\n",
        "               r'$\\chi^2_{\\mathrm{total}}/\\mathrm{d.o.f.} =$' +\n",
        "               str(sum(min_chi2)/n_degrees) + '\\n'\n",
        "               r'p-value $=$' + str(p_value)\n",
        "               )\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "73502eea-f2e5-749d-f73a-40eaa388ded4"
      },
      "source": [
        "The total minimum of chi-squared obtained in the regression is much lower than the number of degrees of freedom (45). This translates into a p-value approximately equals 1, which is a very good fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "827d9a3c-b4cc-05b4-c23b-b00c5acba04b"
      },
      "source": [
        "### [2] Linear regression with TensorFlow ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5d39d808-f2ae-1615-6223-477f006707b9"
      },
      "source": [
        "Reference: ['Linear Regression in Tensorflow' tutorial][1]\n",
        "\n",
        "\n",
        "  [1]: http://aqibsaeed.github.io/2016-07-07-TensorflowLR/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6b75a7d-7809-0c95-4a9b-bdb63c970f9b"
      },
      "outputs": [],
      "source": [
        "n_dim = len(feature_cols)\n",
        "\n",
        "# Include extra dimension for independent coefficient\n",
        "n_dim += 1\n",
        "\n",
        "P = tf.placeholder(tf.float32,[None,n_dim])\n",
        "q = tf.placeholder(tf.float32,[None,1])\n",
        "T = tf.Variable(tf.ones([n_dim,1]))\n",
        "\n",
        "bias = tf.Variable(tf.constant(1.0, shape = [n_dim]))\n",
        "q_ = tf.add(tf.matmul(P, T),bias)\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(q_ - q))\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "training_step = tf.train.GradientDescentOptimizer(\n",
        "                    learning_rate=learning_rate\n",
        "                    ).minimize(cost)\n",
        "\n",
        "# Include extra column 'independent' for independent coefficient\n",
        "X_train = X_train.assign(\n",
        "            independent = pd.Series([1] * len(y_train),\n",
        "            index=X_train.index)\n",
        "            )\n",
        "\n",
        "X_test = X_test.assign(\n",
        "            independent = pd.Series([1] * len(y_train),\n",
        "            index=X_test.index)\n",
        "            )\n",
        "\n",
        "# Convert panda dataframes to numpy arrays\n",
        "P_train = X_train.as_matrix(columns=None)\n",
        "P_test = X_test.as_matrix(columns=None)\n",
        "\n",
        "q_train = np.array(y_train.values).reshape(-1,1)\n",
        "q_test = np.array(y_test.values).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22377507-9d47-790f-286b-ac09b30d9356"
      },
      "outputs": [],
      "source": [
        "training_epochs = 1000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    cost_history = np.empty(shape=[1], dtype=float)\n",
        "    t_history = np.empty(shape=[n_dim, 1], dtype=float)\n",
        "\n",
        "    for epoch in range(training_epochs):\n",
        "    \n",
        "        sess.run(\n",
        "            training_step,\n",
        "            feed_dict={P: P_train, q: q_train}\n",
        "                )\n",
        "        \n",
        "        cost_history = np.append(\n",
        "            cost_history,\n",
        "            sess.run(cost, feed_dict={P: P_train, q: q_train})\n",
        "        )\n",
        "    \n",
        "        t_history = np.append(\n",
        "            t_history,\n",
        "            sess.run(T, feed_dict={P: P_train, q: q_train}),\n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    q_pred = sess.run(q_, feed_dict={P: P_test})[:, 0]\n",
        "    \n",
        "    mse = tf.reduce_mean(tf.square(q_pred - q_test))\n",
        "    \n",
        "    sess.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4df70b01-7206-a048-be58-938a39304f07"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "plt.plot(range(len(cost_history)), cost_history)\n",
        "\n",
        "axes.set_xlim(xmin=0.95)\n",
        "axes.set_ylim(ymin=1.e-2)\n",
        "\n",
        "axes.set_xscale(\"log\", nonposx='clip')\n",
        "axes.set_yscale(\"log\", nonposy='clip')\n",
        "\n",
        "axes.set_ylabel('Cost')\n",
        "axes.set_xlabel(r'Iterations')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27229b44-b209-c878-b34f-3d44c1bedbdf"
      },
      "outputs": [],
      "source": [
        "# Print again result obtained with scikit-learn\n",
        "\n",
        "print(' --- scikit-learn ---')\n",
        "print(learnt_df[['IMDB_norm_actual', 'IMDB_norm_predicted']].head())\n",
        "\n",
        "# NOW, TensorFlow\n",
        "\n",
        "del learnt_df\n",
        "\n",
        "learnt_df = X_test.copy(deep=True)\n",
        "\n",
        "learnt_df.insert(loc=0,\n",
        "                 column='IMDB_norm_predicted',\n",
        "                 value=pd.Series(data=q_pred, index=learnt_df.index)\n",
        "                )\n",
        "\n",
        "learnt_df.insert(loc=0,\n",
        "                 column='IMDB_norm_actual',\n",
        "                 value=q_test\n",
        "                )\n",
        "\n",
        "print('')\n",
        "print(' --- TensorFlow ---')\n",
        "print(learnt_df[['IMDB_norm_actual', 'IMDB_norm_predicted']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "44b89f22-ad73-9d33-ad29-8d19913ecbbc"
      },
      "source": [
        "`scikit-learn` and `tensorflow` give results that are approximately equal up to the second decimal place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1334ffd-81ac-c05a-db35-5c3ff164386e"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(10.,6.))\n",
        "\n",
        "axes[0].scatter(y_test, y_pred, color='red', alpha=0.5)\n",
        "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', lw=1)\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predicted')\n",
        "axes[0].set_title('scikit-learn')\n",
        "\n",
        "axes[1].scatter(q_test, q_pred, color='blue', alpha=0.5)\n",
        "axes[1].plot([q_test.min(), q_test.max()], [q_test.min(), q_test.max()], '--', lw=1)\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predicted')\n",
        "axes[1].set_title('TensorFlow')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9b41f208-cfb9-36f4-bf69-0023ec68169c"
      },
      "source": [
        "The 'tensorflow' result looks almost identical to the one obtained with `scikit-learn`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d8dba23e-b49c-02ab-8cda-3ed6dd7fa154"
      },
      "source": [
        "### [3] Ridge regression with TensorFlow ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "397f388f-b03b-ff3d-026d-f186dad1ff78"
      },
      "source": [
        "References: \n",
        "\n",
        " 1. [Ridge regression in scikit-learn][1]\n",
        " 2. ['Linear Regression in Tensorflow' tutorial][2]\n",
        " 3. [Lasso and ridge regression in TensorFlow Cookbook][3]\n",
        "\n",
        "\n",
        "  [1]: http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression\n",
        "  [2]: http://aqibsaeed.github.io/2016-07-07-TensorflowLR/\n",
        "  [3]: https://github.com/nfmcclure/tensorflow_cookbook/blob/master/03_Linear_Regression/06_Implementing_Lasso_and_Ridge_Regression/06_lasso_and_ridge_regression.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17150bdb-1997-443b-edd7-905816a4172e"
      },
      "outputs": [],
      "source": [
        "penalty_l2 = tf.reduce_mean(tf.square(T))\n",
        "cost_ridge = tf.add(cost, penalty_l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ec16d6c2-3c6f-3fa0-c546-adc60cce7262"
      },
      "outputs": [],
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    cost_ridge_history = np.empty(shape=[1], dtype=float)\n",
        "    t_ridge_history = np.empty(shape=[n_dim, 1], dtype=float)\n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "\n",
        "        sess.run(\n",
        "            training_step,\n",
        "            feed_dict={P: P_train, q: q_train}\n",
        "        )\n",
        "        \n",
        "        cost_ridge_history = np.append(\n",
        "            cost_ridge_history,\n",
        "            sess.run(cost_ridge, feed_dict={P: P_train, q: q_train})\n",
        "        )\n",
        "        \n",
        "        t_ridge_history = np.append(\n",
        "            t_ridge_history,\n",
        "            sess.run(T, feed_dict={P: P_train, q: q_train}),\n",
        "            axis=1\n",
        "        )\n",
        "    \n",
        "    q_pred = sess.run(q_, feed_dict={P: P_test})[:, 0]\n",
        "    \n",
        "    mse = tf.reduce_mean(tf.square(q_pred - q_test))\n",
        "    \n",
        "    \n",
        "    \n",
        "    sess.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "59dca191-db5b-91e8-6e80-0a98af994736"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots()\n",
        "\n",
        "plt.plot(range(len(cost_history)),\n",
        "         cost_history,\n",
        "         color='blue', alpha=0.5,\n",
        "         label='linear regression'\n",
        "        )\n",
        "\n",
        "plt.plot(range(len(cost_ridge_history)),\n",
        "         cost_ridge_history,\n",
        "         color='red', alpha=0.5,\n",
        "         label='ridge regression'\n",
        "        )\n",
        "\n",
        "axes.set_xlim(xmin=0.95)\n",
        "axes.set_ylim(ymin=1.e-2)\n",
        "\n",
        "axes.set_xscale(\"log\", nonposx='clip')\n",
        "axes.set_yscale(\"log\", nonposy='clip')\n",
        "\n",
        "axes.set_ylabel('Cost')\n",
        "axes.set_xlabel(r'Iterations')\n",
        "\n",
        "axes.legend(loc='upper right')\n",
        "\n",
        "axes.set_title('Learning rate = ' + str(learning_rate))\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "342273e8-aa33-63a4-3148-8ebd775c33fc"
      },
      "source": [
        "The ridge regression converges much faster (less iterations, for the same learning rate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3c1c2e65-d49c-ff69-871a-e0a67caff04e"
      },
      "outputs": [],
      "source": [
        "# Print again result obtained with TensorFlow & linear regression\n",
        "\n",
        "print(' --- TensorFlow - linear regression ---')\n",
        "print(learnt_df[['IMDB_norm_actual', 'IMDB_norm_predicted']].head())\n",
        "\n",
        "# NOW, TensorFlow & ridge regression\n",
        "\n",
        "del learnt_df\n",
        "\n",
        "learnt_df = X_test.copy(deep=True)\n",
        "\n",
        "learnt_df.insert(loc=0,\n",
        "                 column='IMDB_norm_predicted',\n",
        "                 value=pd.Series(data=q_pred, index=learnt_df.index)\n",
        "                )\n",
        "\n",
        "learnt_df.insert(loc=0,\n",
        "                 column='IMDB_norm_actual',\n",
        "                 value=q_test\n",
        "                )\n",
        "\n",
        "print('')\n",
        "print(' --- TensorFlow - ridge regression ---')\n",
        "print(learnt_df[['IMDB_norm_actual', 'IMDB_norm_predicted']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cab4c161-f540-e252-2765-53734ab012a0"
      },
      "source": [
        "Linear and ridge regressions have converged to the same results, in TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ec7ff391-7a0a-f0d3-4165-957cbac5e1f3"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True, figsize=(8.,6.))\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "panels = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "\n",
        "for j in range(len(panels)):\n",
        "  \n",
        "    axes[panels[j]].plot(t_ridge_history[j][1:],\n",
        "                    cost_ridge_history[1:],\n",
        "                    color='red', alpha=0.5,\n",
        "                    label='ridge regression'\n",
        "                   )\n",
        "    \n",
        "    axes[panels[j]].scatter(t_ridge_history[j][-1],\n",
        "                    cost_ridge_history[-1],\n",
        "                    color='black', marker='*',\n",
        "                    s=100, label='last point'\n",
        "                   )\n",
        "        \n",
        "    axes[panels[j]].plot(t_history[j][1:],\n",
        "                    cost_history[1:],\n",
        "                    color='blue', alpha=0.5,\n",
        "                    label='linear regression'\n",
        "                   )\n",
        "        \n",
        "    axes[panels[j]].scatter(t_history[j][-1],\n",
        "                    cost_history[-1],\n",
        "                    color='black', marker='*',\n",
        "                    s=100\n",
        "                   )\n",
        "\n",
        "    axes[panels[j]].set_xlabel(feature_cols[j] + ' coeff.')\n",
        "    axes[panels[j]].set_ylabel('Cost')\n",
        "\n",
        "    # axes[panels[j]].set_yscale(\"log\", nonposx='clip')\n",
        "    \n",
        "axes[0, 1].legend(bbox_to_anchor=(1, 0.5))\n",
        "axes[0, 0].set_ylim([0.01, 0.5])\n",
        "axes[0, 0].set_ylim([-0.1, 0.5])\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "765fdf2d-b880-540b-94a1-8a457b0d238b"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, sharex=True, figsize=(10.,6.))\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "axes[0].plot(t_history[0],\n",
        "          t_history[1],\n",
        "          color='blue', alpha=0.5,\n",
        "          label='linear regression'\n",
        "         )\n",
        "\n",
        "axes[0].plot(t_ridge_history[0],\n",
        "          t_ridge_history[1],\n",
        "          color='red', alpha=0.5,\n",
        "          label='ridge regression'\n",
        "         )\n",
        "\n",
        "axes[0].scatter(t_ridge_history[0][-1],\n",
        "             t_ridge_history[1][-1],\n",
        "             color='black', marker='*',\n",
        "             s=100, zorder=10,\n",
        "             label='last point'\n",
        "             )\n",
        "\n",
        "axes[0].set_xlabel(feature_cols[0] + ' coeff.')\n",
        "axes[0].set_ylabel(feature_cols[1] + ' coeff.')\n",
        "\n",
        "axes[0].set_xscale(\"log\", nonposx='clip')\n",
        "# axes[0].set_yscale(\"log\", nonposy='clip')\n",
        "\n",
        "axes[0].legend(loc='upper left')\n",
        "\n",
        "axes[0].set_title('Optimization trajectories on the parameter space')\n",
        "\n",
        "axes[1].plot(t_history[2],\n",
        "          t_history[3],\n",
        "          color='blue', alpha=0.5\n",
        "          )\n",
        "\n",
        "axes[1].plot(t_ridge_history[2],\n",
        "          t_ridge_history[3],\n",
        "          color='red', alpha=0.5\n",
        "          )\n",
        "\n",
        "axes[1].scatter(t_ridge_history[2][-1],\n",
        "             t_ridge_history[3][-1],\n",
        "             color='black', marker='*',\n",
        "             s=100, zorder=10,\n",
        "             )\n",
        "\n",
        "axes[1].set_xlabel(feature_cols[2] + ' coeff.')\n",
        "axes[1].set_ylabel(feature_cols[3] + ' coeff.')\n",
        "\n",
        "axes[1].set_xscale(\"log\", nonposx='clip')\n",
        "axes[1].set_yscale(\"log\", nonposy='clip')\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7fbc0d6d-cc12-2461-1f45-819c5dc9931d"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10.,6.))\n",
        "\n",
        "axes = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "axes.scatter(xs=np.log10(t_ridge_history[0][4:]),\n",
        "             ys=t_ridge_history[1][4:],\n",
        "             zs=cost_ridge_history[4:],\n",
        "             zdir='z',\n",
        "             s=20, \n",
        "             color='red',\n",
        "             depthshade=True\n",
        "             )\n",
        "\n",
        "axes.set_xlabel('log_10(' + feature_cols[0] + ' coeff.)', labelpad=17)\n",
        "axes.set_ylabel(feature_cols[1] + ' coeff.', labelpad=17)\n",
        "axes.set_zlabel('Cost', labelpad=17, rotation=90)\n",
        "\n",
        "axes.set_title('Optimization trajectory on the cost hypersurface')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c122a2e-ab6d-2da4-d55a-c83f4fdf62c7"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10.,6.))\n",
        "\n",
        "axes = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "axes.scatter(xs=np.log10(t_ridge_history[2][4:]),\n",
        "             ys=np.log10(t_ridge_history[3][4:]),\n",
        "             zs=cost_ridge_history[4:],\n",
        "             zdir='z',\n",
        "             s=20, \n",
        "             color='red',\n",
        "             depthshade=True\n",
        "             )\n",
        "\n",
        "axes.set_xlabel('log_10(' + feature_cols[2] + ' coeff.)', labelpad=17)\n",
        "axes.set_ylabel('log_10(' + feature_cols[3] + ' coeff.)', labelpad=17)\n",
        "axes.set_zlabel('Cost', labelpad=17, rotation=90)\n",
        "\n",
        "axes.set_title('Optimization trajectory on the cost hypersurface')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "plt.close()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}