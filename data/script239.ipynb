{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "596ee98a-a698-593f-c83c-1a89125541d9"
      },
      "source": [
        "# Amazon Reviews Unlocked Mobile Phones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "501e8e53-e306-f41d-8345-64c34b003146"
      },
      "outputs": [],
      "source": [
        "import smtplib\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "sns.set(style='ticks', palette='RdBu')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime \n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "pd.options.display.max_colwidth = 1000\n",
        "from time import gmtime, strftime\n",
        "Time_now = strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
        "import timeit\n",
        "start = timeit.default_timer()\n",
        "pd.options.display.max_rows = 100\n",
        "from wordcloud import WordCloud\n",
        "import sqlite3\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "english_stemmer=nltk.stem.SnowballStemmer('english')\n",
        "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import random\n",
        "import itertools\n",
        "import sys\n",
        "import os\n",
        "import argparse\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import six\n",
        "from abc import ABCMeta\n",
        "from scipy import sparse\n",
        "from scipy.sparse import issparse\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils import check_X_y, check_array\n",
        "from sklearn.utils.extmath import safe_sparse_dot\n",
        "from sklearn.preprocessing import normalize, binarize, LabelBinarizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import RFECV, SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn import svm\n",
        "from scipy.stats import skew\n",
        "from scipy.stats.stats import pearsonr\n",
        "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2bd13abb-05da-8ea1-661d-2f8ff3c9c2da"
      },
      "source": [
        "# Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "adc5da3a-6611-6717-56a0-d1b882e091ba"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('../input/Amazon_Unlocked_Mobile.csv', encoding='utf-8')\n",
        "df = data\n",
        "df.columns = ['ProductName', 'BrandName', 'Price', 'Rating', 'Reviews', 'ReviewVotes']\n",
        "df.head().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d989488c-0abf-babb-d83c-d495463a8cc3"
      },
      "source": [
        "# Describe the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83559453-d4af-9026-ce57-0d041f607c19"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e7c1c298-0421-ff80-c8bf-592a8863a820"
      },
      "outputs": [],
      "source": [
        "data.head(n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5717e12-62a2-827f-f621-b4d09cbd9d16"
      },
      "outputs": [],
      "source": [
        "df['Price'] = df['Price'].fillna(0)\n",
        "df['ReviewVotes'] = df['ReviewVotes'].fillna(0)\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c3ad649e-a26f-b9a9-0bc8-38a17049fb9c"
      },
      "source": [
        "# Categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee039e38-5bc6-deef-fac5-78230c3f0151"
      },
      "outputs": [],
      "source": [
        "categorical_features = (data.select_dtypes(include=['object']).columns.values)\n",
        "categorical_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "633c0205-6c35-84d4-832a-258c93b7fbb9"
      },
      "source": [
        "# Numerical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f9b3d75-5dc6-bb1d-ed54-bf761316ed78"
      },
      "outputs": [],
      "source": [
        "numerical_features = data.select_dtypes(include = ['float64', 'int64']).columns.values\n",
        "numerical_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "af5e7593-8666-c719-b23c-d876a719577d"
      },
      "source": [
        "# How many Brands exist? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "813c8cce-665d-0c9f-8cd9-707506abf053"
      },
      "outputs": [],
      "source": [
        "len(list(set(df['BrandName'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "77fcce73-eb4e-f12d-55c0-c76ccb656843"
      },
      "source": [
        "# How many unique products exist? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "687d3346-0cd0-b284-4bec-fadf52cf4b5a"
      },
      "outputs": [],
      "source": [
        "len(list(set(df['ProductName'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d6a564e8-3a3f-2cfe-fc7e-b2738697cad0"
      },
      "source": [
        "# Pivot tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b8f7ae0-ffd7-3611-37b8-d627a221fd1a"
      },
      "outputs": [],
      "source": [
        "pivot = pd.pivot_table(df,\n",
        "            values = ['Rating', 'ReviewVotes'],\n",
        "            index = ['BrandName'], \n",
        "                       columns= [],\n",
        "                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n",
        "                       margins=True).fillna('')\n",
        "pivot.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3dc166bf-ecf6-f345-5489-c8c537cee654"
      },
      "source": [
        "# Which are the top 10 prominent brands?\n",
        "And how many ratings do they have?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad737f7b-429d-0094-323b-41c58a8f6c0a"
      },
      "outputs": [],
      "source": [
        "pivot = pd.pivot_table(df,\n",
        "            values = ['Rating', 'ReviewVotes'],\n",
        "            index =  ['BrandName'],\n",
        "                       columns= [],\n",
        "                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n",
        "                       margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\n",
        "top_10_brands = pivot.reindex().head(n=11)\n",
        "top_10_brands"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dcb51804-e1e1-f41e-a4a8-e072fafbe6da"
      },
      "source": [
        "# Lets extract data only for top 10 brands. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f97af8df-7c70-2ffd-7e2e-e904d02cd956"
      },
      "outputs": [],
      "source": [
        "top_10_brands = top_10_brands.reset_index()\n",
        "tt_brand = top_10_brands['BrandName']\n",
        "tt_brand2 = tt_brand.reset_index()\n",
        "top_10_brand_list = list(set(tt_brand2['BrandName']))\n",
        "top_10_brand_list.remove('All')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ccc5d58-a7cd-e8bb-60b6-0592f26128ee"
      },
      "outputs": [],
      "source": [
        "top_10_brand_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "771cb91a-c11a-3f06-21ab-9d94807bb69b"
      },
      "outputs": [],
      "source": [
        "df_small=df.loc[df['BrandName'].isin(top_10_brand_list)]\n",
        "pivot = pd.pivot_table(df_small,\n",
        "            values = ['Rating'],\n",
        "            index =  ['BrandName'], \n",
        "                       columns= [],\n",
        "                       aggfunc=[np.mean, np.std], \n",
        "                       margins=True, fill_value=0).sort_values(by=('mean', 'Rating'), ascending=False).fillna('')\n",
        "pivot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5736a091-4c69-238c-d1c0-3365490d26bb"
      },
      "source": [
        "# How do average ratings look like for top 10 brands? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1f2cd2c-1189-44b9-64c5-324155adb1f6"
      },
      "outputs": [],
      "source": [
        "cmap = sns.cubehelix_palette(start = 1.5, rot = 1.5, as_cmap = True)\n",
        "plt.subplots(figsize = (15, 8))\n",
        "sns.heatmap(pivot.T,linewidths=0.2,xticklabels=True, yticklabels=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "aa737749-1b4c-b6b0-3198-a46ca1d4ac0d"
      },
      "source": [
        "# Lets find out their topmost products: For 10 Brands, what are top 10 products?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b587542-6c8f-bb50-d6b2-3aea8d662115"
      },
      "outputs": [],
      "source": [
        "df_small.columns.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5db3b63e-7f65-2327-d647-586b6990fad9"
      },
      "outputs": [],
      "source": [
        "def plot_one_company(company, n=20):\n",
        "    df_one_company = df_small.loc[df_small['BrandName'].isin([company])]\n",
        "    pivot = pd.pivot_table(df_one_company,\n",
        "            values = ['Rating', 'ReviewVotes'],\n",
        "            index =  ['ProductName'],\n",
        "                       columns= [],\n",
        "                       aggfunc=[np.sum, np.mean, np.count_nonzero, np.std], \n",
        "                       margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\n",
        "    top_10_prods = pivot.reindex().head(n=20)\n",
        "    top_10_prods = top_10_prods.reset_index()\n",
        "    tt_prods = top_10_prods['ProductName']\n",
        "    tt_prods2 = tt_prods.reset_index()\n",
        "    top_10_prods_list = list(set(tt_prods2['ProductName']))\n",
        "    #top_30_prod_list\n",
        "\n",
        "    try:\n",
        "        aa= df_one_company[df_one_company['ProductName'].isin(top_10_prods_list)]\n",
        "        g = sns.factorplot(x='ProductName', \n",
        "                           y='Rating',\n",
        "                           data=aa, \n",
        "                           saturation=1, \n",
        "                           kind=\"bar\", \n",
        "                           ci=None, \n",
        "                           aspect=4, \n",
        "                           linewidth=1) \n",
        "        locs, labels = plt.xticks()\n",
        "        plt.setp(labels, rotation=90)\n",
        "    except: \n",
        "        pass\n",
        "        \n",
        "for i in top_10_brand_list:\n",
        "    plot_one_company(i, 20)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "34806248-8c3f-6891-f9f6-97236786f48d"
      },
      "source": [
        "# Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5fb150c2-3b3a-1b24-159c-ec816ae2d4d2"
      },
      "outputs": [],
      "source": [
        "def heat_map(corrs_mat):\n",
        "    sns.set(style=\"white\")\n",
        "    f, ax = plt.subplots(figsize=(10, 10))\n",
        "    mask = np.zeros_like(corrs_mat, dtype=np.bool)\n",
        "    mask[np.triu_indices_from(mask)] = True \n",
        "    # Generate a custom diverging colormap\n",
        "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "    sns.heatmap(corrs_mat, mask=mask, cmap=cmap, ax=ax)\n",
        "\n",
        "variable_correlations = df.corr()\n",
        "#variable_correlations\n",
        "heat_map(variable_correlations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5be89067-57ea-0d56-981e-305b6bcb96c9"
      },
      "outputs": [],
      "source": [
        "df.columns.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "13c161bb-dec8-033e-9c92-e8328fed0647"
      },
      "source": [
        "# How are review votes distributed for different prices and different ratings? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb0c44f3-d775-dfda-b4e8-1db963d6f74a"
      },
      "outputs": [],
      "source": [
        "df_small = df[['BrandName', \n",
        "               'Price', \n",
        "               'Rating', \n",
        "               'ReviewVotes']]\n",
        "sns.pairplot(df_small, size=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "283dc74d-4f79-10f2-9d4f-d802b1ccea4a"
      },
      "source": [
        "# Complex plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c9529eaf-8617-c273-3a0e-8b7aca80db36"
      },
      "outputs": [],
      "source": [
        "#data = df\n",
        "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
        "f, axes = plt.subplots(2, 3, figsize=(20,20))\n",
        "sns.despine(left=True)\n",
        "sns.distplot(df['Price'],            color=\"b\", ax=axes[0, 0])\n",
        "sns.distplot(df['Rating'],           color=\"r\", ax=axes[0, 1])\n",
        "sns.distplot(df['ReviewVotes'],      color=\"g\", ax=axes[0, 2])\n",
        "sns.distplot(df['Price'],            kde=False, color=\"b\", ax=axes[1, 0])\n",
        "sns.distplot(df['Rating'],           kde=False, color=\"r\", ax=axes[1, 1])\n",
        "sns.distplot(df['ReviewVotes'],      kde=False, color=\"g\", ax=axes[1, 2])\n",
        "#sns.distplot(df['hour'],                  kde=False, color=\"b\", ax=axes[1, 2])\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "58b67d74-9209-6228-40aa-174a19d24dce"
      },
      "source": [
        "# What can we know about Apple, its products and ratings? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53854f07-43ec-b1e4-3a10-391dc161c80b"
      },
      "outputs": [],
      "source": [
        "df_apple = df.loc[df['BrandName'].isin(['Apple'])]\n",
        "pivot = pd.pivot_table(df_apple,\n",
        "        values = ['Rating', 'ReviewVotes'],\n",
        "        index =  ['ProductName'],\n",
        "                   columns= [],\n",
        "                   aggfunc=[np.sum, np.mean, np.count_nonzero], \n",
        "                   margins=True, fill_value=0).sort_values(by=('count_nonzero', 'Rating'), ascending=False).fillna('')\n",
        "topmost_prods = pivot.reindex().head(n=30)\n",
        "topmost_prods = topmost_prods.reset_index()\n",
        "topmost_prods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6301f727-54b6-0ae5-6827-99b49760fa31"
      },
      "outputs": [],
      "source": [
        "tt_brand = topmost_prods['ProductName']\n",
        "tt_brand2 = tt_brand.reset_index()\n",
        "top_10_prod_list = list(set(tt_brand2['ProductName']))\n",
        "top_10_prod_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ff5d041d-b68e-88f9-0f58-07db7f9b6ac6"
      },
      "source": [
        "Apple's flagship products are cetainly a slightly costlier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8e5a847e-0d79-a959-6338-bcf7cb941da2"
      },
      "source": [
        "# Who is able to charge more to the customers? Apple or Samsung?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a674265e-8ad5-61ad-5dd7-b10c14fbee42"
      },
      "outputs": [],
      "source": [
        "apple_samsumg = ['Apple', 'Samsung']\n",
        "df_top_ten = df.loc[df['BrandName'].isin(apple_samsumg)]\n",
        "df_small = df_top_ten[['BrandName', \n",
        "               'Price', \n",
        "               'Rating'\n",
        "              ]]\n",
        "sns.pairplot(df_small, hue='BrandName', size=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d81d345f-910d-7b51-65a9-794eb4e19074"
      },
      "source": [
        "I was expecting something different, but this is it! I have to admit, this simple method is not exactly creating a one to one comparison. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ed3136bd-af43-d109-292d-18be935e9809"
      },
      "source": [
        "# K Mean clustering use to find out important words in top ten Brands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bc5a6588-ed3e-9f7a-dfcf-33847d01714a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "def find_correlations_one_brand(company):\n",
        "    df_one_company = df.loc[df['BrandName'].isin([company])]\n",
        "    def corr_matrix_of_important_words(term_doc_mat, word_list, scores, n_features_to_keep):\n",
        "        selector = SelectKBest(k=n_features_to_keep).fit(term_doc_mat, scores)\n",
        "        informative_words_index = selector.get_support(indices=True)\n",
        "        labels = [word_list[i] for i in informative_words_index]\n",
        "        data = pd.DataFrame(term_doc_mat[:,informative_words_index].todense(), columns=labels)\n",
        "        data['Score'] = df_one_company.Rating\n",
        "        return(data.corr())\n",
        "\n",
        "    def heat_map(corrs_mat):\n",
        "        sns.set(style=\"white\")\n",
        "        f, ax = plt.subplots(figsize=(20, 20))\n",
        "        mask = np.zeros_like(corrs_mat, dtype=np.bool)\n",
        "        mask[np.triu_indices_from(mask)] = True \n",
        "        # Generate a custom diverging colormap\n",
        "        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "        sns.heatmap(corrs_mat, mask=mask, cmap=cmap, ax=ax)\n",
        "    vectorizer = CountVectorizer(max_features = 500, stop_words='english')\n",
        "    term_doc_mat = vectorizer.fit_transform(df_one_company.Reviews.values.astype('U'))\n",
        "    word_list = vectorizer.get_feature_names()\n",
        "\n",
        "    corrs_large = corr_matrix_of_important_words(term_doc_mat, word_list, df_one_company.Rating, 60)\n",
        "    #print(corrs_large.Score.sort_values(inplace=False)[:-1])\n",
        "    corrs_small = corr_matrix_of_important_words(term_doc_mat, word_list, df_one_company.Rating, 15)\n",
        "    heat_map(corrs_small)\n",
        "\n",
        "for item in top_10_brand_list:\n",
        "    print (item)\n",
        "    find_correlations_one_brand(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b63399ed-5d01-77f0-5553-b21d444aaf6b"
      },
      "source": [
        "# Funny to see those words :) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "85db911d-bad9-6004-9017-a159d414c7f8"
      },
      "outputs": [],
      "source": [
        "df_one_company.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4566d51c-3dba-7977-adbe-ff4155306802"
      },
      "source": [
        "# Lets make a word cloud of words appearing in the reviews of various companies: For speed, running this only on Apple vs Samsung "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b601fd3-8fa3-26b8-e47c-8a6cc491aa6d"
      },
      "outputs": [],
      "source": [
        "def create_word_cloud(one_company):\n",
        "    try: \n",
        "        df_one_company = df.loc[df['BrandName'].isin([one_company])]\n",
        "        df_one_company_sample = df_one_company.sample(frac=0.05)\n",
        "        word_cloud_collection = ''\n",
        "        for val in df_one_company_sample.Reviews.str.lower():\n",
        "            tokens = nltk.word_tokenize(val)\n",
        "            tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "            for words in tokens:\n",
        "                word_cloud_collection = word_cloud_collection + words + ' '\n",
        "        wordcloud = WordCloud(max_font_size=50, width=500, height=500).generate(word_cloud_collection)\n",
        "        plt.figure(figsize=(20,20))\n",
        "        plt.imshow(wordcloud)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "    except: \n",
        "        pass\n",
        "    \n",
        "#company_list = ['Apple', 'Samsung']\n",
        "for i in top_10_brand_list:\n",
        "    print (i)\n",
        "    create_word_cloud(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "143f9a27-2f02-b133-0e23-4797b30191b7"
      },
      "source": [
        "# Let us run machine learning algorithms on the text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5b719148-1201-1af7-bd72-33e7f0523d87"
      },
      "outputs": [],
      "source": [
        "def review_to_wordlist( review, remove_stopwords=True ):\n",
        "    # Function to convert a document to a sequence of words,\n",
        "    # optionally removing stop words.  Returns a list of words.\n",
        "    # 1. Remove HTML\n",
        "    review_text = BeautifulSoup(review).get_text()\n",
        "    # 2. Remove non-letters\n",
        "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
        "    # 3. Convert words to lower case and split them\n",
        "    words = review_text.lower().split()\n",
        "    # 4. Optionally remove stop words (false by default)\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "\n",
        "    b=[]\n",
        "    stemmer = english_stemmer #PorterStemmer()\n",
        "    for word in words:\n",
        "        b.append(stemmer.stem(word))\n",
        "    # 5. Return a list of words\n",
        "    return(words)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = cm.round(3)\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4eede84b-a199-6088-0867-f9eaa00feb94"
      },
      "outputs": [],
      "source": [
        "mod_df = df[df['Reviews'].isnull()==False]\n",
        "mod_df = mod_df.sample(frac = 0.01)\n",
        "train, test = train_test_split(mod_df, test_size = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "143b3bc5-a8cb-74fb-254e-769b86aef6d8"
      },
      "outputs": [],
      "source": [
        "clean_train_reviews = []\n",
        "for review in train['Reviews']:\n",
        "    clean_train_reviews.append( \" \".join(review_to_wordlist(review)))\n",
        "    \n",
        "clean_test_reviews = []\n",
        "for review in test['Reviews']:\n",
        "    clean_test_reviews.append( \" \".join(review_to_wordlist(review)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1bb30088-a588-8e8f-c037-49d0faedb21a"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 200000, ngram_range = ( 1, 4 ),\n",
        "                              sublinear_tf = True )\n",
        "\n",
        "vectorizer = vectorizer.fit(clean_train_reviews)\n",
        "train_features = vectorizer.transform(clean_train_reviews)\n",
        "\n",
        "test_features = vectorizer.transform(clean_test_reviews)\n",
        "fselect = SelectKBest(chi2 , k=10000)\n",
        "train_features = fselect.fit_transform(train_features, train[\"Rating\"])\n",
        "test_features = fselect.transform(test_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "93dc9270-9910-a3b9-94bd-6903a89b186c"
      },
      "source": [
        "# Machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14ef9ee8-c283-0252-8694-34af23a82f6a"
      },
      "outputs": [],
      "source": [
        "classifiers = [('RandomForestClassifierG', RandomForestClassifier(n_jobs=-1, criterion='gini')),\n",
        "               ('RandomForestClassifierE', RandomForestClassifier(n_jobs=-1, criterion='entropy')),\n",
        "               ('AdaBoostClassifier', AdaBoostClassifier()),\n",
        "               ('ExtraTreesClassifier', ExtraTreesClassifier(n_jobs=-1)),\n",
        "               ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
        "               ('LogisticRegression', LogisticRegression()),\n",
        "               ('MultinomialNB', MultinomialNB(alpha=0.001)), \n",
        "               ('SGDClassifier', SGDClassifier(loss='modified_huber', n_iter=5, random_state=0, shuffle=True)),\n",
        "               ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
        "               \n",
        "              ]\n",
        "allscores = []\n",
        "for name, classifier in classifiers:\n",
        "    scores = []\n",
        "    for i in range(1): # 3 runs\n",
        "        print (name)\n",
        "\n",
        "        classifier.fit( train_features, train[\"Rating\"] )\n",
        "        pred = classifier.predict( test_features.toarray() )\n",
        "        print('prediction accuracy: ', accuracy_score(test['Rating'], pred))\n",
        "        cnf_matrix = confusion_matrix(test['Rating'], pred)\n",
        "        plot_confusion_matrix(cnf_matrix, classes=['1','2','3','4','5'],\n",
        "                      title='Confusion matrix, with normalization', normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a857fd29-16c6-d721-e480-29c7563c7286",
        "collapsed": true
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}