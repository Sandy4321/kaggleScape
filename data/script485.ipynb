{"cells": [{"metadata": {"_uuid": "c7a91c704b73cbc4f446b3ca5fecea1bfe2da6d0", "_cell_guid": "d525d176-3893-43f1-a0c4-5ea3ce7dfecc", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["import json, sys, random\n", "import numpy as np"], "execution_count": null}, {"metadata": {"_uuid": "d71f7932de8f99bd20fa95f027369bc8832cab7d", "_cell_guid": "0a21ff8c-9e61-48fc-ae62-0fecf9b22621", "_kg_hide-input": false, "collapsed": true, "_kg_hide-output": true}, "outputs": [], "cell_type": "code", "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Flatten, Activation\n", "from keras.layers import Dropout\n", "from keras.layers.convolutional import Conv2D, MaxPooling2D\n", "from keras.utils import np_utils\n", "from keras.optimizers import SGD\n", "import keras.callbacks"], "execution_count": null}, {"metadata": {"_uuid": "8f63a621f82c1857944bd44ae0a1d2240610dcbd", "_cell_guid": "cfb69e15-6f35-4697-986c-91ce8658c009", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["from PIL import Image, ImageDraw "], "execution_count": null}, {"metadata": {"_uuid": "b56c0b610ff19ff25fc2887708d7c1ba98572675", "_cell_guid": "ff096dd4-4037-42ac-a021-5f606fde719e", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["from matplotlib import pyplot as plt"], "execution_count": null}, {"metadata": {"_uuid": "6281af693d99ce4eb593439de9344e1d0cd0cd96", "_cell_guid": "a673bc83-526b-4cd5-866f-f578e092da28"}, "cell_type": "markdown", "source": ["### Download and study the dataset"]}, {"metadata": {"_uuid": "b51559108aecd4fd5fcd4d7ec2093e723ccdda7f", "_cell_guid": "4cb0b1c7-dfa6-4f4c-af09-c0531c7a297c", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# download dataset from json object\n", "f = open(r'../input/ships-in-satellite-imagery/shipsnet.json')\n", "dataset = json.load(f)\n", "f.close()"], "execution_count": null}, {"metadata": {"_uuid": "db0a4029d922825c9fc4147f3ecd0f9a27a094c6", "_cell_guid": "06cfd769-f873-4510-84f8-f83a6c5e7933", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["input_data = np.array(dataset['data']).astype('uint8')\n", "output_data = np.array(dataset['labels']).astype('uint8')"], "execution_count": null}, {"metadata": {"_uuid": "7e088317d719d8a358e94545f7f1de119be9a2bd", "_cell_guid": "3b779e26-b635-4ec5-af41-5acbaf274987"}, "cell_type": "markdown", "source": ["INPUT"]}, {"metadata": {"_uuid": "af3f2d71206333a4f8e6ae6c8fd754f3043e63bf", "_cell_guid": "c554a856-8dd7-4d65-ba8c-e75314d6693a"}, "cell_type": "markdown", "source": ["The dataset contains 2800 images. One image is represented as a vector of length 19200 elements."]}, {"metadata": {"_uuid": "c766bcbd6f7be386dac37cdf77b3794bc339654f", "_cell_guid": "90f1581a-b2b7-44ff-8567-983c9a7cd827", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["input_data.shape"], "execution_count": null}, {"metadata": {"_uuid": "a41703a2abfc4be3b621208ed6ee7fe2973f850c", "_cell_guid": "64374bb2-18fd-41e9-b9da-81f7b2a8afd4", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["n_spectrum = 3 # color chanel (RGB)\n", "weight = 80\n", "height = 80\n", "X = input_data.reshape([-1, n_spectrum, weight, height])\n", "X[0].shape"], "execution_count": null}, {"metadata": {"_uuid": "d5f60803a6aa86fecd3072f493ee79cf92daa5f8", "_cell_guid": "deb01f4e-bab9-4fe9-b3a2-782939566a8c", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# get one chanel\n", "pic = X[0]\n", "\n", "rad_spectrum = pic[0]\n", "green_spectrum = pic[1]\n", "blue_spectum = pic[2]"], "execution_count": null}, {"metadata": {"_uuid": "c10722df44747bf52e6f95ab11bd83fa8a2bf1e4", "_cell_guid": "84703e3b-8884-42ad-812b-f9f51f16f210", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["plt.figure(2, figsize = (5*3, 5*1))\n", "plt.set_cmap('jet')\n", "\n", "# show each channel\n", "plt.subplot(1, 3, 1)\n", "plt.imshow(rad_spectrum)\n", "\n", "plt.subplot(1, 3, 2)\n", "plt.imshow(green_spectrum)\n", "\n", "plt.subplot(1, 3, 3)\n", "plt.imshow(blue_spectum)\n", "    \n", "plt.show()"], "execution_count": null}, {"metadata": {"_uuid": "ce096eae5b5b6f2ce7db5463436ea1d6a63bc207", "_cell_guid": "931df9f5-a86b-4c84-abd9-b1f6acfd2a70"}, "cell_type": "markdown", "source": ["OUTPUT"]}, {"metadata": {"_uuid": "e7f03831759e17b776e9d78bb20e6d4628cc1a64", "_cell_guid": "e9ee9100-7e3f-4695-b512-129ffe86d133"}, "cell_type": "markdown", "source": ["The output is a vector of lenght 2800 elements."]}, {"metadata": {"_uuid": "74fb860f985b46eac6a72327e2a0513d5f27ec4b", "_cell_guid": "704be993-d12d-453a-a2ac-67b652ff248c", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["output_data.shape"], "execution_count": null}, {"metadata": {"_uuid": "6b601fcc16bff6341ff7c780a0b547089e0c4eca", "_cell_guid": "9d0a9b2e-1ac4-416e-ad27-90369fc23bb3"}, "cell_type": "markdown", "source": ["The vector contains int 0 and 1"]}, {"metadata": {"_uuid": "25a2ca93f50f57e2aa95481f3cc9547565fbe82a", "_cell_guid": "114f9ed6-8414-41de-8fee-7b4274012ff1", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["output_data"], "execution_count": null}, {"metadata": {"_uuid": "6473b125764a97026826e9a00604acda80f58e85", "_cell_guid": "4fa5591b-26d9-488b-90f2-988d01c52377"}, "cell_type": "markdown", "source": ["Vector contains of 2100 zeros and 700 units. This means that in a dataset of 700 images tagged with \"ship\" and 2100 images marked as \"not ship\"."]}, {"metadata": {"_uuid": "d97eb870db8ae126de15086ff804627b04236101", "_cell_guid": "0f9ad0d9-6b67-4f56-a079-96f77d8dc46a", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["np.bincount(output_data)"], "execution_count": null}, {"metadata": {"_uuid": "6fa3ecb5eb43d57eef59d10bef424edee4e57cd8", "_cell_guid": "e318f774-6c00-4718-a122-dc631100cace"}, "cell_type": "markdown", "source": ["### Preparing data"]}, {"metadata": {"_uuid": "c6ad1e8056dea32c3ac2af49497d82ef5e3381c4", "_cell_guid": "fa9a91a3-2c47-4a4b-ae0f-3768cd37336f", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# output encoding\n", "y = np_utils.to_categorical(output_data, 2)"], "execution_count": null}, {"metadata": {"_uuid": "dedafb6ccc2001b921b95f6ae8712eccaf27e711", "_cell_guid": "4905b7e9-03d5-4541-9c03-c8a68249de54", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# shuffle all indexes\n", "indexes = np.arange(2800)\n", "np.random.shuffle(indexes)"], "execution_count": null}, {"metadata": {"_uuid": "9648ef4837cde776e6094bfba96b762713447751", "_cell_guid": "5b0cf256-db02-4170-bafc-284ced785c44", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["X_train = X[indexes].transpose([0,2,3,1])\n", "y_train = y[indexes]"], "execution_count": null}, {"metadata": {"_uuid": "6400b0729f94068bb61288be8f3f81ff708ef34a", "_cell_guid": "3bd9754e-ca6d-4355-8296-bf3cc7d3bcc1", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# normalization\n", "X_train = X_train / 255"], "execution_count": null}, {"metadata": {"_uuid": "3c65892fa6f0502557cda3643afeda50179f7a70", "_cell_guid": "f2d2db89-ade8-4df2-ae21-8c2762c3846a"}, "cell_type": "markdown", "source": ["### Traing network"]}, {"metadata": {"_uuid": "1699be4a44f2a47a5ed12fa1bdbf5b63e26d4a70", "_cell_guid": "84103547-49ea-4852-83ac-37836fd351e1", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["np.random.seed(42)"], "execution_count": null}, {"metadata": {"_uuid": "8b5c2f2a7e5f448931b61f6bddd155bd3bd8a122", "_cell_guid": "9a5bf059-af37-4d71-88f9-2821c7bfc736", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# network design\n", "model = Sequential()\n", "\n", "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(80, 80, 3), activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2, 2))) #40x40\n", "model.add(Dropout(0.25))\n", "\n", "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2, 2))) #20x20\n", "model.add(Dropout(0.25))\n", "\n", "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2, 2))) #10x10\n", "model.add(Dropout(0.25))\n", "\n", "model.add(Conv2D(32, (10, 10), padding='same', activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2, 2))) #5x5\n", "model.add(Dropout(0.25))\n", "\n", "model.add(Flatten())\n", "model.add(Dense(512, activation='relu'))\n", "model.add(Dropout(0.5))\n", "\n", "model.add(Dense(2, activation='softmax'))"], "execution_count": null}, {"metadata": {"_uuid": "65b0af2640298ea8e6fd6fb08ee1bc5766039c11", "_cell_guid": "476c19dc-9402-459d-b0a8-020b7abaa6ee", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# optimization setup\n", "sgd = SGD(lr=0.01, momentum=0.9, nesterov=True)\n", "model.compile(\n", "    loss='categorical_crossentropy',\n", "    optimizer=sgd,\n", "    metrics=['accuracy'])\n", "\n", "# training\n", "model.fit(\n", "    X_train, \n", "    y_train,\n", "    batch_size=32,\n", "    epochs=18,\n", "    validation_split=0.2,\n", "    shuffle=True,\n", "    verbose=2)"], "execution_count": null}, {"metadata": {"_uuid": "32f617491ea14f896b3a107c33d0ae2d05cae1a5", "_cell_guid": "06461c02-c1fc-4ff5-b8bb-c1eab79b347c"}, "cell_type": "markdown", "source": ["# Using network"]}, {"metadata": {"_uuid": "5a0ac58e0e0863c5e1902231f1a1f62aabb27250", "_cell_guid": "7492d8b7-77a3-4ed0-83ba-c9d3de351956"}, "cell_type": "markdown", "source": ["### download image"]}, {"metadata": {"_uuid": "c22186e1baa7552c0130d09d7747bd8b00c1c2a6", "_cell_guid": "51a26a8b-1410-4ca7-8f91-6502426c43c0", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["image = Image.open('../input/sfbay/sfbay_1.png')\n", "pix = image.load()"], "execution_count": null}, {"metadata": {"_uuid": "abecb3613e5425495d48270456cf8e097dbaf7e1", "_cell_guid": "84cb5662-09b0-400e-9cf2-bf7f2e5b282e", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["n_spectrum = 3\n", "width = image.size[0]\n", "height = image.size[1]"], "execution_count": null}, {"metadata": {"_uuid": "bf7a9fded14807ca67e3dd85e6f370035443344d", "_cell_guid": "ca19907b-3380-47ee-b5b5-bbab246be32a", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# creat vector\n", "picture_vector = []\n", "for chanel in range(n_spectrum):\n", "    for y in range(height):\n", "        for x in range(width):\n", "            picture_vector.append(pix[x, y][chanel])"], "execution_count": null}, {"metadata": {"_uuid": "bcad0fe4f3abc3e4c566515b87d232721fc802fc", "_cell_guid": "96eb56f1-2564-4bcc-ac85-2543c2cba80a", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["picture_vector = np.array(picture_vector).astype('uint8')\n", "picture_tensor = picture_vector.reshape([n_spectrum, height, width]).transpose(1, 2, 0)"], "execution_count": null}, {"metadata": {"_uuid": "85cc607eadb466f9ab1c96bb255626c9cadf277b", "_cell_guid": "9f04c729-d761-4c6f-b04e-e8b3d3a7f585", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["plt.figure(1, figsize = (15, 30))\n", "\n", "plt.subplot(3, 1, 1)\n", "plt.imshow(picture_tensor)\n", "\n", "plt.show()"], "execution_count": null}, {"metadata": {"_uuid": "7ca00dde064690ea1c795d07a9d8ec10371ea689", "_cell_guid": "dd418636-ac3e-41ce-aef7-d1d850ab8e74", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["picture_tensor = picture_tensor.transpose(2,0,1)"], "execution_count": null}, {"metadata": {"_uuid": "4244478132fbc697158abba0047f560846dfd8be", "_cell_guid": "2b8ec8c8-1875-4302-8674-f88614e1de69"}, "cell_type": "markdown", "source": ["### Search on the image"]}, {"metadata": {"_uuid": "538d3be5b0a9409711c4360705b67d030820693c", "_cell_guid": "ec6666e8-bdac-4206-a59a-a5cf9b6d09d7", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["def cutting(x, y):\n", "    area_study = np.arange(3*80*80).reshape(3, 80, 80)\n", "    for i in range(80):\n", "        for j in range(80):\n", "            area_study[0][i][j] = picture_tensor[0][y+i][x+j]\n", "            area_study[1][i][j] = picture_tensor[1][y+i][x+j]\n", "            area_study[2][i][j] = picture_tensor[2][y+i][x+j]\n", "    area_study = area_study.reshape([-1, 3, 80, 80])\n", "    area_study = area_study.transpose([0,2,3,1])\n", "    area_study = area_study / 255\n", "    sys.stdout.write('\\rX:{0} Y:{1}  '.format(x, y))\n", "    return area_study"], "execution_count": null}, {"metadata": {"_uuid": "0da219174c5a628e5d665c0f69a4eabf87ffdcaf", "_cell_guid": "07009f5d-5a2f-4e2d-9965-b37f937085dd", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["def not_near(x, y, s, coordinates):\n", "    result = True\n", "    for e in coordinates:\n", "        if x+s > e[0][0] and x-s < e[0][0] and y+s > e[0][1] and y-s < e[0][1]:\n", "            result = False\n", "    return result"], "execution_count": null}, {"metadata": {"_uuid": "0175083b390371f8bc95e86cf2310000a41469b5", "_cell_guid": "e94e2716-b9a0-46d8-812c-dc3de13e3a27", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["def show_ship(x, y, acc, thickness=5):   \n", "    for i in range(80):\n", "        for ch in range(3):\n", "            for th in range(thickness):\n", "                picture_tensor[ch][y+i][x-th] = -1\n", "\n", "    for i in range(80):\n", "        for ch in range(3):\n", "            for th in range(thickness):\n", "                picture_tensor[ch][y+i][x+th+80] = -1\n", "        \n", "    for i in range(80):\n", "        for ch in range(3):\n", "            for th in range(thickness):\n", "                picture_tensor[ch][y-th][x+i] = -1\n", "        \n", "    for i in range(80):\n", "        for ch in range(3):\n", "            for th in range(thickness):\n", "                picture_tensor[ch][y+th+80][x+i] = -1"], "execution_count": null}, {"metadata": {"_uuid": "6275697ebe5f3d5378b0738f09a66749cd03fb71", "_cell_guid": "4fd605e1-3e74-47e6-857e-1f1ac39f2c91", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["step = 10; coordinates = []\n", "for y in range(int((height-(80-step))/step)):\n", "    for x in range(int((width-(80-step))/step) ):\n", "        area = cutting(x*step, y*step)\n", "        result = model.predict(area)\n", "        if result[0][1] > 0.90 and not_near(x*step,y*step, 88, coordinates):\n", "            coordinates.append([[x*step, y*step], result])\n", "            print(result)\n", "            plt.imshow(area[0])\n", "            plt.show()"], "execution_count": null}, {"metadata": {"_uuid": "9705e23c05c79837ae255019de0834b355031bec", "_cell_guid": "f7cb1bf4-1b6b-48b7-9cd0-14d0dedcd8c1", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["for e in coordinates:\n", "    show_ship(e[0][0], e[0][1], e[1][0][1])"], "execution_count": null}, {"metadata": {"_uuid": "0deb6d3dc998a1396ea930061f56fbb080afbc5f", "_cell_guid": "41273679-bd96-42b5-bde4-2f05ecda4195", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["#picture_tensor = picture_tensor.transpose(2,0,1)\n", "picture_tensor = picture_tensor.transpose(1,2,0)\n", "picture_tensor.shape"], "execution_count": null}, {"metadata": {"_uuid": "057be27f1f84364997336eaae2f31e71dbc32308", "_cell_guid": "12af3d3e-93fc-480e-a130-4e807fe00c33", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["plt.figure(1, figsize = (15, 30))\n", "\n", "plt.subplot(3,1,1)\n", "plt.imshow(picture_tensor)\n", "\n", "plt.show()"], "execution_count": null}, {"metadata": {"_uuid": "f4ad01e6d84814811549402a9a73c7fb85232996", "_cell_guid": "6173eff7-fe4b-497e-b3e4-67a531729393", "collapsed": true}, "outputs": [], "cell_type": "code", "source": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.4", "mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat": 4, "nbformat_minor": 1}