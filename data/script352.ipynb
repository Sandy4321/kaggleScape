{"nbformat_minor": 1, "metadata": {"language_info": {"file_extension": ".py", "version": "3.6.3", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"metadata": {"_uuid": "a05e1d28e0367e1502d9c7fee3894ad22fb966bb", "_cell_guid": "7fee1dd7-490a-48f4-b6d2-a12a379ab218"}, "source": ["# ** Introduction **\n", ">**About Zillow:** Zillow's Economic Research Team collects, cleans and publishes housing and economic data from a variety of public and proprietary sources. Public property record data filed with local municipalities -- including deeds, property facts, parcel information and transactional histories -- forms the backbone of our data products, and is fleshed out with proprietary data derived from property listings and user behavior on Zillow.\n", "\n", "> In this notebook, I will be analysing Zillow Economics Data.  \n", "\n", "## Table of Contents\n", "> 1. [Load the data](#load_the_data)\n", "> 2. [Value of all homes per square in different year ](#value_per_sq_diff_ye)\n", "> 3. [Median of list prices per square foot in different year](#value_listing_per_sq_diff_ye)\n", "> 4. [Median of rental prices per square foot in different year](#rental_price_per_sq_diff_ye)\n", "> 5. [Zillow's different home value in different year](#dif_hom_va_dif_ye)\n", "> 6. [Percentage of home sold in previous year](#perce_home_sold_pre_year)\n", "> 7. [Median of the value of all homes per square foot in different states](#value_home_per_sqft_dif_states)\n", "> 8. [The percentage of all homes in a given area that sold in the past years](#value_home_sold_dif_states)"], "cell_type": "markdown"}, {"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "plt.style.use('ggplot')\n", "import seaborn as sns\n", "from IPython.display import Image, display\n", "\n", "# import plotly\n", "import plotly\n", "import plotly.offline as py\n", "py.init_notebook_mode(connected=True)\n", "import plotly.tools as tls\n", "import plotly.graph_objs as go\n", "import plotly.tools as tls\n", "import plotly.figure_factory as fig_fact\n", "plotly.tools.set_config_file(world_readable=True, sharing='public')\n", "\n", "\n", "%matplotlib inline\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_uuid": "09ef5748393547ea5a3af5d3845b4774beeae3d9", "_kg_hide-input": true, "_cell_guid": "e4c533f1-98ed-4c4d-bec7-8444e8030075", "_kg_hide-output": true}, "outputs": [], "cell_type": "code", "execution_count": 1}, {"metadata": {"_uuid": "12cabfe7d10583b177883851bfe97c8184abd245", "_cell_guid": "0903553d-a6ca-43f3-9e7c-9fa985ef5d63"}, "source": ["<a id=\"load_the_data\"></a>\n", "> # 1. **Load the data**\n", ">> *In this section, I will load the necessary data. For this notebook, I will need only two file. a) **City_time_series.csv** b) **cities_crosswalk.csv***. "], "cell_type": "markdown"}, {"source": ["# let's read the 'City_time_series.csv' \n", "df_city_time_seris = pd.read_csv('../input/City_time_series.csv')\n", "# print top 10 item \n", "df_city_time_seris.head()"], "metadata": {"_uuid": "bc2e9243bf6ca38754823dae1f899556f5ca1839", "_kg_hide-input": false, "_cell_guid": "86a0132e-4f3e-4f42-bc76-1d7b534b3b0e"}, "outputs": [], "cell_type": "code", "execution_count": 2}, {"source": ["df_cities_crosswalk = pd.read_csv('../input/cities_crosswalk.csv')\n", "df_cities_crosswalk.head()"], "metadata": {"_uuid": "e9079055584f372cd119165c9f99533621e043fb", "_cell_guid": "db9c7407-6df3-42cc-af62-473f7e989b28"}, "outputs": [], "cell_type": "code", "execution_count": 3}, {"metadata": {"_uuid": "3d9ea64cdfef9d4674496954f2e78b3fed2ff725", "_cell_guid": "030e54ee-2a4f-4794-a8e1-b7de61d14626"}, "source": ["<a id=\"value_per_sq_diff_ye\"></a>\n", "> # ** 2. Value of all homes per square in different year **\n", ">> **Value of all homes per square** -  Median of the value of all homes per square foot. This number is calculated by taking the estimated home value for each home in a given region and dividing it by the home's square footage. "], "cell_type": "markdown"}, {"source": ["df_city_time_seris.Date = pd.to_datetime(df_city_time_seris.Date)\n", "df_city_time_seris.groupby(df_city_time_seris.Date.dt.year)['ZHVIPerSqft_AllHomes'].mean().plot(kind='bar', figsize=(10, 6))\n", "plt.suptitle('Median of the value of all homes per square foot in different year', fontsize=12)\n", "plt.ylabel('Zillow home value per square foot')\n", "plt.xlabel('Year')\n", "plt.show()"], "metadata": {"_uuid": "9cd8558a5f3fc30ac1b7d385b8bc909f416ff247", "_kg_hide-input": true, "_cell_guid": "91e79e07-3501-4227-bc01-0a5aa78630dc"}, "outputs": [], "cell_type": "code", "execution_count": 4}, {"metadata": {"_uuid": "4d61ec681692f04fcab7b8e6e38166331e32ad43", "_cell_guid": "42ba1b70-2dbb-4dfc-a69a-ee2e7b5034c4"}, "source": ["> ** It' seems like Zelow home value per square foot is higher in 2005 - 2009 and again high in 2017 **"], "cell_type": "markdown"}, {"metadata": {"_uuid": "b5f7f4ba792d06c90177e380eaa0c1289171018d", "_cell_guid": "b969d146-83a7-43d3-bce8-ddf059963a69"}, "source": ["<a id=\"value_listing_per_sq_diff_ye\"></a>\n", "# ** 3. Median of list prices per square foot in different year ** \n", "> ** How median of list prices are calculated: ** *Median of list prices divided by the square footage of a home*"], "cell_type": "markdown"}, {"source": ["df_city_time_seris_without_null = df_city_time_seris.dropna(subset=['MedianListingPricePerSqft_AllHomes'], how='any')\n", "df_city_time_seris_without_null.groupby(df_city_time_seris_without_null.Date.dt.year)['MedianListingPricePerSqft_AllHomes'].mean().plot(kind='bar', figsize=(10, 6))\n", "plt.suptitle('Median of list prices per square foot in different year', fontsize=24)\n", "plt.ylabel('Median Listing Price Per Square foot')\n", "plt.xlabel('Year')\n", "plt.show()"], "metadata": {"_uuid": "a23503f42696340b53f8105c164108e1aef0d87c", "_kg_hide-input": true, "_cell_guid": "cae499f7-897e-4ca0-9560-353875338083"}, "outputs": [], "cell_type": "code", "execution_count": 5}, {"metadata": {"_uuid": "efaf280862dce384323f57dccd254dabede5b70b", "_cell_guid": "1afe3da4-79a0-436c-ab30-f6f87725b5a2"}, "source": ["> It looks like list prices are high in 2017 compares to the previous year. "], "cell_type": "markdown"}, {"metadata": {"_uuid": "3570f9e70aa68d122a86d9c5b22a9d895c923236", "_cell_guid": "4b3f9d41-f765-4f29-ac26-7d8920e5fad7"}, "source": ["<a id=\"rental_price_per_sq_diff_ye\"></a>\n", "# ** 4. Median of rental prices per square foot in different year **\n", "> ** How median of rental prices are calculated: ** *Median of the rental price per square foot of homes listed for rent on Zillow in a given region*"], "cell_type": "markdown"}, {"source": ["df_city_time_seris_without_null_rent = df_city_time_seris.dropna(subset=['MedianRentalPricePerSqft_AllHomes'], how='any')\n", "df_city_time_seris_without_null_rent.groupby(df_city_time_seris_without_null_rent.Date.dt.year)['MedianListingPricePerSqft_AllHomes'].mean().plot(kind='bar', figsize=(10, 6))\n", "plt.suptitle('Median of rental prices per square foot in different year', fontsize=24)\n", "plt.ylabel('Median rental Price Per Square foot')\n", "plt.xlabel('Year')\n", "plt.show()"], "metadata": {"_uuid": "3b0fa20968f487e970139f93625f3b3640135a08", "_kg_hide-input": true, "_cell_guid": "f2d0a0fd-ef14-451e-bef9-990c35ea227b"}, "outputs": [], "cell_type": "code", "execution_count": 6}, {"metadata": {"_uuid": "25742b17bd0003bc41575dbc6fdb2be09df12498", "_cell_guid": "11f12716-9f10-4068-902e-15b570bd6dd0"}, "source": ["> "], "cell_type": "markdown"}, {"metadata": {"_uuid": "bd5df0a4a548538afb9d9eb9b4752343b5859f70", "_cell_guid": "ba40e35c-a137-44d2-902d-5ba121055c63"}, "source": ["<a id=\"dif_hom_va_dif_ye\"></a>\n", "# **5. Zillow's different home value in different year **\n", "> **Zillow home differs from many housing types. Like 2, 3 or 4 bedrooms. Let's see how value differs from different house type.**"], "cell_type": "markdown"}, {"source": ["df_city_time_seris.groupby(df_city_time_seris.Date.dt.year)[['ZHVI_2bedroom','ZHVI_3bedroom','ZHVI_4bedroom']].mean().plot(kind='bar', figsize=(10, 6))\n", "plt.suptitle(\"Zillow's different home value in different year\", fontsize=24)\n", "plt.ylabel('Zillow home value in different housing type')\n", "plt.xlabel('Year')\n", "plt.show()"], "metadata": {"_uuid": "da56e0c65ce183fdde7d24f86650ec251ff70136", "_kg_hide-input": true, "_cell_guid": "6ad3b205-e121-4ac0-8902-ddfc11acdd78"}, "outputs": [], "cell_type": "code", "execution_count": 7}, {"metadata": {"_uuid": "e414258c8e06185c7621ec38b2992d5631a0f1ff", "_cell_guid": "57d8e23b-fd55-4405-9a2b-5eb8b3bcdcb5"}, "source": ["> It looks like the comparison of 2,3 and 4 bedroom house price is always same."], "cell_type": "markdown"}, {"metadata": {"_uuid": "67710300aadd2d84ff5ac749cb48d8ae8e4f741e", "_cell_guid": "4eb69ea0-4cfb-431b-b82e-a3603a7cdcac"}, "source": [" <a id=\"perce_home_sold_pre_year\"></a>\n", " # **6. Percentage of home sold in previous year **\n", " > ** Let's find out the percentage of home sold in the previous year.**"], "cell_type": "markdown"}, {"source": ["df_city_time_seris_without_null_h_sold = df_city_time_seris.dropna(subset=['Turnover_AllHomes'], how='any')\n", "df_city_time_seris_without_null_h_sold.groupby(df_city_time_seris_without_null_h_sold.Date.dt.year)['Turnover_AllHomes'].mean().plot(kind='bar', figsize=(10, 6))\n", "plt.suptitle(\"The percentage of all homes in a given area that sold in the past years\", fontsize=18)\n", "plt.ylabel('Percentage of sold', fontsize=18)\n", "plt.xlabel('Year')\n", "plt.show()"], "metadata": {"_uuid": "a73dc7bdd43e5649e7ea30469f6101ca97b1c66b", "_kg_hide-input": true, "_cell_guid": "1ab0af95-1e16-468d-acaa-944affa67c3d"}, "outputs": [], "cell_type": "code", "execution_count": 8}, {"metadata": {"_uuid": "b2c61452390470f6097ff3b662204d898bedc245", "_cell_guid": "475b6505-38d8-44a8-9bfc-43dff177ea10"}, "source": ["> Wow! That's interesting. In 2003 - 2007, more homes sold compared to others year. And in 2017, the percentage of the house sells is really low compared to previous year."], "cell_type": "markdown"}, {"source": ["# let's replace the regionName column value with State name from cities_crosswalk.csv\n", "df_city_time_seris['RegionName'] = df_city_time_seris['RegionName'].map(df_cities_crosswalk.set_index('Unique_City_ID')['State'])\n", "df_city_time_seris"], "metadata": {"_uuid": "dfe25fe32a0cb5bee36ceffbf6f11042615ed807", "_kg_hide-input": true, "_cell_guid": "1749cea6-0239-42e3-af15-5093618587a6", "_kg_hide-output": true}, "outputs": [], "cell_type": "code", "execution_count": 9}, {"source": ["# group regionName with ZHVIpersqft mean value\n", "df_regi_zhvi_sq_mean = df_city_time_seris.groupby(df_city_time_seris.RegionName)['ZHVIPerSqft_AllHomes'].mean().reset_index(name = \"ZHVIpersqft_mean\")\n", "# drop null values\n", "df_regi_zhvi_sq_mean = df_regi_zhvi_sq_mean.dropna(subset=['ZHVIpersqft_mean'], how='any')\n", "df_regi_zhvi_sq_mean"], "metadata": {"_uuid": "108c06acb8aefa0cd302440428c1de3ca8ff99d4", "_kg_hide-input": true, "_cell_guid": "ca916b4e-0384-435f-8ed6-88a253db0a67", "_kg_hide-output": true}, "outputs": [], "cell_type": "code", "execution_count": 10}, {"metadata": {"_uuid": "af1ddc134526ae0ead2b7a018ddbf8f6ceb8edc9", "_cell_guid": "07b9ea3f-2980-48aa-a0d6-7a228c07294b"}, "source": [" <a id=\"value_home_per_sqft_dif_states\"></a>\n", "# ** 7. Median of the value of all homes per square foot in different states**\n", "> ** Let's see the median value of per square of all homes in different country **"], "cell_type": "markdown"}, {"source": ["scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],[0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n", "\n", "\n", "# difine our data for plotting\n", "data = [ dict(\n", "        type='choropleth',\n", "        colorscale = scl,\n", "        autocolorscale = False,\n", "        locations = df_regi_zhvi_sq_mean['RegionName'], # location (states)\n", "        z = df_regi_zhvi_sq_mean['ZHVIpersqft_mean'].astype(float), # Zillow Home value per square foot\n", "        locationmode = 'USA-states', # let's define the location mode to USA_states\n", "        text = 'Median home value per square foot',\n", "        marker = dict(\n", "            line = dict (\n", "                color = 'rgb(255,255,255)',\n", "                width = 2\n", "            ) ),\n", "        colorbar = dict(\n", "            title = \"Home value per square foot\")\n", "        ) ]\n", "\n", "layout = dict(\n", "        title = 'Median of the value of all homes per square foot in different states<br>(Hover for breakdown)',\n", "        geo = dict(\n", "            scope='usa',\n", "            projection=dict( type='albers usa' ),\n", "            showlakes = True,\n", "            lakecolor = 'rgb(255, 255, 255)'),\n", "             )\n", "\n", "\n", "\n", "\n", "    \n", "fig = dict( data=data, layout=layout )\n", "# let's plot\n", "py.iplot( fig, filename='d3-cloropleth-map' )"], "metadata": {"_uuid": "e019d859a6857cd8b01e5201fc8d3749a0963509", "_kg_hide-input": true, "_cell_guid": "403cbfbf-dfa0-4924-adf1-262712f53349"}, "outputs": [], "cell_type": "code", "execution_count": 11}, {"source": ["# group region with percentage of house sold\n", "df_city_time_seris_house_sold = df_city_time_seris.groupby(df_city_time_seris.RegionName)['Turnover_AllHomes'].mean().reset_index(name = \"percen_sold_house\")\n", "# drop null values\n", "df_city_time_seris_house_sold = df_city_time_seris_house_sold.dropna(subset=['percen_sold_house'], how='any')\n", "df_city_time_seris_house_sold"], "metadata": {"_uuid": "6c9bb98c8382e71140decebe81ba3a136ebf47ba", "_kg_hide-input": true, "_cell_guid": "acd6fb60-56df-46a2-8a79-23228fd5c815", "_kg_hide-output": true}, "outputs": [], "cell_type": "code", "execution_count": 12}, {"metadata": {"_uuid": "b18bc5e88d5e7eade4c71635edd5ebe348116617", "_cell_guid": "6ec450e0-a362-4993-896f-385440657704"}, "source": [" <a id=\"value_home_sold_dif_states\"></a>\n", "# ** 8. The percentage of all homes in a given area that sold in the past years **\n", "> **Okay! Let's see the percentage of sold of the house in different states.**"], "cell_type": "markdown"}, {"source": ["scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],[0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n", "\n", "\n", "data = [ dict(\n", "        type='choropleth',\n", "        colorscale = scl,\n", "        autocolorscale = False,\n", "        locations = df_city_time_seris_house_sold['RegionName'],\n", "        z = df_city_time_seris_house_sold['percen_sold_house'].astype(float),\n", "        locationmode = 'USA-states',\n", "        text = 'Percentage of sold',\n", "        marker = dict(\n", "            line = dict (\n", "                color = 'rgb(255,255,255)',\n", "                width = 2\n", "            ) ),\n", "        colorbar = dict(\n", "            title = \"% of sold\")\n", "        ) ]\n", "\n", "layout = dict(\n", "        title = 'The percentage of all homes in a given area that sold in the past years<br>(Hover for breakdown)',\n", "        geo = dict(\n", "            scope='usa',\n", "            projection=dict( type='albers usa' ),\n", "            showlakes = True,\n", "            lakecolor = 'rgb(255, 255, 255)'),\n", "             )\n", "\n", "\n", "\n", "\n", "    \n", "fig = dict( data=data, layout=layout )\n", "py.iplot( fig, filename='d3-cloropleth-map' )"], "metadata": {"_uuid": "38b35d2c5f9cfae166cfeb512953629890d8baed", "_kg_hide-input": true, "_cell_guid": "0a5fa0fc-8241-4ff1-9101-877236020b03"}, "outputs": [], "cell_type": "code", "execution_count": 13}, {"metadata": {"collapsed": true, "_uuid": "a39c022dd8815594230e4cb2a4430868147f27c2", "_cell_guid": "01ed709b-6fb8-4602-8810-69e58e0c6ea1"}, "source": ["# **Conclusion**\n", "> *Thanks for reading this notebook. I am new to data science. So if you have any suggestions feel free to tell me. Don't forget to upvote!*"], "cell_type": "markdown"}], "nbformat": 4}