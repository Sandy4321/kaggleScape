{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Understanding Approval:- Donor Choose EDA\n![](https://cdn.donorschoose.net/images/media-logo-tagline-reversed@2x.jpg)\n\n# Contents:\n* Introduction\n    * About Donors Choose\n    * Competition Objective\n    * Kernel objective\n* Imports and overview\n* Custom Helper Functions\n    * Plotting Functions\n    * Text functions\n        * Extract text stats\n        * Make Wordclouds\n* Individual Feature impact on Approval rates\n    * Categorical features - Teacher-prefix, Gender, Grade/class\n    * Cleaning up - Subject category and Subject sub-category\n* Text columns exploration\n    * Title\n    * Student description\n    * Project description\n    * Resource summary\n* Resources dataset\n* Custom Word Vectors (Word2Vec)\n    * Product Descriptions\n    * Similar Products\n    * Primer to product clustering \n* Product Clustering\n    * **Are teachers asking for the same type of products getting rejected?**\n* Price points\n    * Exploring some costly items\n* Pre-processing and cleaning text\n* Feature Engineering\n    * Label encoding\n    * Create date features\n    * Custom Vectorizer for ELI5 compatability\n* Baseline Models -- XGBoost and LightGBM\n    * ROC curve and \n* Understanding how the model predicts - ELI5\n    * Explore correct classifications\n    * Explore mis-classifications\n\n# 1. Introduction:\n## 1.1 About Donors Choose:\n[Donorschoose.org](https://www.donorschoose.org/about) is a crowdfunding platform which connects Public school teachers and Donors. \n![](http://stuffonix.com/wp-content/uploads/2017/09/donorschoose-how-it-work.jpg)\n\n\nAs per their [website](https://www.donorschoose.org/about/impact.html), they have raised $645,575,280 till date and claim that 77 percent of all the public schools in America have at least one teacher who has posted a project on DonorsChoose.org. Amazing!\n\nWith such high numbers, the number of applications they receive is increasing every year and the current screening process is manually vetting the applications by a team of volunteers. As a result, there are three main problems they need to solve:\n\n* How to scale current manual processes and resources to screen 500,000 projects so that they can be posted as quickly and as efficiently as possible\n* How to increase the consistency of project vetting across different volunteers to improve the experience for teachers\n* How to focus volunteer time on the applications that need the most assistance\n\n## 1.2 Competition Objective:\n\nThe goal of the competition is to predict whether or not a DonorsChoose.org project proposal submitted by a teacher will be approved, using the text of project descriptions as well as additional metadata about the project, teacher, and school. DonorsChoose.org can then use this information to identify projects most likely to need further review before approval.\n\n## 1.3 Kernel objective:\n\nTo explore and understand factors that make a successful project and hopefully create an approval process pipeline/algorithm to help Donorschoose.org with the vetting process of approving a project.\n\n# 2. Imports and overview:\n\nLets get started by importing all the required packages and performing basic sanity checks like the test-train split ratio, Missing value checks,etc."},{"metadata":{"_cell_guid":"8eb0d250-9b77-42e0-b7b1-28b2cd49dc2d","_uuid":"4a935348420caa39131b6eef5f1111a8c3fd81bb","trusted":true},"cell_type":"code","source":"#peak\n!ls -l ../input/*","execution_count":1,"outputs":[]},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#import required packages\n#basics\nimport pandas as pd \nimport numpy as np\n\n#viz\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec \nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom PIL import Image\n\n\n#nlp\nimport re    #for regex\nimport nltk\nfrom nltk.corpus import stopwords\nimport gensim\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nlem = WordNetLemmatizer()\neng_stopwords = set(stopwords.words(\"english\"))\n\n\n#stats\nfrom statsmodels.stats.proportion import proportion_confint\n\n#misc\nimport gc\nimport time\nimport warnings\n\n#settings\nstart_time=time.time()\ncolor = sns.color_palette()\nsns.set_style(\"dark\")\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"25b024b8-3f7e-4bb4-b09a-9422ae7f20da","collapsed":true,"_uuid":"1dd2e29fc5edaed70d331c6e736ce26a8bfb3820","trusted":true},"cell_type":"code","source":"#import all the files!\ntrain=pd.read_csv(\"../input/donorschoose-application-screening/train.csv\")\nresources=pd.read_csv(\"../input/donorschoose-application-screening/resources.csv\")\ntest=pd.read_csv(\"../input/donorschoose-application-screening/test.csv\")\nsample_sub=pd.read_csv(\"../input/donorschoose-application-screening/sample_submission.csv\")","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"cf239116-319f-41ff-b7ec-44a759be9221","_uuid":"12138214a709a1c067290f89e02805f5d43470b0","trusted":true},"cell_type":"code","source":"# peak at the data\ntrain.head()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"e508d53d-70e0-4377-91b9-fee38e284b16","_uuid":"2819e28785a3dab1f6ab2acee589f71eb065ab65","trusted":true},"cell_type":"code","source":"#take a peak\nresources.head()","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"253f4654-0fd6-4608-9abd-26ab082b1836","_uuid":"73389ec993176e4cc170c38f62c467ac070bc696"},"cell_type":"markdown","source":"### Check the test-train split ratio:"},{"metadata":{"_cell_guid":"c1399e25-354f-4117-a562-ed1d853358f0","_kg_hide-input":true,"_uuid":"8a06997ee2e4a651f9b80080320a5586fd7312cf","trusted":true},"cell_type":"code","source":"#check test train split\nnrow_train=train.shape[0]\nnrow_test=test.shape[0]\nsum=nrow_train+nrow_test\nprint(\"Checking proportion of Test-train split\")\nprint(\"       : train  : test\")\nprint(\"rows   :\",nrow_train,\":\",nrow_test)\nprint(\"perc   :\",round(nrow_train*100/sum),\"    :\",round(nrow_test*100/sum))","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"10b6f6f5-d47b-4d6d-b0fb-edbf2911d7d5","_kg_hide-input":true,"_uuid":"64de7052847f16e0e61b9fd973a19c28b0eb327a","trusted":true},"cell_type":"code","source":"# check for missing values\nprint(\"Check for Percent of missing values in Train dataset\")\nnull_check=train.isnull().sum()\n(null_check/len(train))*100","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"38fbe8bf-40f2-450a-b294-a77f0c7fd9f2","_kg_hide-input":true,"_uuid":"192f2d736cbbc08c8505e14f90144a6ca221448d","trusted":true},"cell_type":"code","source":"# check for missing values\nprint(\"Check for Percent of missing values in RESOURCES file\")\nnull_check=resources.isnull().sum()\n(null_check/len(resources))*100","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"b0056363-bb57-476e-b29a-97b459919427","_uuid":"c6639a9001ee0bfcb925837c9e28ab01bbdc92e3"},"cell_type":"markdown","source":"### Target Variable:\nThe target variable for this competition is a Binary variable which indicates if the project was **approved to be hosted on the site** or not.\n\nNote that this does not indicate if the project was **funded** or not! "},{"metadata":{"_cell_guid":"8fa83b8b-3a63-404b-9f99-72b1fbdc6c63","_kg_hide-input":true,"_uuid":"8b34694655f0daa013923eeb3a364c9dd6f99d0c","trusted":true},"cell_type":"code","source":"x=train.project_is_approved.value_counts()\n#plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.index, x.values, alpha=0.8)\nplt.title(\"Target Variable\",fontsize=20)\nplt.ylabel('# of Occurrences', fontsize=12)\nplt.xlabel('Project is approved?', fontsize=12)\n#adding the text labels\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n\nplt.show()\nprint(\"Approval rate:\",x[1]/(x[0]+x[1])*100)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"7306a6ae-b736-4d83-9023-84aebc6dcd3e","_kg_hide-input":true,"_uuid":"416fdec3b835e4a8c01b8f546ca17e7337b5be69"},"cell_type":"markdown","source":"\nDuring the training period, there is an impressive **84%** approval rate! \n\nThere are some null values in some fields, Project essays 3,4 and Resource description.\n\nAs per the data description, the Project essays 3,4 are just optional descriptive fields that the teachers can enter that became obsolete after a structural change. Hence, it is ok that we observe around 96.5% empty values.\n\nBut the null entries in the resources dataset is fishy. Let's explore more on that."},{"metadata":{"_cell_guid":"bcd92d24-b03c-4980-8790-2c232ec07dd3","_kg_hide-input":true,"_uuid":"89497b6439a983f2d53d41d6a25c356688ce788b","trusted":true},"cell_type":"code","source":"# take IDs of the projects which have null description\nprint(\"There are\",resources.description.isnull().sum(),\"NULL entries in description column of Resources dataset\")\nnull_ids=resources[resources.description.isnull()].id\nprint(\"Those Null entries are from\",len(null_ids.unique()),\"projects\")\nnull_entries_train=train[train.id.isin(null_ids)]\nprint(\"There are\",len(null_entries_train),\"of these projects are in train\")\nnull_entries_test=test[test.id.isin(null_ids)]\nprint(\"There are\",len(null_entries_test),\"of these projects are in test\")\nx=null_entries_train.project_is_approved.value_counts()\nprint(\"Approval rate of projects with NULL as the description under Resources:\",x[1]/(x[0]+x[1])*100)\nx=null_entries_train[null_entries_train.teacher_number_of_previously_posted_projects==0].project_is_approved.value_counts()\nprint(\"Approval rate of projects with NULL as the description under Resources and 0 previous project submissions:\",x[1]/(x[0]+x[1])*100)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"9fd02a3e-a20a-4995-b6ce-79cd91312643","_uuid":"c656dbac686a116a28cd253d14897dc66bf7779e"},"cell_type":"markdown","source":"There is a significant dip in approval rates (from 85% to 62%) if there is no description of the resources and if the project is the first submission by a teacher."},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"7cbf02f36bc52f0ff37d83a6040655da09d54f4d","_cell_guid":"9fac0fe9-731c-43ff-be39-66e041e1233a","trusted":true},"cell_type":"code","source":"# null_entries_train[null_entries_train.project_is_approved==0].head(2)\n# No obvious predictable pattern :(","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"819ccd3f-3b03-4442-92d3-1184c725f3a2","_uuid":"c8108d10f7ff6fc55be53e28d3053b201e1dfd2e","trusted":true},"cell_type":"code","source":"null_entries_train[null_entries_train.project_is_approved==0].project_resource_summary.iloc[0]","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"13fac155-2cd0-40d1-9b40-c214ebf1585b","_uuid":"f50d22319203cf557f789530dbec841ece6e2417","trusted":true},"cell_type":"code","source":"null_entries_train[null_entries_train.project_is_approved==0].project_resource_summary.iloc[1]","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"56252be6-aa73-430a-81a0-4eb7e9dadca0","_uuid":"53570095da233ce0e06cade56327b1135d13c2bf"},"cell_type":"markdown","source":"A lot of them seem to be **Art Supplies!? **. Is that supposed to mean something? Anyways, let's continue on...\n\n\n# Custom helper functions:\nCreating some functions here that would be used across multiple analysis.\n\n## Plotting functions:\nCreating a simple function to create two plots.\n* Frequency plot\n* Approval rate across the target column entries\n"},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"aa9e90f56191e4d68347606cdb1bd724b889b555","_cell_guid":"3acb8ea6-cd40-4f9d-8af8-3ee3facf943c","trusted":true},"cell_type":"code","source":"#making this for easy subsetting later\napprovals=train[train.project_is_approved==1]\nrejects=train[train.project_is_approved==0]\n\n# lets make a simple re-usable function to make the plots!\n# This lets us add more functionality if needed later and it would be replicated across all plots!\ndef make_custom_plot(target_column_name='',title='',total_counts=None,approvals_counts=None,rejects_counts=None,x_rotation_angle=0):\n    \"\"\"        \n    Description:\n        Creates a 1x2 plot of 1. the # of projects across the variable and the 2. A stacked Percentage bar chart of the Approval rates across the variable\n    Useage: 1) make_custom_plot('gender','Analyzing Gender')\n            2) make_custom_plot(total_counts=x,approvals_counts=x1,rejects_counts=x2)\n    \"\"\"\n    if(target_column_name!=''):\n        x=train[target_column_name].value_counts()\n        x1=approvals[target_column_name].value_counts()\n        x2=rejects[target_column_name].value_counts()\n    else:\n        x=total_counts\n        x1=approvals_counts\n        x2=rejects_counts\n        target_column_name=title\n    #plot initiate\n    plt.figure(figsize=(16,6))\n    \n    #super title\n    plt.suptitle(title,fontsize=18)\n    plt.subplot(121)\n    #title and labels for plot1\n    plt.title('Total Projects Submitted',fontsize=12)\n    plt.ylabel('# of Projects', fontsize=12)\n    plt.xlabel(target_column_name, fontsize=12)\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=x_rotation_angle)\n    # Barplot\n    ax= sns.barplot(x.index, x.values, alpha=0.8)\n\n    #adding the text labels\n    rects = ax.patches\n    labels = x.values\n    for rect, label in zip(rects, labels):\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n    \n    \n    plt.subplot(122)\n    #title and labels for plot2\n    plt.title('Approval Rate',fontsize=12)\n    plt.ylabel('Percent Approved Projects', fontsize=12)\n    plt.xlabel(target_column_name, fontsize=12)\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=x_rotation_angle)\n    # https://python-graph-gallery.com/13-percent-stacked-barplot/\n    r=np.arange(len(x))\n    totals=x\n    greenBars = [i / j * 100 for i,j in zip(x1, totals)]\n    redBars = [i / j * 100 for i,j in zip(x2, totals)]\n\n    barWidth = 0.85\n    names = x.index\n    # Create green Bars\n    plt.bar(r, greenBars, color='#b5ffb9', edgecolor='white', width=barWidth, label=\"Approved\")\n    # Create red Bars\n    plt.bar(r, redBars, bottom=greenBars, color='red', edgecolor='white', width=barWidth, label=\"Rejected\")\n    # Custom x axis\n    plt.xticks(r, names)\n    # Add a legend\n    plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n    plt.show()","execution_count":14,"outputs":[]},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"5fa9bd9494fe310acbc31c16e8ac76652f5286c5","_cell_guid":"d8b3f565-5c83-4bfc-8f55-0382e25068d5","trusted":true},"cell_type":"code","source":"# Adding another custom function with Error bars\n\ndef make_custom_plot2(target_column_name='',title='',total_counts=None,approvals_counts=None,rejects_counts=None,x_rotation_angle=0):\n    \"\"\"        \n    Description:\n        Creates a 1x2 plot of 1. the # of projects across the variable(stacked bar chart) and the 2. Error bar using Binomial confidence interval\n    Useage: 1) make_custom_plot('gender','Analyzing Gender')\n            2) make_custom_plot(total_counts=x,approvals_counts=x1,rejects_counts=x2)\n    \"\"\"\n    if(target_column_name!=''):\n        x=train[target_column_name].value_counts()\n        x1=approvals[target_column_name].value_counts()\n        x2=rejects[target_column_name].value_counts()\n    else:\n        x=total_counts\n        x1=approvals_counts\n        x2=rejects_counts\n        target_column_name=title\n    #plot initiate\n    plt.figure(figsize=(25,6))\n    \n    #super title\n    plt.suptitle(title,fontsize=18)\n    plt.subplot(121)\n    #title and labels for plot1\n    plt.title('Total Projects Submitted',fontsize=12)\n    plt.ylabel('# of Projects', fontsize=12)\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=x_rotation_angle)\n    # https://python-graph-gallery.com/13-percent-stacked-barplot/\n    r=np.arange(len(x))\n    totals=x\n    greenBars = x1\n    redBars = x2\n\n    barWidth = 0.85\n    names = x.index\n    # Create green Bars\n    plt.bar(r, greenBars, color='#9AFF87', width=barWidth, label=\"Approved\")\n    # Create red Bars\n    plt.bar(r, redBars, bottom=greenBars, color='#60B350',width=barWidth, label=\"Rejected\")\n    # Custom x axis\n    plt.xticks(r, names)\n    # Add a legend\n    plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n    \n    plt.subplot(122)\n    #title and labels for plot2\n    plt.title('Approval Rate(with Binomial Confidence intervals)',fontsize=12)\n    plt.ylabel('Percent Approved Projects', fontsize=12)\n    plt.xlabel(target_column_name, fontsize=12)\n    locs, labels = plt.xticks()\n    plt.setp(labels, rotation=x_rotation_angle)\n    # https://python-graph-gallery.com/13-percent-stacked-barplot/\n    top_list=[]\n    bot_list=[]\n    for n_total,n_approved in zip(x,x1):\n        top_val,bot_val = proportion_confint(count=n_approved,nobs=n_total,alpha=0.05,method='normal')\n        top_list.append(top_val)\n        bot_list.append(bot_val)\n    plt.errorbar(x=x.index, \n             y=x1/x, \n             yerr=[(top-bot)/2 for top,bot in zip(top_list,bot_list)],\n             fmt='o',mfc='red',\n             mec='green',mew=2,ms=5,capsize =10)\n    plt.hlines(xmin=0, xmax=len(x)-1,\n           y=x1.sum()/x.sum(), \n           linewidth=1.0,\n           color=\"green\")\n    plt.show()\n","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"8506eed7-9ec5-46af-a093-5351cc58cfbe","_uuid":"86c679ed6c768e7f45f5ce7aabf5a7450770100a"},"cell_type":"markdown","source":"## Text Functions:\nCreating custom functions to be used in the various text fields in the dataset.\n### Extract text stats:\nThis function does the following\n* Gets basic text statistics (Word count, Unique word count) from the text column\n* Plot Violin plot(Extension of box plot) across Project approval for the computed variables\n* Create a KDE plot for unique word percent\n"},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"c9994f1f597335aa1ee57edaf192513a80aa06aa","_cell_guid":"c3d020c1-1012-4f54-9699-d7811b45974f","trusted":true},"cell_type":"code","source":"# Making a function instead of writing code for single text columns so that its more scalable and can be applied to all text cols\ndef get_text_stats(text_col):\n    \"\"\"\n    Get Wordcount,Unique Wordcount and WordCount Percent and make appropriate visuals\n    Todo: Add more text stats\n    \"\"\"\n    title=\"Text Stats of \" + text_col\n    target_col='project_is_approved'\n    # Borrowed from previous work at https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda\n    text_stats=pd.DataFrame()\n    text_stats[target_col]=train[target_col]\n    #Word count \n    text_stats['word_count']=train[text_col].apply(lambda x: len(str(x).split()))\n    #Unique word \n    text_stats['count_unique_word']=train[text_col].apply(lambda x: len(set(str(x).split())))\n    #Word count percent in each comment:\n    text_stats['word_unique_percent']=(text_stats['count_unique_word']*100)/text_stats['word_count']\n    \n    temp_df = pd.melt(text_stats, value_vars=['word_count', 'count_unique_word'], id_vars=target_col)\n    \n    print(\"------ Sample from an Approved project ------\\n\")\n    print(approvals[text_col].iloc[0])\n    \n    print(\"\\n------ Sample from a Rejected project ------\\n\")\n    print(rejects[text_col].iloc[0])\n    # Need to make this pythonic\n    #get_binCI <- function(x,n) as.list(setNames(binom.test(x,n)$conf.int, c(\"lwr\", \"upr\")))\n\n    \n    #plotting\n    plt.figure(figsize=(16,5))\n    plt.subplot(121)\n    plt.suptitle(title,fontsize=16)\n    #re-shaping as required\n    plt.title(\"Word Count\")\n    sns.violinplot(x='variable', y='value', hue=str(target_col), data=temp_df,inner='quartile')\n    plt.ylabel('# of projects', fontsize=12)\n    \n    plt.subplot(122)\n    plt.title(\"Percentage of Unique words - effect on Approval\")\n    ax=sns.kdeplot(text_stats[text_stats.project_is_approved == 0].word_unique_percent, label=\"Not Approved\",shade=True,color='r')\n    ax=sns.kdeplot(text_stats[text_stats.project_is_approved == 1].word_unique_percent, label=\"Approved\")\n    plt.legend()\n    plt.xlabel('Percent unique words', fontsize=12)\n    plt.ylabel('# of projects', fontsize=12)\n    plt.show()","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"8a8264ff-df93-45b4-8aa6-7e1993ad1aa1","_uuid":"25506a0a6e787d7af1fc750e48264f9f23e47ede"},"cell_type":"markdown","source":"### Make Wordclouds:\nA simple function that takes in a text column/field and makes separate word-clouds for approved and rejected projects.\n\n### Simple wordclouds are so boring!!!! Function now has the masked version."},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"0cc7351d2cb532346f2cc93fce3ca5770a509126","_cell_guid":"57ad1a12-99c6-4064-8305-94a90c4e672d","trusted":true},"cell_type":"code","source":"# for the wordcloud\nstopword=set(STOPWORDS)\n\n# Custom Adding some stop words to make better and more meaningful wordclouds\nstopword.add('will')\nstopword.add('student')\nstopword.add('students')\nstopword.add('class')\nstopword.add('classroom')\nstopword.add('child')\nstopword.add('children')\nstopword.add('teacher')\nstopword.add('school')\nstopword.add('needs')\n\ndef make_word_clouds(text_col,approved_mask,rejected_mask,title_overall):\n    \"\"\"\n    Makes two wordclouds : one for Approvals and one for rejects\n    \n    Todo: Think of faceted clouds across categorical var (Eg:Grade category)\n    \"\"\"\n    plt.figure(figsize=(16,8))\n    plt.suptitle(title_overall,fontsize=20)\n    plt.subplot(121)\n    # Get text col from approvals subset\n    text=approvals[text_col].values\n    # make wordcloud\n    wc= WordCloud(background_color=\"white\",max_words=1000,stopwords=stopword,mask=approved_mask,normalize_plurals=True)\n    wc.generate(\" \".join(text))\n\n    plt.axis(\"off\")\n    plt.title(\"Words frequented in Approved Projects\", fontsize=16)\n    #https://matplotlib.org/examples/color/colormaps_reference.html for colormaps\n    plt.imshow(wc.recolor(colormap='inferno',random_state=17), alpha=0.98,interpolation='bilinear')\n    \n    plt.subplot(122)\n    # Get text col from Rejects subset\n    text=rejects[text_col].values\n\n    # make wordcloud\n    wc= WordCloud(background_color=\"black\",max_words=1000,stopwords=stopword,mask=rejected_mask,normalize_plurals=True)\n    wc.generate(\" \".join(text))\n    \n    plt.axis(\"off\")\n    plt.title(\"Words frequented in Rejected Projects\", fontsize=16)\n    plt.imshow(wc.recolor(colormap='Pastel1',random_state=17), alpha=0.98,interpolation='bilinear')\n    plt.show()","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"1d7fc0d5-8000-403a-b273-1bffee597a87","collapsed":true,"_uuid":"216c7844cf0d2e412e7531c9158358b5149cef0e"},"cell_type":"markdown","source":"# Individual Feature's impact on Approval:\n\nLet's explore the impact of our descriptive features on Project approval rates.\n\n## 1) Teacher-prefix:\nThis variable gives information of the title of the teacher submitting the request. \n\nAlso, indirectly we can infer the gender from this variable."},{"metadata":{"_cell_guid":"6c53f1dc-6640-4e74-bfd4-dbe5824a5f0a","_uuid":"46f8f8eaa4c9db6c49353d62e74074f29b04ccc5","trusted":true},"cell_type":"code","source":"make_custom_plot2('teacher_prefix','Does a Title affect approval?')","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"c6a6e611-3ee2-417d-bbbe-c11497b5e0c7","_uuid":"994cba037de3d05c1a4a32db9126cbfd1cc97368"},"cell_type":"markdown","source":"The results for Dr are not reliable as they do not have enough entries. This is quite evident from the huge error bars they have in the binomial confidence interval.\n\nThe line depits the overall mean approval rate.\n\n\n### 2) Gender:\nThis is a created field from the teacher prefix field. The mapping is as follows,\n* Mrs, Ms --> Female\n* Mr. --> Male\n* Teacher,Dr --> Unknown"},{"metadata":{"_cell_guid":"aee5cbe1-7d09-4273-bcdf-711b18622e94","_uuid":"db188e2635517ca558eeccb9a9010f61025febd8","trusted":true},"cell_type":"code","source":"# Creating the gender column\ngender_mapping = {\"Ms.\": \"Female\", \"Mrs.\":\"Female\", \"Mr.\":\"Male\", \"Teacher\":\"Unknown\", \"Dr.\":\"Unknown\", np.nan:\"Unknown\"  }\ntrain[\"gender\"] = train.teacher_prefix.map(gender_mapping)\napprovals[\"gender\"] = approvals.teacher_prefix.map(gender_mapping)\nrejects[\"gender\"] = rejects.teacher_prefix.map(gender_mapping)\ntest['gender'] = test.teacher_prefix.map(gender_mapping)\nmake_custom_plot('gender','Analyzing Gender')","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"4f5f515c-8ec0-407e-b552-b6f08da8109d","_uuid":"926175cbe3b4b9fae4cbe5c1c215bafb5abda5a3"},"cell_type":"markdown","source":"Unsurprisingly, there are more Female teachers. But that does not affect/bias the Approval rate at all.\n\n### 3) Project Grade Category:\nThis variable shows us the class/grade of the students that would benefit from the donation!\n"},{"metadata":{"_cell_guid":"18992042-8e91-412a-8eec-9fc58922b5dd","_kg_hide-input":true,"_uuid":"aa17e4b924c602002ee7c03ea0361fb60685f356","trusted":true},"cell_type":"code","source":"make_custom_plot2('project_grade_category','Do smaller kids get more approval rates?')","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"a7ee09f5-aff2-42ec-9228-fbfd47a50f3a","_uuid":"dee9b62b6abb5d8f28586c6a8afebca545497dfa"},"cell_type":"markdown","source":"While Smaller kids seem to get more projects, more projects seem to be approved for the 3-5 Grade projects.\n\n## 4) Subject Category:\nThis field shows us the Subject category/categories that this project aims to help at. Note that sometimes, there are multiple subject categories tagged to one project."},{"metadata":{"_cell_guid":"7f95948b-653d-49e2-bccd-b35c8a257cc0","_kg_hide-input":true,"_uuid":"b689384aaacbda3f8a88f042d3ac862dcf949d98","trusted":true},"cell_type":"code","source":"x= train.project_subject_categories.value_counts()\n#prep for chart\nx=x.sort_values(ascending=False)\nx=x.iloc[0:20]\n\n#chart\nplt.figure(figsize=(16,4))\nax = sns.barplot(x.index, x.values, alpha=0.8,color=color[0])\nplt.title(\"What are the frequent subject categories?\",fontsize=16)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=80)\nplt.ylabel('# Projects', fontsize=12)\nplt.xlabel('Subject Category', fontsize=12)\n\n#adding the text labels\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n\nplt.show()\nprint(\"There are \",len(train.project_subject_categories.unique()),\"unique Subject Categories\")","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"927cc573-5599-46c5-bcc0-4853cc7c8c52","_uuid":"edf9aa15542add7cc869ea4fe856f2da9807a637"},"cell_type":"markdown","source":" The subject categories can be cleaned a bit further.\n \n For example, the third most popular category can be broken down into 1)\"Literacy & language\", 2)\"Math & science\" separately"},{"metadata":{"_cell_guid":"fd82b246-359c-47c2-87bc-fd0af1265025","_kg_hide-input":true,"_uuid":"7f1621f3f5a67f13c4d9f2a5c89a4793f08765e0","trusted":true},"cell_type":"code","source":"# Grouping similar categories for overall\nsubject_cats=','.join(train['project_subject_categories'])\ncats=pd.DataFrame(subject_cats.split(','),columns=['project_subject_categories']) # to split on \",\"\ncats.project_subject_categories=cats.project_subject_categories.str.strip() # to remove unwanted spaces\nx=cats.project_subject_categories.value_counts()\nprint(\"There are\",len(x),\"different subject categories after cleaning\")\n\n# repeat for approved group and rejected group\n# Grouping similar categories for approved \nsubject_cats=','.join(approvals['project_subject_categories'])\ncats=pd.DataFrame(subject_cats.split(','),columns=['project_subject_categories']) # to split on \",\"\ncats.project_subject_categories=cats.project_subject_categories.str.strip() # to remove unwanted spaces\nx1=cats.project_subject_categories.value_counts()\n\n# Grouping similar categories for rejected\nsubject_cats=','.join(rejects['project_subject_categories'])\ncats=pd.DataFrame(subject_cats.split(','),columns=['project_subject_categories']) # to split on \",\"\ncats.project_subject_categories=cats.project_subject_categories.str.strip() # to remove unwanted spaces\nx2=cats.project_subject_categories.value_counts()\n","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"f198e034-1cad-41d1-a02a-dfc8736ff27e","_uuid":"fbd3881632732873dea6c337c8d0062b0f9466c2","trusted":true},"cell_type":"code","source":"make_custom_plot2(title='Subject Category',total_counts=x,approvals_counts=x1,rejects_counts=x2,x_rotation_angle=80)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"ac4b54a6-dc91-4b8c-9979-1debe0944f8e","_uuid":"3b1ff8ef1a6746b6b7c4c61277da0e881d802e77"},"cell_type":"markdown","source":"Literature/Language supplies seem to be in high demand. I guess books would fall into this category.\n\nCare and hunger , Warmth seem to be a more frequently approved.\n\n## 5) Project Sub-Category:\nPerforming a similar analysis for the project sub-category."},{"metadata":{"_cell_guid":"773a7a56-f416-452a-9e55-17a1f3ec3e66","_uuid":"105df86992f83a8427920e52ca574d07c998d478","trusted":true},"cell_type":"code","source":"x= train.project_subject_subcategories.value_counts()\n#prep for chart\nx=x.sort_values(ascending=False)\nx=x.iloc[0:20]\n\n#chart\nplt.figure(figsize=(16,4))\nax = sns.barplot(x.index, x.values, alpha=0.8,color=color[0])\nplt.title(\"What are the frequent subject sub categories?\",fontsize=16)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=80)\nplt.ylabel('# Projects', fontsize=12)\nplt.xlabel('Subject sub-Category', fontsize=12)\n\n#adding the text labels\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n\nplt.show()\nprint(\"There are\",len(train.project_subject_subcategories.unique()),\"unique Subject Categories\")","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"479866a9-9787-4243-a202-ce60fc6fa807","_kg_hide-input":true,"_uuid":"7cc59338b798903989671b4539c2b7435d7704ce","trusted":true},"cell_type":"code","source":"# Grouping similar categories for overall\nsubject_cats=','.join(train['project_subject_subcategories'])\ncats=pd.DataFrame(subject_cats.split(','),columns=['project_subject_subcategories']) # to split on \",\"\ncats.project_subject_subcategories=cats.project_subject_subcategories.str.strip() # to remove unwanted spaces\nx=cats.project_subject_subcategories.value_counts()\nprint(\"There are \",len(x),\" different subject sub-categories after Cleaning\")\nprint(\"They are:- \",x.index.values)\n# repeat for approved group and rejected group\n# Grouping similar categories for approved \nsubject_cats=','.join(approvals['project_subject_subcategories'])\ncats=pd.DataFrame(subject_cats.split(','),columns=['project_subject_subcategories']) # to split on \",\"\ncats.project_subject_subcategories=cats.project_subject_subcategories.str.strip() # to remove unwanted spaces\nx1=cats.project_subject_subcategories.value_counts()\n\n# Grouping similar categories for rejected\nsubject_cats=','.join(rejects['project_subject_subcategories'])\ncats=pd.DataFrame(subject_cats.split(','),columns=['project_subject_subcategories']) # to split on \",\"\ncats.project_subject_subcategories=cats.project_subject_subcategories.str.strip() # to remove unwanted spaces\nx2=cats.project_subject_subcategories.value_counts()","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"d584122a-14fa-4f73-b63c-9d9a2486a659","_uuid":"4699462e5d00b90b8e2e5f22081e2b775bc2903e","trusted":true},"cell_type":"code","source":"# Plotting top 8 to avoid clutter\nmake_custom_plot2(title='Subject Sub-Category(Top-8)',total_counts=x.iloc[0:8],approvals_counts=x1.iloc[0:8],rejects_counts=x2.iloc[0:8],x_rotation_angle=80)","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"8ca64411-5c93-4aa8-9bcb-59b6cc8f715e","_uuid":"0ab2cee2dd369ffea2335cf2740afdb74a75de39","trusted":true},"cell_type":"code","source":"end_preprocess=time.time()\nprint(\"Time till sub-category:\",end_preprocess-start_time,\"s\")","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"7d07c6a7-db67-4601-83c1-2c743ee3d7ea","_uuid":"6e8fe20a2acaa496a6a1e25f510a645ddcbceb00"},"cell_type":"markdown","source":"# States:\n\nLets find out if the location has any impact on approval.\n\nFirst, lets create a state level summary containing the following metrics.\n* Total projects per state\n* Total approved projects per state\n* Total number of teachers in the state (who applied in Donorchoose)\n* Number of projects per teacher\n* Approval rate\n\nThen , we plot them on an interactive map using Plotly. "},{"metadata":{"_cell_guid":"00b40392-3b9f-4983-bb45-5aed9cf485e7","_kg_hide-input":true,"_uuid":"2c66ecd634e402a4c07693a7e64721aadeb6155e","trusted":true},"cell_type":"code","source":"state_vals=train.groupby(['school_state'])['project_is_approved','teacher_id'].agg(\n    {'project_is_approved':['sum','count'],'teacher_id':['nunique']}).reset_index()\nstate_vals.columns=['state','approved','total','teacher_count']\nstate_vals['approval_perc']=(state_vals.approved*100)/state_vals.total\nstate_vals['proj_per_teacher']=(state_vals.total)/state_vals.teacher_count\nstate_vals=state_vals.round(2)\nprint(\"Top States\")\nstate_vals.sort_values('total',ascending=False).head()","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"594d7d56-dea0-4a84-aa43-e33a4b5e1f0f","_kg_hide-input":true,"_uuid":"b1aa32a0b4988f3f5022f33cf05f12a13d162469","trusted":true},"cell_type":"code","source":"import plotly.offline as py\npy.init_notebook_mode(connected=True)\n\n\nstate_vals['text'] = 'Approved Projects: '+state_vals['approved'].astype(str)+ '<br>'+'Total Projects:'+state_vals['total'].astype(str)+'<br>'+\\\n    'Total Teachers:'+state_vals['teacher_count'].astype(str)+ '<br>'+'# projects per teacher:' +state_vals['proj_per_teacher'].astype(str)+'<br>'+\\\n    'Approval Rate: '+state_vals['approval_perc'].astype(str)\nscl = [[0.0, 'rgb(0,39,143)'],[0.2, 'rgb(0,107,177)'],[0.4, 'rgb(0,154,200)'],\\\n            [0.6, 'rgb(0,189,220)'],[0.8, 'rgb(0,218,235)'],[1.0, 'rgb(0,240,247)']]\n\n\ndata = [ dict(\n        type='choropleth',\n        colorscale = scl,\n        autocolorscale = False,\n        locations = state_vals['state'],\n        z = state_vals['approval_perc'],\n        locationmode = 'USA-states',\n        text = state_vals['text'],\n        marker = dict(\n            line = dict (\n                color = 'rgb(0,200,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Approval Percentage\")\n        ) ]\n\nlayout = dict(\n        title = 'State wide Approval Analysis <br>(Hover for breakdown)',\n        geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\n    \nfig = dict( data=data, layout=layout )\npy.iplot( fig, validate=False,filename='d3-cloropleth-map' )","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"452a303d-78b0-42fb-9c72-0f8e14d851e3","_uuid":"f3ea5e063733ccde43b88f1d6a7708f294512189"},"cell_type":"markdown","source":"The above plot is **Interactive**.\n\nHover over the states to get the individual numbers of that state.\n\n\n# Time:\n\n"},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"baac54fdc9849ebef33398c34c731e81872d5417","_cell_guid":"f90ae214-b583-4312-b989-d11d25a909a6","trusted":true},"cell_type":"code","source":"approvals['project_submitted_datetime'] = pd.to_datetime(approvals['project_submitted_datetime'])\napprovals['datetime_dow'] = approvals['project_submitted_datetime'].dt.dayofweek\napprovals['datetime_year'] = approvals['project_submitted_datetime'].dt.year\napprovals['datetime_month'] = approvals['project_submitted_datetime'].dt.month\napprovals['datetime_hour'] = approvals['project_submitted_datetime'].dt.hour\napprovals['datetime_day'] = approvals['project_submitted_datetime'].dt.day\napprovals['datetime_date'] = approvals['project_submitted_datetime'].dt.date\n\nrejects['project_submitted_datetime'] = pd.to_datetime(rejects['project_submitted_datetime'])\nrejects['datetime_dow'] = rejects['project_submitted_datetime'].dt.dayofweek\nrejects['datetime_year'] = rejects['project_submitted_datetime'].dt.year\nrejects['datetime_month'] = rejects['project_submitted_datetime'].dt.month\nrejects['datetime_hour'] = rejects['project_submitted_datetime'].dt.hour\nrejects['datetime_day'] = rejects['project_submitted_datetime'].dt.day\nrejects['datetime_date'] = rejects['project_submitted_datetime'].dt.date\napp_date=approvals.groupby('datetime_date')['datetime_date'].count()\nrej_date=rejects.groupby('datetime_date')['datetime_date'].count()","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"85bf3249-eabc-4b1c-a3d4-ca673555ca65","_kg_hide-input":true,"_uuid":"9fe0fabc6c1d1dc9cf9d89d2cee532f98c7b7123","trusted":true},"cell_type":"code","source":"import plotly.plotly as py\nfrom plotly.offline import plot, iplot, init_notebook_mode\n\nimport plotly.graph_objs as go\n# Make plotly work with Jupyter notebook\ninit_notebook_mode()\napproved = go.Scatter(\n    x=app_date.index,\n    y=app_date.values,\n    name = \"# of Approved Projects\",\n    line = dict(color = '#17BECF'),\n    opacity = 0.8)\n\nrejected = go.Scatter(\n    x=rej_date.index,\n    y=rej_date.values,\n    name = \"# of Rejected Projects\",\n    line = dict(color = '#7F7F7F'),\n    opacity = 0.8)\n\ndata = [approved,rejected]\n\nlayout = dict(\n    title='Approved and Rejected projects over Time(with Rangeslider)',\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=14,\n                     label='2w',\n                     step='day',\n                     stepmode='backward'),\n                dict(count=7,\n                     label='1w',\n                     step='day',\n                     stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(),\n        type='date'\n    )\n)\n\nfig = dict(data=data, layout=layout)\niplot(fig, validate=False,filename = \"Approval with Rangeslider\")","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"227e96e1-eac3-4aef-a874-f7e4724afef2","_uuid":"58cf61cfbc3aca3c16a1765777eb8c84bffcd77a"},"cell_type":"markdown","source":"The abpve plot is interactive too! Hover over to see the value of that particular date. Also you can zoom in , and play around with specific time-frames using the \"Range Slider\" in the bottom!\n\nNow, lets further look into the effect of months in the approval."},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"87c6c9898044c6dee1366f4cb42a944f7b405b05","_cell_guid":"2dc0d5eb-1be0-4790-ad82-77da7af5276e","trusted":true},"cell_type":"code","source":"df=approvals.groupby(['datetime_day','datetime_month'])['project_is_approved'].sum()\ndf=df.reset_index()\ndf=df.pivot(index='datetime_day',columns='datetime_month')[['project_is_approved']]\ndf.columns = df.columns.droplevel()\ndf=df.reset_index()","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"cce17190-7d6f-4016-bbc7-679fa2ac3cdf","_kg_hide-input":true,"_uuid":"f4428fe04b294fd43d9992afc763c4d40ae44919","trusted":true},"cell_type":"code","source":"# import calender\ndf.columns = ['x','January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'] \n# Initialize the figure\nplt.style.use('seaborn-darkgrid')\n# create a color palette\npalette = plt.get_cmap('Set1')\nplt.figure(figsize=(15,10))\n\ngridspec.GridSpec(4,3) \nplt.subplots_adjust(hspace=0.4)\n# multiple line plot\nnum=0\nfor column in df.drop('x', axis=1):\n    num+=1\n     # Find the right spot on the plot\n    plt.subplot(4,3, num)\n     # plot every groups, but discreet\n    for v in df.drop('x', axis=1):\n        plt.plot(df['x'], df[v], marker='', color='grey', linewidth=0.6, alpha=0.3)\n     # Plot the lineplot\n    plt.plot(df['x'], df[column], marker='', color=palette(num), linewidth=3.2, alpha=0.9, label=column)\n     # Same limits for everybody!\n    plt.xlim(0,32)\n    plt.ylim(-2,2000)\n     # Not ticks everywhere\n    if num in range(10) :\n        plt.tick_params(labelbottom='off')\n    if num not in [1,4,7,10] :\n        plt.tick_params(labelleft='off')\n     # Add title\n    plt.title(column, loc='left', fontsize=12, fontweight=0, color=palette(num) )\n# general title\nplt.suptitle(\"# of Approvals - Variation Across Months\", fontsize=20, fontweight=0, color='black', style='italic', y=1.02)\n \nplt.show()","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"bb10007c-666d-48ee-951f-86603fb67cda","_uuid":"ba48bebcf1b3983959ecb601e55460006bd1d982"},"cell_type":"markdown","source":"There seem to be bursts of activity which I think corresponds with the Back to School dates.\n\n\n# Text Fields:\n\n\n## Title:\n\nA short title of the project given by the teacher.\n\nThere are a lot of creative and funny titles in the list. Lets explore some of the most successful ones!"},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"be0ebc7fed562ba6e308d71ecf7985c1bc938945","_cell_guid":"f01e392f-40f7-4baf-8842-4c3787147efc","trusted":true},"cell_type":"code","source":"text_col='project_title'\ntarget_col='project_is_approved'\n# Borrowed from previous work at https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda\ntext_stats=pd.DataFrame()\ntext_stats[target_col]=train[target_col]\n#Word count \ntext_stats['word_count']=train[text_col].apply(lambda x: len(str(x).split()))\n#Unique word \ntext_stats['count_unique_word']=train[text_col].apply(lambda x: len(set(str(x).split())))\n# text_stats.groupby('project_is_approved').mean()","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"c024959f-bb2b-43de-8040-d2e23ec21d22","_uuid":"6488855039941f6e69beb39c7ef15034003abea6","trusted":true},"cell_type":"code","source":"temp=train.groupby('project_title')['project_is_approved'].agg(['sum','count'])\ntemp['approval_rate']=(temp['sum']*100)/temp['count']\ntemp.columns=['# of projects approved','# of total projects','Approval rate']\ntemp=temp.sort_values(by='# of total projects',ascending=False)\ntemp=temp.iloc[0:20]\ntemp","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"0bfca6fe-d557-4c1e-a867-73f915c0aac0","_uuid":"6b32da06a093f8f14388cda457471dc1beda034b"},"cell_type":"markdown","source":"Looks like **Wiggle while you work!** is a really famous phrase on the platform. It's having several entries with minor changes. \n\n#### Also, the Approval rates are impressive **~91%** for projects with that title.\n\nNow, lets visualize the words commonly occuring in approved and rejected titles. \n\nGetting some image masks for the word clouds to make it more visually appealing!!"},{"metadata":{"_cell_guid":"4aa4aaba-eb09-403f-8983-958636f61ff7","_uuid":"bb919ee8df34682d7b56b882c0a909fe8382ae37","trusted":true},"cell_type":"code","source":"approved_mask=np.array(Image.open(\"../input/imagesfordonorchoose/1_approve_heart.png\"))\nrejected_mask=np.array(Image.open(\"../input/imagesfordonorchoose/2_reject_heart.png\"))\n# simple invert mask              # This is done to fill the words within the shape and not outside it\napproved_mask=~approved_mask[:,:,1]\nrejected_mask=~rejected_mask[:,:,1]\nmake_word_clouds('project_title',approved_mask,rejected_mask,\"What does a good title contain?\")","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"1b72ff1f-f34b-424d-8da8-4bd8b7471f5f","_uuid":"10bb91cfef1775b322711795b94df5b2be4f363d"},"cell_type":"markdown","source":"Beautiful! ** Learning Technology** seems to be a re-occuring theme!\n\n# Project Essays:\n\nOn May 17th, 2016, the DonorsChoose.org application switched from having 4 essay prompts to just 2 prompts, so from that point forward, only project_essay_1 and project_essay_2 contain text, and project_essay_3 and project_essay_4 have NaNs.\n\nHere's a summary of the essay prompts before and after that date.\n\n**Before May 17th, 2016:**\n\n* project_essay_1: \"Introduce us to your classroom\"\n* project_essay_2: \"Tell us more about your students\"\n* project_essay_3: \"Describe how your students will use the materials you're requesting\"\n* project_essay_4: \"Close by sharing why your project will make a difference\"\n\n**May 17th, 2016 and beyond: **\n\n* project_essay_1: \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"\n* project_essay_2: \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"\n\n\nAs @HeadsorTails explains in this [discussion post](https://www.kaggle.com/c/donorschoose-application-screening/discussion/51352#292941), performing the following changes to clean up the NaNs.\n* Combine essay_1 and essay_2 before May 17th to make \"student_description\" and use essay_1 after May 17th directly\n* Combine essay_3 and essay_4 before May 17th to make \"project_description\" and use essay_2 after May 17th directly\n"},{"metadata":{"_cell_guid":"6bfe831e-cc9e-41e3-bd3d-71507e540a7d","_uuid":"9a5c893667de0b9595cf12633bbe7b0e89b91a68","trusted":true},"cell_type":"code","source":"# Before performing changes , simple check\nx=train[train.project_essay_3.notnull()]\nprint(\"The last time an entry occured in Project essay 3 -- \",x['project_submitted_datetime'].max())","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"078371bc-f839-40b8-810b-caf759cace16","collapsed":true,"_uuid":"36514e53f1a3a52e6e40ea780fe12d83d631a10a","trusted":true},"cell_type":"code","source":"# Making the First essay column :student_description\ntrain['student_description']=train['project_essay_1']\n#performing the adjustment\n# df.loc[selection criteria, columns I want] = value\ntrain.loc[train.project_essay_3.notnull(),'student_description']=train.loc[train.project_essay_3.notnull(),'project_essay_1']+train.loc[train.project_essay_3.notnull(),'project_essay_2']\n#repeat for test dataset\ntest['student_description']=test['project_essay_1']\ntest.loc[test.project_essay_3.notnull(),'student_description']=test.loc[test.project_essay_3.notnull(),'project_essay_1']+test.loc[test.project_essay_3.notnull(),'project_essay_2']","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"02695448-2ab0-4ab7-9e9b-e69d7bc25ac1","_uuid":"6c310ebed44c0df6871e69094c5508bdf45fded8","trusted":true},"cell_type":"code","source":"# Making the second essay column : project_description\ntrain['project_description']=train['project_essay_2']\n#performing the adjustmen\n# df.loc[selection criteria, columns I want] = value\ntrain.loc[train.project_essay_3.notnull(),'project_description']=train.loc[train.project_essay_3.notnull(),'project_essay_3']+train.loc[train.project_essay_3.notnull(),'project_essay_4']\ntest['project_description']=test['project_essay_2']\ntest.loc[test.project_essay_3.notnull(),'project_description']=test.loc[test.project_essay_3.notnull(),'project_essay_3']+test.loc[test.project_essay_3.notnull(),'project_essay_4']\n# check\ntest[test.project_essay_3.notnull()].head(1).project_description.values","execution_count":39,"outputs":[]},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"2d068d41f073f189156c130c7025502e4067e3ff","_cell_guid":"27bdcf1f-ed8f-4eea-8b5a-9d62b3f106a3","trusted":true},"cell_type":"code","source":"#remove unwanted colunms\ndel(train['project_essay_1'])\ndel(train['project_essay_2'])\ndel(train['project_essay_3'])\ndel(train['project_essay_4'])\ndel(test['project_essay_1'])\ndel(test['project_essay_2'])\ndel(test['project_essay_3'])\ndel(test['project_essay_4'])\n\n#update the subsets\napprovals=train[train.project_is_approved==1]\nrejects=train[train.project_is_approved==0]","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"dbcc8b59-c3ca-4b11-9fdc-e0d3a6d9e168","_uuid":"62f6e79258dffcc6579a3a04e5cc4ca2a60c68d2"},"cell_type":"markdown","source":"## Student Description (Project essay 1):\n\n\"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"\n\nNote: The data has been altered to account for the change at May 17th, 2016."},{"metadata":{"_cell_guid":"80465467-823e-4803-99c7-26bc3bef4681","_uuid":"2275338dc060503c3a59646b4867e8dfcca16123","trusted":true},"cell_type":"code","source":"get_text_stats(text_col='student_description')","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"d86acbae-76e8-4055-867d-98cbe9f1d9b7","_uuid":"d6043acfcad5d14390122553b0379199312a8bf2"},"cell_type":"markdown","source":"Almost Identical plots across project approval in both word count and unique word count! Looks like they won't be much use here. "},{"metadata":{"_cell_guid":"8c26c310-1393-4e61-9e14-22bc684af12d","_uuid":"06abbbb63346c392d2698083caefa11d5fd9e122","trusted":true},"cell_type":"code","source":"rejected_mask=np.array(Image.open(\"../input/imagesfordonorchoose/1_approve_hand.png\"))\napproved_mask=np.array(Image.open(\"../input/imagesfordonorchoose/2_reject_hand.png\"))\n# simple invert mask\napproved_mask=~approved_mask[:,:,1]\nrejected_mask=~rejected_mask[:,:,1]\nmake_word_clouds('student_description',approved_mask,rejected_mask,\"How are Students described in Approved VS Rejected projects?\")","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"de7ad12e-02ef-40da-8487-b9a43d7f1808","_uuid":"a83fe08536d6c472b464f7a5a99a08fcccb15336"},"cell_type":"markdown","source":"## Project Description (Project essay 2):\n\"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"\n\nNote: The data has been altered to account for the change at May 17th, 2016."},{"metadata":{"_cell_guid":"94827ea2-ae50-474a-9f2f-70981f108521","_uuid":"7033a8cbdb68462778ee97b1d73ed2ae075c4920","trusted":true},"cell_type":"code","source":"get_text_stats(text_col='project_description')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5c6c6bef-1734-4160-925b-1cb06022de79","_uuid":"78caeb8e51f0cc0d96b3863ff63e8fbcc6601d21","trusted":true,"collapsed":true},"cell_type":"code","source":"approved_mask=np.array(Image.open(\"../input/imagesfordonorchoose/1_approve_tick.png\"))\nrejected_mask=np.array(Image.open(\"../input/imagesfordonorchoose/2_reject_tick.png\"))\n# simple invert mask\napproved_mask=~approved_mask[:,:,1]\nrejected_mask=~rejected_mask[:,:,1]\nmake_word_clouds('project_description',approved_mask,rejected_mask,\"How are Projects described in Approved VS Rejected projects?\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eeb13982-0853-4b41-8523-416bac3b8d23","_uuid":"8a5a57b5caaea9d9e70bd281fd3f9fef45f0ac32"},"cell_type":"markdown","source":"## Project resource summary:\nThis variable contains a short summary of the resources needed for the project."},{"metadata":{"_cell_guid":"06d953e1-a5ff-41da-94f6-25c9df54e393","_uuid":"2fdae6b8d3847f5be356c3f4d768f379f0ab0586","trusted":true,"collapsed":true},"cell_type":"code","source":"get_text_stats('project_resource_summary')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"707d318b-bdef-4bd2-bf18-a80fa78177e6","_kg_hide-input":true,"_uuid":"15494c74bfb5b4d1aa5fa6cfc0f167f4afc8a028","trusted":true,"collapsed":true},"cell_type":"code","source":"grade_mask_1=np.array(Image.open(\"../input/imagesfordonorchoose/grade1.png\"))\ngrade_mask_2=np.array(Image.open(\"../input/imagesfordonorchoose/grade2.png\"))\ngrade_mask_3=np.array(Image.open(\"../input/imagesfordonorchoose/grade3.png\"))\ngrade_mask_4=np.array(Image.open(\"../input/imagesfordonorchoose/grade4.png\"))\n\n# simple invert mask\ngrade_mask_1=~grade_mask_1[:,:,1]\ngrade_mask_2=~grade_mask_2[:,:,1]\ngrade_mask_3=~grade_mask_3[:,:,1]\ngrade_mask_4=~grade_mask_4[:,:,1]\n\nplt.figure(figsize=(16,12))\nplt.suptitle(\"Do different grades request for different Items?\", fontsize=20)\nplt.subplot(221)\ntext=train[train.project_grade_category=='Grades PreK-2'].project_resource_summary\nwc= WordCloud(background_color=\"white\",max_words=7000,stopwords=stopword,mask=grade_mask_1,normalize_plurals=True)\nwc.generate(\" \".join(text))\nplt.axis(\"off\")\nplt.title(\"Words frequented in Grade-PreK-2 Projects\", fontsize=16)\n#https://matplotlib.org/examples/color/colormaps_reference.html for colormaps\nplt.imshow(wc.recolor(colormap='Dark2',random_state=17), alpha=0.98,interpolation='bilinear')\n\nplt.subplot(222)\ntext=train[train.project_grade_category=='Grades 3-5'].project_resource_summary\nwc= WordCloud(background_color=\"black\",max_words=7000,stopwords=stopword,mask=grade_mask_2,normalize_plurals=True)\nwc.generate(\" \".join(text))\nplt.axis(\"off\")\nplt.title(\"Words frequented in Grades 3-5 Projects\", fontsize=16)\nplt.imshow(wc.recolor(colormap='Pastel1',random_state=17), alpha=0.98,interpolation='bilinear')\n\nplt.subplot(223)\ntext=train[train.project_grade_category=='Grades 6-8'].project_resource_summary\nwc= WordCloud(background_color=\"black\",max_words=7000,stopwords=stopword,mask=grade_mask_3,normalize_plurals=True)\nwc.generate(\" \".join(text))\nplt.axis(\"off\")\nplt.title(\"Words frequented in Grades 6-8 Projects\", fontsize=16)\nplt.imshow(wc.recolor(random_state=17), alpha=0.98,interpolation='bilinear')\n\nplt.subplot(224)\ntext=train[train.project_grade_category=='Grades 9-12'].project_resource_summary\nwc= WordCloud(background_color=\"white\",max_words=7000,stopwords=stopword,mask=grade_mask_4,normalize_plurals=True)\nwc.generate(\" \".join(text))\nplt.axis(\"off\")\nplt.title(\"Words frequented in Grades 9-12 Projects\", fontsize=16)\n#https://matplotlib.org/examples/color/colormaps_reference.html for colormaps\nplt.imshow(wc.recolor(colormap='Dark2',random_state=17), alpha=0.98,interpolation='bilinear')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"419319c1-2289-4083-80f5-7245c0563f36","_uuid":"55b1b04d4be41e123ce445d48c9f88161c91b6b4","trusted":true,"collapsed":true},"cell_type":"code","source":"end_time=time.time()\nprint(\"Time till plotting section\",end_time-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ff5ae261-07e7-45a6-98e8-929682eadb99","collapsed":true,"_uuid":"16313dc4b64431867f1855d9d9302adff658f96c"},"cell_type":"markdown","source":"# Adding features from the Resources Dataset:\nApart from the train dataset , we also have another file containing the details of the items that were requested and their price points and quantities.\n\nLets look into them!"},{"metadata":{"_cell_guid":"86663953-1421-4afd-b53b-0849f2e51dd0","_uuid":"c3d8e0ac30a7fd318e9d45443ef1c6e21c3d5448","trusted":true,"collapsed":true},"cell_type":"code","source":"resources['total_cost']=resources['quantity']*resources['price']\n# Group by and get concat of the description\nresources['description']=resources['description'].astype(str)\nx=resources.groupby('id')['description'].apply(lambda x: \"%s\" % ', '.join(x))   #https://stackoverflow.com/questions/17841149/pandas-groupby-how-to-get-a-union-of-strings\nx.head(2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6bc51390-3e74-4284-a4c8-426f034dc7eb","collapsed":true,"_uuid":"c668edf6f8d06a676f731c93b4592f310abfd63a","trusted":true},"cell_type":"code","source":"# project level resource stats\nresources_agg=resources.groupby('id')['quantity','price','total_cost'].agg({'quantity':['sum','count'],'price':['mean'],'total_cost':['sum']})\nresources_agg.columns=['item_quantity_sum','variety_of_items','avg_price_per_item','total_cost']\nresources_agg['collated_description']=x\nresources_agg=resources_agg.reset_index()\n#resources_agg=resources_agg.sort_values(\"total_cost\",ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b31f8c6a-aed9-476f-8f3f-521c4183dea0","scrolled":true,"_uuid":"696afb761253d1eb98b6d230731d8d3ca5b43298","trusted":true,"collapsed":true},"cell_type":"code","source":"train_merge=pd.merge(left=train,right=resources_agg,on='id',how='left')\ntrain_merge.sort_values(\"total_cost\",ascending=False).head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cd2b9c72-ed75-4671-ae9b-597766cff876","_uuid":"988f2b3f8366d45b74c8e89a9fc5c659131833fc"},"cell_type":"markdown","source":"# Custom Word Vectors:\n\nWord Embeddings are a great way to understanding text. Instead of using a pre-trained word-vector created by some huge dataset, Lets create one of our own from the product descriptions.\n\nThe steps followed here are,\n* Basic pre-processing( Tokenization, to lower-case,etc)\n* Cleaning by Lemmatization ( Converting to root word)\n* Bigram Collection ( Collecting popular bigrams together Eg: new+ york --> new_york)\n* Creating the custom model\n* Apply model to the cleaned descriptions\n* Sanity checks \n"},{"metadata":{"_cell_guid":"a983f1b6-bc41-4f53-9e01-cc0caab9bad2","collapsed":true,"_uuid":"b1b6fe9de2ca59f831cbdfcc925a7c0b101230be","trusted":true},"cell_type":"code","source":"all_data=pd.concat([train,test],axis=0)\nall_data_merge=pd.merge(left=all_data,right=resources_agg,on='id',how='left')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"613b0e18-80f3-47f7-8f3b-ca44edb8b4fc","collapsed":true,"_uuid":"a8c4b4eddce7970854be3e12a7da65cd6a204560","trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom sklearn.manifold import TSNE\n\ndef preprocess_and_clean(text_col):\n    word_list = gensim.utils.simple_preprocess(text_col, deacc=True)\n    clean_words = [w for w in word_list if not w in eng_stopwords]\n    clean_words=[lem.lemmatize(word, \"v\") for word in clean_words]\n    return(clean_words)\nx=all_data_merge['collated_description'].apply(preprocess_and_clean)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c8ddfd48-bf84-455b-8c97-9369500a0ffd","_uuid":"80fc7bb4fb0d45fa8db2087fb2e3ad3e48f21ab5","trusted":true,"collapsed":true},"cell_type":"code","source":"bigram_transformer = gensim.models.Phrases(x)\nx=x.apply(lambda word : bigram_transformer[word])\n#take a peak to check\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3c8cfff4-6483-464c-bd98-40d54754e61d","collapsed":true,"_uuid":"11b87a3fafc8b53aa6cac6c776f46f86c6d7692a","trusted":true},"cell_type":"code","source":"model = Word2Vec(x, size=100, window=5, min_count=10, workers=4,seed=10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"01c933ab-cdf3-401b-a994-6096c19d95ff","_uuid":"4cf98c83e4218207613b340a08a278f976fc186c"},"cell_type":"markdown","source":"#### Awesome! Now, we have our very own custom Word-Embeddings. \n\nNow lets check if they have made valid connections by visualizing some of the common words and finding their closest associated words. \n\nIf we have created meaningful connections, then these words should make logical sence too!\n\nHere, We define another utility function. This function takes in a word as input and does the following.\n* Gets a word as input\n* From our custom model, finds the closets 10 words in the \"Vector space\" and gets their vectors in an array\n* Uses T-SNE ( a dimentionality reduction technique) to visualize the selected words in 2 Dimentions\n"},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"19e7daf1fd8fc49f10b9a5a20ad7d832ac28cb81","_cell_guid":"f45e67c4-f916-45dc-9e25-3640fb4dbcd3","trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE\n\ndef display_closestwords_tsnescatterplot(model, word):\n    \n    arr = np.empty((0,100), dtype='f')\n    word_labels = [word]\n\n    # get close words\n    close_words = model.similar_by_word(word)\n    \n    # add the vector for each of the closest words to the array\n    arr = np.append(arr, np.array([model[word]]), axis=0)\n    for wrd_score in close_words:\n        wrd_vector = model[wrd_score[0]]\n        word_labels.append(wrd_score[0])\n        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n        \n    # find tsne coords for 2 dimensions\n    tsne = TSNE(n_components=2, random_state=0)\n    np.set_printoptions(suppress=True)\n    Y = tsne.fit_transform(arr)\n\n    x_coords = Y[:, 0]\n    y_coords = Y[:, 1]\n    # display scatter plot\n    plt.scatter(x_coords, y_coords)\n    for label, x, y in zip(word_labels, x_coords, y_coords):\n        plt.annotate(label, xy=(x, y), xytext=(5, 5), textcoords='offset points')\n    plt.xlim(x_coords.min()+10, x_coords.max()+10)\n    plt.ylim(y_coords.min()+10, y_coords.max()+10)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7a90f34d-576c-4420-83e4-ef8594251d73","_kg_hide-input":true,"_uuid":"19016dac606b79792940cb4fb7b4ce836d49eca6","trusted":true,"collapsed":true},"cell_type":"code","source":"word='apple'\nprint(\"Word Embedding of words similar to the word:- \",str(word))\ndisplay_closestwords_tsnescatterplot(model,word)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"78b695f9-4e57-455c-a828-613e2c07c03c","_kg_hide-input":true,"_uuid":"59bea54a5dfb979bd5ab3ad1db72bf237014a3ff","trusted":true,"collapsed":true},"cell_type":"code","source":"word='chair'\nprint(\"Word Embedding of words similar to the word:- \",str(word))\ndisplay_closestwords_tsnescatterplot(model,word)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9be9e160-957f-48ae-9623-94611b4b76e2","_uuid":"8070f1290f2224dc73c018046d03194e44547c24","trusted":true,"collapsed":true},"cell_type":"code","source":"word='shirt'\nprint(\"Word Embedding of words similar to the word:- \",str(word))\ndisplay_closestwords_tsnescatterplot(model,word)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8a6c0978-9202-41e7-b9d5-cd25d2016942","_uuid":"7a6c9beeaeafe43dcbdc43c4b4ea56c19acd998c","trusted":true,"collapsed":true},"cell_type":"code","source":"word='art'\nprint(\"Word Embedding of words similar to the word:- \",str(word))\ndisplay_closestwords_tsnescatterplot(model,word)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1d9bf8b2-61f0-4636-a7e6-0fa6f3536d87","_uuid":"073d95d039400968f6953194b9f5e3cf28193050","trusted":true,"collapsed":true},"cell_type":"code","source":"import gensim\nfrom gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\nfrom gensim.models.wrappers import LdaMallet\nfrom gensim.corpora import Dictionary\n\n#create the dictionary\ndictionary = Dictionary(x)\nprint(\"There are\",len(dictionary),\"number of words in the final dictionary\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"936022e4-5d0b-403d-af95-d9f5edfa75f2","collapsed":true,"_uuid":"fa37741bbaf0b5217e3b335a182a9c77d1cdb1b9","trusted":true},"cell_type":"code","source":"corpus = [dictionary.doc2bow(text) for text in x]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f6fb6bbd-a669-4c0e-8c21-a3ef1cd1a884","_uuid":"f0968e03b1f0fc1e365956ec744b5030b4aa9de6","trusted":true,"collapsed":true},"cell_type":"code","source":"#create the Lda model\nldamodel = LdaModel(corpus=corpus, num_topics=15, id2word=dictionary)\nend_lda=time.time()\nprint(\"Time till Lda model creation:\",end_lda-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bb97267b-2f0c-4586-82f4-89ade28e8556","collapsed":true,"_uuid":"88745831e9ed12fa965842881faacd36fb7475f7","trusted":true},"cell_type":"code","source":"import pyLDAvis.gensim\n\npyLDAvis.enable_notebook()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b0c1fa88-c669-4b50-8a0d-86f56cb4cf1b","_uuid":"56905f31f802d800b1a08b5b99eb6180f1eecdc8","trusted":true,"collapsed":true},"cell_type":"code","source":"pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"73f3598e-1936-48a7-81cd-e31a9ebb2673","collapsed":true,"_uuid":"18c8186c70a6882cb63f60d2e9238090517086af","trusted":true},"cell_type":"code","source":"#creating the topic probability matrix \ntopic_probability_mat = ldamodel[corpus]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"950617d3-52e4-4e86-98b3-f4d921d6f84e","collapsed":true,"_uuid":"18034c06698636bad2047515b52842ec9c3d2fbc","trusted":true},"cell_type":"code","source":"#split it to test and train\ntrain_matrix=topic_probability_mat[:train.shape[0]]\ntest_matrix=topic_probability_mat[train.shape[0]:]\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2521545f-74dd-44b7-b563-1693dbf0556c","_uuid":"62b6b9daa82e2d7a42c87796cbe35f5e935456dc","trusted":true,"collapsed":true},"cell_type":"code","source":"# check one entry\nx.iloc[6]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b2f1bc5c-4bae-42e9-bb81-0f27d98e0be1","_uuid":"f4438a03df1f71f09cad43b95dec9ce9404d4f6e","trusted":true,"collapsed":true},"cell_type":"code","source":"start=time.time()\ndoc = x.iloc[6]\nvec_bow = dictionary.doc2bow(doc)\nvec_lda = ldamodel[vec_bow] # convert the query to Lda space\nprint(vec_lda)\nend=time.time()\nprint(\"Time for one iter:\",end-start,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94fceb6f-a802-486b-b945-a0faacf7bdeb","collapsed":true,"_uuid":"daec7ddd1e29a39e10497f5430b82b423dbdef50","trusted":true},"cell_type":"code","source":"from gensim import corpora, models, similarities\nindex = similarities.MatrixSimilarity(ldamodel[corpus]) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a4be72f9-f7a0-4db2-8d9b-33dea39b62b7","collapsed":true,"_uuid":"d0f96f8f198e4491a2620dad9bf2a726567753b5","trusted":true},"cell_type":"code","source":"sims = index[vec_lda] ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"44fa2f3b-8b23-4ae9-8a8d-388fe1c431ff","collapsed":true,"_uuid":"1b71e96afb03a877de972cf6bf2c3952a4a9e1a5","trusted":true},"cell_type":"code","source":"sims = sorted(enumerate(sims), key=lambda item: -item[1])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5843813a-2083-4d33-8b6d-5d257ea2c469","_uuid":"ac25fe17c343e3b1cb5150b256d544470c875fe7"},"cell_type":"markdown","source":"Now that we have topics for each sentence, it opens up few interesting analyses.\n\n* Are teachers asking for items in the same group?\n* What are the item groups of preference to kindergarden teachers VS others?\n    * Is the rejection rate more if grade 5 teacher asks for an item asked predominently by a kindergarden teacher?\n* Can we detect duplicates ? \n    * Teachers asking for the same thing within a short span of time get rejected more?\n        * If so, which category / item group gets rejected more?\n\n\n\n<<<< Section under construction >>>\n"},{"metadata":{"_cell_guid":"bff7aa00-e574-47a4-8348-c34bf37c5609","_uuid":"051b79f2e9f6b29f0564dd35468254c8d100bfe3","trusted":true,"collapsed":true},"cell_type":"code","source":"end_lda=time.time()\nprint(\"Time till Lda model viz:\",end_lda-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"993133fb-d7a9-4ef2-bf6c-b70f9c4029ec","_uuid":"88e865de9b205426437056c375970d8a1ee1f1d0","trusted":true,"collapsed":true},"cell_type":"code","source":"del(ldamodel)\ndel(corpus)\ndel(dictionary)\ndel(model)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"59ad90b9-9acb-4b96-a02d-2021162ee549","_uuid":"e23a45feedbe37f51d33c1fcfe9dc5626d5473d9"},"cell_type":"markdown","source":"## Product clustering\n<< Section under construction >>"},{"metadata":{"_cell_guid":"0e695bfa-1ac6-4b3b-87b6-81db250d2237","collapsed":true,"_uuid":"30c79fe261e41c97e24d2d4cf0d063f7a493cca4","trusted":true},"cell_type":"code","source":"# To be done","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"39235511-fe81-47da-9b59-159b4e73ba92","_uuid":"e641855c0ac0ea1ee167577eb5304adc149c5029"},"cell_type":"markdown","source":"# Price point analysis:"},{"metadata":{"_cell_guid":"87de45a9-4cd6-4689-8847-cb42bf42814a","_uuid":"dc1fd21e616e03de32fe950c365011121b2daa45","trusted":true,"collapsed":true},"cell_type":"code","source":"x=train_merge.total_cost.value_counts()\n#sort by price\nx=x.sort_index(ascending=False)\n#subset for alteast 5 entries\nx=x[x>5]\n# get the top 20\nx=x.iloc[0:20]\n#plot\nplt.figure(figsize=(16,5))\nax= sns.barplot(x.index, x.values, alpha=0.8)\nplt.title(\"Frequent(more than 5 projects) Price points\")\nplt.ylabel('# of Occurrences', fontsize=12)\nplt.xlabel('Price point', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d1b5ef80-88b9-4508-9ddf-5c13cb6ab421","_uuid":"cb110f1988e080c448f661b784c783dd4b0db978"},"cell_type":"markdown","source":"There are some pricey items on the list. \n\nLet's explore some of the most costly items requested to hopefully find a useful pattern.\n\n# Google Expeditions Kit : 9999, 6999, 3999 :\nThis seems to be the costliest item under DonorsChoose. Its a set of 30 Virtual Reality glasses for the entire classroom. \n\nI would've loved to have this during my schooling days! [Demo](https://support.google.com/edu/expeditions/answer/7375176?hl=en&ref_topic=6334250)\n\n![](https://images.bbycastatic.ca/sf/projects/bestbuyforbusiness/education/contents/google-expeditions/assets/featured-kit-size-30.jpg)\n\nThe item comes at three price points (9999,6999,3999).\n\nThere were 34 requests for this item and only two rejections at 9999\n\nThere were 13 requests for the item and 0 rejects at 6999\n\n57 requests for this item at 3999 and 5 rejects"},{"metadata":{"_cell_guid":"b26ee9ef-6f92-460d-a3aa-27bca6710383","_uuid":"8bd8cacd57865b20ba38610390d253a9dfad9b66","trusted":true,"collapsed":true},"cell_type":"code","source":"# subset expedition kit requests\nsubset=train_merge[train_merge.total_cost==9999]\nprint(\"Number of times requested:\",len(subset))\nsubset[subset.project_is_approved==0].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a8b94b0a-d4ce-491d-b95e-606abb95c17c","_uuid":"cd5e90dffceaa3572e9e018d4cbfb9b385e2a3be","trusted":true,"collapsed":true},"cell_type":"code","source":"# subset expedition kit requests\nsubset=train_merge[train_merge.total_cost==6999]\nprint(\"Number of times requested:\",len(subset))\nsubset[subset.project_is_approved==0].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79e0777b-2f2b-47e9-9db1-893bf3ae5c13","_uuid":"b3fc20e8b1be6cb60d82aa7091905fa4fa44844b","trusted":true,"collapsed":true},"cell_type":"code","source":"# subset expedition kit requests\nsubset=train_merge[train_merge.total_cost==3999]\nprint(\"Number of times requested:\",len(subset))\nsubset[subset.project_is_approved==1].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f2da85d2-b5fe-40f6-9f09-a5fb7abb189e","_uuid":"2dd52217fff87d7b2223dbb24d9c2352b577df8c"},"cell_type":"markdown","source":"# Engage 2 - Interactive table - 4995.95 :\n\n![](https://images.kaplanco.com/images/products/engage2-interactive-table2015.jpg)\n\nInteractive table for kindergardeners!\n\nRequested 7 times and no rejects!"},{"metadata":{"_cell_guid":"a7c65eaa-b020-4eb8-85d5-b7188ba7e016","_uuid":"6e4172c4943e7105004de68cff925a47822a837b","trusted":true,"collapsed":true},"cell_type":"code","source":"# subset expedition kit requests\nsubset=train_merge[train_merge.total_cost==4995.95]\nprint(\"Number of times requested:\",len(subset))\nsubset[subset.project_is_approved==1].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"171678c9-ac9c-4443-a5d0-50b95d1ce8f2","_uuid":"96162e3f58d9341f2947e2383782c1a7c28b6b7f"},"cell_type":"markdown","source":"# Apple products:\n\nIpad , Ipad mini, Macbook seem to be frequent in the wishlist of teachers."},{"metadata":{"_cell_guid":"001f57ef-845e-4498-9303-59ffccadfdc2","_uuid":"bdbb3b37ab50bff70a8dfd8fe12be6677c3e8230","trusted":true,"collapsed":true},"cell_type":"code","source":"\nprice_points=[1999.99, 1999.96, 1999.95,1999.9]\n# subset expedition kit requests\nsubset=train_merge[train_merge.total_cost.isin(price_points)]\nprint(\"Number of times requested:\",len(subset))\nprint(\"Number of times approved:\",len(subset[subset.project_is_approved==1]))\nsubset[subset.project_is_approved==0].head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0fb80e24-0f3a-4246-bb8c-c1bb0a3792e9","collapsed":true,"_uuid":"1c79c131ea50b939fd3673a451724f6e10f80207"},"cell_type":"markdown","source":"# Feature Engineering (ELI5 version):\n\nThe competition is more focussed on explainability (ie) understanding why a project gets approved, so that they can pre-approve some applications and pass on some of the difficult ones to Human volunteers.\n\nHence, Ive built the model to be compatable with [ELI5](https://www.kaggle.com/lopuhin/eli5-for-mercari), so that we can hopefully understand why the model thinks that certain projects are rejected!\n\n## Pre-processing/Cleaning text fields:\n\nThe following steps have been done for pre-processing.\n\n* Tokenization (Splitting into seperate words )\n* Basic pre-processing ( convert to lower,etc) by Gensim\n* Remove stop words\n* Lemmatization (Converting word to its root form : babies --> baby ; children --> child)\n\n"},{"metadata":{"_cell_guid":"11bafe2f-0ef0-4d3f-90d8-45f66b00f811","_uuid":"a681e399802bda43f471cbdbefbe555b9bda61c0","trusted":true,"collapsed":true},"cell_type":"code","source":"# Using cleaning functions from previous work --> https://www.kaggle.com/jagangupta/understanding-the-topic-of-toxicity/notebook\ndef preprocess_and_clean(text_col):\n    \"\"\"\n    Function to build tokenized texts from input comment and the clean them\n    Following transformations will be done\n    1) Stop words removal from the nltk stopword list\n   #commenting out for speed issues 2) Bigram collation (Finding common bigrams and grouping them together using gensim.models.phrases) (Eg: new + york --> new_york )\n    3) Lemmatization (Converting word to its root form : babies --> baby ; children --> child)\n    \"\"\"\n    \n    word_list = gensim.utils.simple_preprocess(text_col, deacc=True)\n    #Phrases help us group together bigrams :  new + york --> new_york\n    #bigram = gensim.models.Phrases(text_col)\n    \n    #remove stop words\n    clean_words = [w for w in word_list if not w in eng_stopwords]\n    #collect bigrams\n    #clean_words = bigram[clean_words]\n    #Lemmatize\n    clean_words=[lem.lemmatize(word, \"v\") for word in clean_words]\n    return(' '.join(clean_words))  \n\n#check clean function\nprint(\"Before clean:\",train.project_description.iloc[16])\nprint(\"After clean:\",preprocess_and_clean(train.project_description.iloc[16]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eec87b09-03fb-4602-901a-fac7b560994e","_uuid":"c455973bd11320fece07bb06f45cea7fa5259d5b","trusted":true,"collapsed":true},"cell_type":"code","source":"# Null treatment\ntrain.teacher_prefix=train.teacher_prefix.fillna('Unknown')\ntest.teacher_prefix=test.teacher_prefix.fillna('Unknown')\ntrain.gender=train.gender.fillna('Unknown')\ntest.gender=test.gender.fillna('Unknown')\n\nprint(train.shape)\nprint(test.shape)\ny=train['project_is_approved']\ntrain_id=train['id']\ntest_id=test['id']\ndel(train['project_is_approved'])\nall_data=pd.concat([train,test],axis=0)\nprint(all_data.shape)\nall_data_merge=pd.merge(left=all_data,right=resources_agg,on='id',how='left')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8c8f8f23-1297-4fe9-aec2-f0d8b9250d5d","collapsed":true,"_uuid":"7309255a3e66ca38eaa2650a6b4e47049713ce97","trusted":true},"cell_type":"code","source":"# taking some FE ideas from public kernals\n# thanks owl, --> https://www.kaggle.com/the1owl/the-choice-is-yours\n# and jmbull --> https://www.kaggle.com/jmbull/xtra-credit-xgb-w-tfidf-feature-stacking","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"736141b6-f226-4c36-b5a0-e043f87e068a","_uuid":"f461e74060625e49dc662c19e33dc20d57daa1a4","trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn import *\nfrom tqdm import tqdm\n# Label encode some columns\ncols = [\n    'teacher_id', \n    'teacher_prefix', \n    'school_state', \n    'project_grade_category',\n    'project_subject_categories', \n    'project_subject_subcategories',\n    'gender']\nfor c in tqdm(cols):\n    le = preprocessing.LabelEncoder()\n    le.fit(all_data_merge[c].astype(str))\n    all_data_merge[c] = le.transform(all_data_merge[c].astype(str))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a502977b-5cd1-4b59-8331-23828f2198f8","collapsed":true,"_uuid":"a4722e331c0888a4691128c8ff31862cb5280bb1","trusted":true},"cell_type":"code","source":"# Log1p transform price columns\nall_data_merge['avg_price_per_item']=np.log1p(all_data_merge['avg_price_per_item'])\nall_data_merge['total_cost']=np.log1p(all_data_merge['total_cost'])\n\n# date features\nall_data_merge['project_submitted_datetime'] = pd.to_datetime(train['project_submitted_datetime'])\nall_data_merge['datetime_dow'] = all_data_merge['project_submitted_datetime'].dt.dayofweek\nall_data_merge['datetime_year'] = all_data_merge['project_submitted_datetime'].dt.year\nall_data_merge['datetime_month'] = all_data_merge['project_submitted_datetime'].dt.month\nall_data_merge['datetime_hour'] = all_data_merge['project_submitted_datetime'].dt.hour\nall_data_merge['datetime_day'] = all_data_merge['project_submitted_datetime'].dt.day","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd0f18d5-47e6-47ef-b03f-e32c005f1d99","_uuid":"ae8983f4cb77a5b54d8086179aa0f2e040a9a6df","trusted":true,"collapsed":true},"cell_type":"code","source":"#process text cols\ntext_cols=['project_title', \n           'collated_description',\n           'project_resource_summary',\n           'student_description', \n           'project_description']\nfor c in tqdm(text_cols):\n    all_data_merge[c+'_len']=all_data_merge[c].apply(len)               # get length (ie) letter count\n    all_data_merge[c+'_word_count']=all_data_merge[c].apply(lambda x: len(str(x).split())) # get word count\n    all_data_merge[c]=all_data_merge[c].apply(preprocess_and_clean)\nend_time=time.time()\nprint(\"Time till end\",end_time-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4d331675-1086-46c5-a16d-b0b8af882e16","_uuid":"8a07bf52903c9f790b032dfd28ed87020e617e8a","trusted":true,"collapsed":true},"cell_type":"code","source":"train_shape=train.shape\ntest_shape=test.shape\n# del(train)\n# del(test)\ndel(train_merge)\ndel(resources)\ndel(resources_agg)\ndel(subset)\ndel(approvals)\ndel(rejects)\ndel(all_data)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"349dcbb0646321e506e6608a209c2e4067bee135","_cell_guid":"1344301e-e247-4cbb-91a9-bf40a56c8439","trusted":true},"cell_type":"code","source":"############################\n# needs debugging\n########################\n# from sklearn.pipeline import FeatureUnion,TransformerMixin,Pipeline\n# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n# from sklearn.feature_extraction import DictVectorizer\n# from sklearn.metrics import auc\n\n# # https://www.kaggle.com/lopuhin/eli5-for-mercari\n# # https://github.com/scikit-learn/scikit-learn/issues/2034\n\n# class GetItemTransformer(TransformerMixin):\n#     \"\"\"\n#     Custom class to fetch just the column needed from the numpy nd array from pandas.values that is passed to the vectorizer\n#     \"\"\"\n#     def __init__(self, field):\n#         self.field = field\n#     def fit(self, X, y=None):\n#         return self\n#     def transform(self,X):\n#         field_idx = list(all_data_merge.columns).index(self.field)\n#         return X[:,field_idx]\n    \n\n# vectorizer = FeatureUnion([\n#     ('project_title',\n#          Pipeline([\n#             ('get', GetItemTransformer('project_title')),\n#             ('vectorize',CountVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=2000))\n#          ])),\n#     ('project_resource_summary',\n#          Pipeline([\n#             ('get', GetItemTransformer('project_resource_summary')) ,\n#             ('vectorize',TfidfVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=5000))\n#          ])),\n#     ('student_description',\n#          Pipeline([\n#             ('get', GetItemTransformer('student_description')) ,\n#             ('vectorize',TfidfVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=20000))\n#          ])),\n#     ('project_description',\n#          Pipeline([\n#             ('get', GetItemTransformer('project_description')),\n#             ('vectorize',TfidfVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=20000))\n#          ])),\n#     ('collated_description',                                                 # using count vect here as this coulmn contains mostly product descr. \n#          Pipeline([\n#             ('get', GetItemTransformer('collated_description')),\n#             ('vectorize',CountVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=10000))\n#          ]))\n# ])\n# error due to pipeline not having get feature names!! --> https://github.com/scikit-learn/scikit-learn/issues/6424\n# # todo : to add other fields(non-text) into the pipeline itself","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3f2a6a73-1b19-40b5-9eae-21b671dcd264","_uuid":"53e1bb15eb2789cabcfcd351539a6d9e0049a320","trusted":true,"collapsed":true},"cell_type":"code","source":"del(all_data_merge['project_submitted_datetime'])\n#https://stackoverflow.com/questions/29815129/pandas-dataframe-to-list-of-dictionaries\nall_data_merge_1=all_data_merge.to_dict('records')\ndel(all_data_merge)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"56bcf207ececbc507332b430e4218e8fc12c391f","_cell_guid":"54e15aa6-1d04-4896-8e44-fd5351cfc640","trusted":true},"cell_type":"code","source":"# from sklearn.pipeline import FeatureUnion,TransformerMixin,Pipeline\n# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n# from sklearn.feature_extraction import DictVectorizer\n# from sklearn.metrics import auc\n# import dill as pickle\n# # https://www.kaggle.com/lopuhin/eli5-for-mercari\n# # https://github.com/scikit-learn/scikit-learn/issues/2034\n\n# vectorizer = FeatureUnion([\n#         ('project_title',CountVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=5000,\n#             preprocessor=lambda x: x['project_title'])),\n#         ('project_resource_summary',TfidfVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=10000,\n#             preprocessor=lambda x: x['project_resource_summary'])),\n#         ('student_description',TfidfVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=30000,\n#             preprocessor=lambda x: x['student_description'])),\n#         ('project_description',TfidfVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=30000,\n#             preprocessor=lambda x: x['project_description'])),\n#         ('char_project_resource_summary',TfidfVectorizer(\n#             ngram_range=(3,5),analyzer='char',\n#             max_features=5000,\n#             preprocessor=lambda x: x['project_resource_summary'])),\n#         ('char_student_description',TfidfVectorizer(\n#             ngram_range=(3,5),analyzer='char',\n#             max_features=5000,\n#             preprocessor=lambda x: x['student_description'])),\n#         ('char_project_description',TfidfVectorizer(\n#             ngram_range=(3,5),analyzer='char',\n#             max_features=5000,\n#             preprocessor=lambda x: x['project_description'])),   \n    \n#         ('collated_description',CountVectorizer(\n#             ngram_range=(1, 2),\n#             max_features=30000,\n#             preprocessor=lambda x: x['collated_description'])),\n#         ('Non_text',DictVectorizer())\n#     ],njobs=4)\n\n## Parallel processing didn't work ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"15d468bd-51d2-4b02-a41e-08c7e8023568","collapsed":true,"_uuid":"d741ff017ac3cd1ebb1b060ceea6d2c016bbe378","trusted":true},"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion,TransformerMixin,Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.metrics import auc\n# import dill as pickle\n# https://www.kaggle.com/lopuhin/eli5-for-mercari\n# https://github.com/scikit-learn/scikit-learn/issues/2034\ndef get_col(col_name):\n    return lambda x: x[col_name]\n\nvectorizer = FeatureUnion([\n        ('project_title',CountVectorizer(\n            ngram_range=(1, 2),\n            max_features=10000,\n            preprocessor=get_col('project_title'))),\n        ('project_resource_summary',TfidfVectorizer(\n            ngram_range=(1, 2),\n            max_features=30000,\n            preprocessor=get_col('project_resource_summary'))),\n        ('student_description',TfidfVectorizer(\n            ngram_range=(1, 2),\n            max_features=100000,\n            preprocessor=get_col('student_description'))),\n        ('project_description',TfidfVectorizer(\n            ngram_range=(1, 2),\n            max_features=100000,\n            preprocessor=get_col('project_description'))),\n        ('collated_description',CountVectorizer(\n            ngram_range=(1, 2),\n            max_features=30000,\n            preprocessor=get_col('collated_description'))),\n        ('Non_text',DictVectorizer())\n    ])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5717b93f-8d1b-4963-9801-2c44584c705b","_uuid":"28eb8efb670c6fe4446d2cac8762ba7376312c52","trusted":true,"collapsed":true},"cell_type":"code","source":"start_vect=time.time()\nall_data_vectorized = vectorizer.fit_transform(all_data_merge_1)\n# split train and test \n# train_text_data_vectorizer=vectorizer.fit_transform(all_data_merge.iloc[:train_shape[0]])\n# test_text_data_vectorizer=vectorizer.fit_transform(all_data_merge.iloc[train_shape[0]:])\n\nend_time=time.time()\n\nprint(\"total time in vectorization creation\",end_time-start_vect,\"s\")\nprint(\"total time till vectorization creation\",end_time-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"237d8a5e-c6cb-4c85-95f1-1de4d90ee815","collapsed":true,"_uuid":"336ede878e1e3fefa881805885387a08082c1ee5","trusted":true},"cell_type":"code","source":"from scipy.sparse import csr_matrix, hstack\nfinal_dataset=all_data_vectorized.tocsr()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"d5a15de86225f5f2c968858ef486b948e6185007","_cell_guid":"2a2664c5-ac38-4e13-9346-79cfcf8500f3","trusted":true},"cell_type":"code","source":"# older version\n# all_text_data_vectorized = vectorizer.fit_transform(all_data_merge.values)\n# train_x_only_text=all_text_data_vectorized[0:train_shape[0]]\n# test_x_only_text=all_text_data_vectorized[train_shape[0]:]\n# all_cols=all_data_merge.columns.values\n# non_text_cols = [col for col in all_cols if col not in text_cols]\n# non_text_cols.remove('id')\n# non_text_cols.remove('project_submitted_datetime')\n# from scipy.sparse import csr_matrix, hstack\n# all_non_text_data = csr_matrix(all_data_merge[non_text_cols].values)\n# final_dataset=hstack((all_text_data_vectorized,all_non_text_data)).tocsr()\n# end_time=time.time()\n# print(\"total time till Sparse mat creation\",end_time-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7dd8a0d8-2a43-4533-91e0-4111c4673709","collapsed":true,"_uuid":"7b6c670b5ebb343a97441946047e00df89e397e9","trusted":true},"cell_type":"code","source":"train_x=final_dataset[0:train_shape[0]]\ntest_x=final_dataset[train_shape[0]:]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"35606cb1-6893-46a9-a6ca-921deba995de","_uuid":"29598c74e2f65b6b6e3532161681ec25b6afb716","trusted":true,"collapsed":true},"cell_type":"code","source":"del final_dataset,all_data_vectorized\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ff128a71-b7ce-4f23-8ad1-e4e77a48e846","collapsed":true,"_uuid":"26f94c81404a237d1fc56c4ccde712be273e7a73","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(train_x, y, test_size=0.33, random_state=2018)\n# Using LGBM params from https://www.kaggle.com/opanichev/lightgbm-and-tf-idf-starter/code\nparams = {\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'auc',\n        'max_depth': 16,\n        'num_leaves': 31,\n        'learning_rate': 0.25,\n        'feature_fraction': 0.85,\n        'bagging_fraction': 0.85,\n        'bagging_freq': 5,\n        'verbose': 1,\n        'num_threads': 4,\n        'lambda_l2': 1,\n        'min_gain_to_split': 0,\n        'seed':1234\n}  ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0a5c7bb9-d99e-43d2-b7f7-81cb911bf24e","_uuid":"59c77aef8f35c9213eceff3bcaf57cbac8caea18","trusted":true,"collapsed":true},"cell_type":"code","source":"import lightgbm as lgb\n\nmodel = lgb.train(\n        params,\n        lgb.Dataset(X_train, y_train),\n        num_boost_round=10000,\n        valid_sets=[lgb.Dataset(X_valid, y_valid)],\n        early_stopping_rounds=100,\n        verbose_eval=25)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"551c9409-c826-4e37-96d7-91e612e61f8e","_uuid":"b9831d0b479f4677ad59697e48b45a8b322d0ff1","trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nvalid_preds = model.predict(X_valid, num_iteration=model.best_iteration)\ntest_preds = model.predict(test_x, num_iteration=model.best_iteration)\nauc = roc_auc_score(y_valid, valid_preds)\nprint('AUC:',auc)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f23e916f-ab65-4c5b-9207-0d64370b6195","_uuid":"5d951dbd0b526b16df575ec8b9086ed061e2db06","trusted":true,"collapsed":true},"cell_type":"code","source":"end_time=time.time()\nprint(\"total time till LGB model\",end_time-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3bfb193f-88d9-4845-a40c-67b4ad29278b","collapsed":true,"_uuid":"e63341d38a2b4722317ea3ba8b7238c8d50b367a","trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxgb_params = {'eta': 0.2, \n                  'max_depth': 5, \n                  'subsample': 0.8, \n                  'colsample_bytree': 0.8, \n                  'objective': 'binary:logistic', \n                  'eval_metric': 'auc', \n                  'seed': 1234\n                 }\n# d_train = xgb.DMatrix(X_train, y_train)\n# d_valid = xgb.DMatrix(X_valid, y_valid)\n# d_test = xgb.DMatrix(test_x)\nX_train, X_valid, y_train, y_valid = train_test_split(train_x, y, test_size=0.33, random_state=2018)\n#for eli5\nd_train = xgb.DMatrix(X_train, y_train)\nd_valid = xgb.DMatrix(X_valid, y_valid)\nd_test = xgb.DMatrix(test_x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cb81db91-4cdd-4b80-8157-1b248ddf7cca","_uuid":"533b32d0f650fb246ac49f4010c7e848273758ed","trusted":true,"collapsed":true},"cell_type":"code","source":"watchlist = [(d_train, 'train'), (d_valid, 'valid')]\nmodel_xgb = xgb.train(xgb_params, d_train, 500, watchlist, verbose_eval=50, early_stopping_rounds=20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ea841800-ab7f-4df4-8559-2a8f5c5b7fa9","_uuid":"c11618f992b5d87c3e7ac1a4123e02a1ad804935","trusted":true,"collapsed":true},"cell_type":"code","source":"xgb_pred_test = model_xgb.predict(d_test)\nxgb_pred_valid = model_xgb.predict(d_valid)\nauc = roc_auc_score(y_valid, xgb_pred_valid)\nprint('AUC:',auc)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc15a6b0-38bb-49ef-b852-81c2421ef463","_uuid":"21da68bffa82fc95a8fb310c09d5ed5daaa463c2","trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr,tpr,thresholds=roc_curve(y_valid, xgb_pred_valid)\nroc_auc = metrics.auc(fpr, tpr)\nfpr_1,tpr_1,thresholds_1=roc_curve(y_valid,valid_preds)\nroc_auc_1 = metrics.auc(fpr_1, tpr_1)\nplt.figure(figsize=(8,6))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'XGBoost-AUC = %0.2f' % roc_auc)\nplt.plot(fpr_1, tpr_1, 'g', label = 'LGBM-AUC = %0.2f' % roc_auc_1)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n# end_time=time.time()\n# print(\"total time till XBG model\",end_time-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"252aa002-ac95-49d8-9308-3c25b9a4e495","collapsed":true,"_uuid":"97f60f0f77601fc84d2815dfe52d30a25cd2ca9d","trusted":true},"cell_type":"code","source":"xgb_pred_train = model_xgb.predict(d_train)\nimport eli5","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d3418ccb-569c-4bea-b24d-4701a78f4959","collapsed":true,"_uuid":"64608855364e82c4c49120509783840bbe0f42de","trusted":true},"cell_type":"code","source":"# eli5.explain_weights_lgb(model_xgb, vec=vectorizer)     # out of bounds error\n# text_features=vectorizer.get_feature_names()\n# other_features=non_text_cols\n# all_features=text_features+non_text_cols\n# eli5.explain_weights_xgboost(model_xgb, feature_names=all_features)          ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f2990970-cbb1-4dd5-ad73-a4519262961f","_uuid":"c1e882477c80cc0b33dbc082130c36b9962f99ba","trusted":true,"collapsed":true},"cell_type":"code","source":"eli5.show_weights(model_xgb,vec=vectorizer)    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"09e3547b-22bc-452e-939b-d10820ea05a5","_uuid":"1410a2335d34257031045cc5f33d23802eb009db"},"cell_type":"markdown","source":"Lets use ELI5 to understand why a particular entry was selected or rejected"},{"metadata":{"_cell_guid":"4af65bec-37e5-4a67-a9b2-fcf1dc3b9679","_uuid":"5c778379583cb7e721d667bef3201ed6a78a5afc","trusted":true,"collapsed":true},"cell_type":"code","source":"# random entry\nprint(\"Project is Approved?:Actual\",y[100])\nprint(\"Project is Approved?:Predicted prob:\",xgb_pred_train[100])\ndisplay(eli5.show_prediction(model_xgb, doc=all_data_merge_1[100], vec=vectorizer,show_feature_values=True,top=20))    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94830976-dfd2-4cd0-9be4-98a5d16a0603","_uuid":"e84f06130ed20468a8948f4e2f2c33f80dc29d4f","trusted":true,"collapsed":true},"cell_type":"code","source":"# random entry\nprint(\"Project is Approved?:Actual\",y[500])\nprint(\"Project is Approved?:Predicted prob:\",xgb_pred_train[500])\ndisplay(eli5.show_prediction(model_xgb, doc=all_data_merge_1[500], vec=vectorizer,show_feature_values=True,top=20))    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef00c90a-2a42-4c49-b2c6-c681f920e9dc","_uuid":"f43ecc4767f90291e05879631222ef4c433ff9d7"},"cell_type":"markdown","source":"## Some interesting observations here.\nThe fact that some words(set,ipad,materials) are missing contributes to the model thinking that the project is approved!!  I am not sure, if I am interpreting this correctly here though.\n\n\nAlso,The sentences are cleaned(ie) Stop words removed, Lemmatized.  Need to think of a way to perform the cleaning in the vectorizer itself, to display the original sentence. Do let me know in the comments section if you have any ideas :)\n\n\n"},{"metadata":{"_cell_guid":"268f103f-8d8a-4263-97fd-b2e7e9986ffd","scrolled":false,"_uuid":"e4d7b9b5c3730d4c3f3d0373e8b7aef48b031af7","trusted":true,"collapsed":true},"cell_type":"code","source":"from IPython.display import display\nno_missing = lambda feature_name, feature_value: not np.isnan(feature_value)\nfor i in range(5):\n    print(\"Project is Approved?:Actual\",y[i])\n    print(\"Project is Approved?:Predicted prob:\",xgb_pred_train[i])\n    display(eli5.show_prediction(model_xgb, doc=all_data_merge_1[i], vec=vectorizer,show_feature_values=True,top=30,feature_filter=no_missing))  ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec2e239e-bca1-43ed-ad1e-cea2e0f5256a","collapsed":true,"_uuid":"dc45f6a1ee2708b3e8c7069830d1b8244e1e32eb","trusted":true},"cell_type":"code","source":"final_preds=0.4*xgb_pred_test+0.6*test_preds","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b31caed1-07d3-4ac9-9e20-2f9763d7e70b","collapsed":true,"_uuid":"f5dca11063777ebc1769517e5931963b96ff52f7","trusted":true},"cell_type":"code","source":"# Making submission\nx_preds = pd.DataFrame(final_preds)\nx_preds.columns = ['project_is_approved']\nsub_id=sample_sub['id']\nsubmission = pd.concat([sub_id, x_preds], axis=1)\nsubmission.to_csv('lgbm_xgb_blend.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6410588a-a4e8-4498-95b1-97fa7080d2be","_uuid":"11cfe01b5cb0ae0ae61873bf2cbe84ecb0d0cb80","trusted":true,"collapsed":true},"cell_type":"code","source":"end_time=time.time()\nprint(\"total time spent in FE and model\",end_time-start_vect,\"s\")\nprint(\"total time till end\",end_time-start_time,\"s\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"42027866-e177-44e1-9569-d2705555a1a7","collapsed":true,"_uuid":"72cbe52db52cf8cc134eea6c6d47eb38734ca8f8"},"cell_type":"markdown","source":"# Footnotes:\nTo be done:\n* Tune XGB,LGBM better\n* Explore other models\n* Interpret ELi5 output and make changes to the model\n* Explore more on State and Time variables\n* Explore interactions\n* Explore Topic Modeling, text clustering\n* Explore vector based features\n* Add more functionality to text stats, wordcloud functions\n* Add confidence interval to the plotting function\n* Think of a way to perform cleaning in the vectorizer itself , so that ELI5 displays the original sentence instead of the cleaned one\n\n### To be continued....\n\n\n## Do leave an upvote if you liked the content :) \n"},{"metadata":{"_cell_guid":"72158ace-3047-4a4d-8ec3-d15190cef21e","collapsed":true,"_uuid":"4d86c2d0444e2095f30241386f43d7d3c835937d","trusted":true},"cell_type":"code","source":"# To be continued....","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}