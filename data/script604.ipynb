{"nbformat": 4, "cells": [{"source": ["# Animating and Smoothing 3D Facial Keypoints\n", "**Note:** if you are impatient, please **press the \"output\" tab** to look at a few giff's that are the final result of this script (please wait a bit for the giff's to load, and then they will be displayed at normal speed)  \n", "\n", "In this script I will build upon the very pretty visualizations in [DrGuillermo's 3D Animation Script](https://www.kaggle.com/drgilermo/3d-kmeans-animation) and provide a utility function to draw 3D shape animations with a surrounding 3D bounding box. In this script I also provide several additional utility functions to aid the process of working with this dataset: one function to normalize shapes (2D or 3D) and an additional one to write videos for visualization.  \n", "\n", "After showing an animation of the movment of facial keypoints in 3D, we then continue to filter some of the noise in the shape keypoints data by utilizing the spatial correlations across the dataset and create animations of the denoised keypoints, resulting in a much smoother and nicer animations.\n", "\n", "We then continue to apply temporal filtering on the denoised keypoint coordinates, resulting in even smoother animations.\n", "\n", "Finally, we verify that the filtering opperations didn't ruin anything by overlaying them on the original videos and looking at the differences. We conclude that the process of spatio-temporal filtering does produce a much nicer and cleaner anontation."], "cell_type": "markdown", "metadata": {"_uuid": "5ddea6a62812d7e718cd632fd3da31b46e05c5ef", "_cell_guid": "3f4cf0fa-ef64-4193-b5ca-e647ffd51b09"}}, {"source": ["import numpy as np\n", "import pandas as pd\n", "from sklearn import decomposition\n", "from scipy import signal\n", "import matplotlib.pyplot as plt\n", "import matplotlib.animation as animation\n", "import matplotlib\n", "import plotly.offline as py\n", "import plotly.graph_objs as go\n", "#import imageio\n", "import glob\n", "\n", "py.init_notebook_mode(connected=True)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "98550b0b8a698dedfb3b63cd0233d5001cb6b8b1", "_cell_guid": "0cd6a085-4049-40b7-8176-122a08ec5daf", "_kg_hide-output": true, "_kg_hide-input": true}}, {"source": ["# Load the Data"], "cell_type": "markdown", "metadata": {"_uuid": "e928636e24da24b1218b3503def1bb51f9e5a532", "_cell_guid": "5747ccc1-ae2a-4ffa-b0eb-de4a29ed2d60"}}, {"source": ["videoDF = pd.read_csv('../input/youtube_faces_with_keypoints_large.csv')\n", "\n", "# create a dictionary that maps videoIDs to full file paths\n", "npzFilesFullPath = glob.glob('../input/youtube_faces_*/*.npz')\n", "videoIDs = [x.split('/')[-1].split('.')[0] for x in npzFilesFullPath]\n", "fullPaths = {}\n", "for videoID, fullPath in zip(videoIDs, npzFilesFullPath):\n", "    fullPaths[videoID] = fullPath\n", "\n", "# remove from the large csv file all videos that weren't uploaded yet\n", "videoDF = videoDF.loc[videoDF.loc[:,'videoID'].isin(fullPaths.keys()),:].reset_index(drop=True)\n", "print('Number of Videos uploaded so far is %d' %(videoDF.shape[0]))\n", "print('Number of Unique Individuals so far is %d' %(len(videoDF['personName'].unique())))"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "40f739c0263fd6ae0ef8c9a98a0fdbfd59ad5d56", "_cell_guid": "bba43a18-77ee-4bde-a49f-3410b141a73e", "_kg_hide-input": true}}, {"source": ["# Show Overview of Dataset Content (that has been uploaded so far)"], "cell_type": "markdown", "metadata": {"_uuid": "0884059b08b805f5a1bb712cba38e7c438730d73", "_cell_guid": "6fab1c30-59a1-4536-ad64-51ea4016df23"}}, {"source": ["# overview of the contents of the dataset\n", "groupedByPerson = videoDF.groupby(\"personName\")\n", "numVidsPerPerson = groupedByPerson.count()['videoID']\n", "groupedByPerson.count().sort_values('videoID', axis=0, ascending=False)\n", "\n", "plt.close('all')\n", "plt.figure(figsize=(25,20))\n", "plt.subplot(2,2,1)\n", "plt.hist(x=numVidsPerPerson,bins=0.5+np.arange(numVidsPerPerson.min()-1,numVidsPerPerson.max()+1))\n", "plt.title('Number of Videos per Person',fontsize=30); \n", "plt.xlabel('Number of Videos',fontsize=25); plt.ylabel('Number of People',fontsize=25)\n", "\n", "plt.subplot(2,2,2)\n", "plt.hist(x=videoDF['videoDuration'],bins=20);\n", "plt.title('Distribution of Video Duration',fontsize=30); \n", "plt.xlabel('duration [frames]',fontsize=25); plt.ylabel('Number of Videos',fontsize=25)\n", "plt.xlim(videoDF['videoDuration'].min()-2,videoDF['videoDuration'].max()+2)\n", "\n", "plt.subplot(2,2,3)\n", "plt.scatter(x=videoDF['imageWidth'], y=videoDF['imageHeight'])\n", "plt.title('Distribution of Image Sizes',fontsize=30)\n", "plt.xlabel('Image Width [pixels]',fontsize=25); plt.ylabel('Image Height [pixels]',fontsize=25)\n", "plt.xlim(0,videoDF['imageWidth'].max() +15)\n", "plt.ylim(0,videoDF['imageHeight'].max()+15)\n", "\n", "plt.subplot(2,2,4)\n", "averageFaceSize_withoutNaNs = np.array(videoDF['averageFaceSize'])\n", "averageFaceSize_withoutNaNs = averageFaceSize_withoutNaNs[np.logical_not(np.isnan(averageFaceSize_withoutNaNs))]\n", "plt.hist(averageFaceSize_withoutNaNs, bins=20);\n", "plt.title('Distribution of Average Face Sizes ',fontsize=30);\n", "plt.xlabel('Average Face Size [pixels]',fontsize=25); plt.ylabel('Number of Videos',fontsize=25);"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "3a4a0d2fef8ee2464cfa88ad3d5fac8d2487eeda", "_cell_guid": "dd606a19-5d79-443c-844f-8adbe0766b46", "_kg_hide-output": true, "_kg_hide-input": true}}, {"source": ["# Define some shape normalization utility functions"], "cell_type": "markdown", "metadata": {"_uuid": "3da2ec380655c4f4643ab764f7904ca2fc479f8c", "_cell_guid": "d0fe22a3-7f6e-4285-8075-db72cd4ed7cb"}}, {"source": ["#%% define shape normalization utility functions\n", "def NormlizeShapes(shapesImCoords):\n", "    (numPoints, numDims, _) = shapesImCoords.shape\n", "    \"\"\"shapesNomalized, scaleFactors, meanCoords  = NormlizeShapes(shapesImCoords)\"\"\"\n", "    \n", "    # calc mean coords and subtract from shapes    \n", "    meanCoords = shapesImCoords.mean(axis=0)\n", "    shapesCentered = np.zeros(shapesImCoords.shape)\n", "    shapesCentered = shapesImCoords - np.tile(meanCoords,[numPoints,1,1])\n", "\n", "    # calc scale factors and divide shapes\n", "    scaleFactors = np.sqrt((shapesCentered**2).sum(axis=1)).mean(axis=0)\n", "    shapesNormlized = np.zeros(shapesCentered.shape)\n", "    shapesNormlized = shapesCentered / np.tile(scaleFactors, [numPoints,numDims,1])\n", "\n", "    return shapesNormlized, scaleFactors, meanCoords\n", "\n", "\n", "def TransformShapeBackToImageCoords(shapesNomalized, scaleFactors, meanCoords):\n", "    \"\"\"shapesImCoords_rec = TransformShapeBackToImageCoords(shapesNomalized, scaleFactors, meanCoords)\"\"\"\n", "    (numPoints, numDims, _) = shapesNomalized.shape\n", "    \n", "    # move back to the correct scale\n", "    shapesCentered = shapesNomalized * np.tile(scaleFactors, [numPoints,numDims,1])\n", "    # move back to the correct location\n", "    shapesImCoords = shapesCentered + np.tile(meanCoords,[numPoints,1,1])\n", "    \n", "    return shapesImCoords"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "60666c9657efde99e1abbba5d382d380e4a31466", "_cell_guid": "b0732bcf-861b-4efb-be60-1ebc1837a756", "collapsed": true, "_kg_hide-input": true}}, {"source": ["# Normalize the 2D and 3D Shapes\n", "remember that like we showed in the [Exploration Script](https://www.kaggle.com/selfishgene/exploring-youtube-faces-with-keypoints-dataset), in order to compare apples to apples (or in this case, shapes to shapes), we need first to normalize the shapes in and manually remove the things that we don't care about (in this case, we want to disregard translation and scale differences between shapes, and model only the shape's shape :-) ) "], "cell_type": "markdown", "metadata": {"_uuid": "99992b70a77357c9a10f0c9d9a130dec98ec6f9c", "_cell_guid": "cef9587a-cbdf-45c8-8025-69ab500f9dfc"}}, {"source": ["#%% Normalize 2D and 3D shapes\n", "\n", "# collect all 2D and 3D shapes from all frames from all videos to a single numpy array matrix\n", "totalNumberOfFrames = videoDF['videoDuration'].sum()\n", "landmarks2D_all = np.zeros((68,2,int(totalNumberOfFrames)))\n", "landmarks3D_all = np.zeros((68,3,int(totalNumberOfFrames)))\n", "\n", "shapeIndToVideoID = {} # dictionary for later useage\n", "endInd = 0\n", "for i, videoID in enumerate(videoDF['videoID']):\n", "    \n", "    # load video\n", "    videoFile = np.load(fullPaths[videoID])\n", "    landmarks2D = videoFile['landmarks2D']\n", "    landmarks3D = videoFile['landmarks3D']\n", "\n", "    startInd = endInd\n", "    endInd   = startInd + landmarks2D.shape[2]\n", "\n", "    # store in one big array\n", "    landmarks2D_all[:,:,startInd:endInd] = landmarks2D\n", "    landmarks3D_all[:,:,startInd:endInd] = landmarks3D\n", "    \n", "    # make sure we keep track of the mapping to the original video and frame\n", "    for videoFrameInd, shapeInd in enumerate(range(startInd,endInd)):\n", "        shapeIndToVideoID[shapeInd] = (videoID, videoFrameInd)\n", "\n", "# normlize shapes\n", "landmarks2D_normlized, _, _  = NormlizeShapes(landmarks2D_all)\n", "landmarks3D_normlized, _, _  = NormlizeShapes(landmarks3D_all)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "0ea28bd97c51de60c0dccc616b253536a2d12756", "_cell_guid": "c666ebfa-6db4-43ec-b093-a2d910629d88", "collapsed": true, "_kg_hide-input": true}}, {"source": ["# Define a utility function to Create a 3D animation\n", "This is essentially the same code in [DrGuillermo's 3D Animation Script](https://www.kaggle.com/drgilermo/3d-kmeans-animation), only I've wrapped it with a function and added a bounding box drawing in order to avoid plotly's automatic rescaling of the axes, thus creating a contious scene and a feeling of a face moving around that scene."], "cell_type": "markdown", "metadata": {"_uuid": "b67422f31221ee5ae85536c9113062b713533397", "_cell_guid": "1303de0a-9aa1-4418-abd6-34d6bf66cd6b"}}, {"source": ["#%% define a utility function to show 3D animation\n", "def ShowAnimation_3D(landmarks3D):\n", "    \n", "    landmarks3D = landmarks3D.copy()\n", "    landmarks3D[:,0,:] = -landmarks3D[:,0,:]\n", "    \n", "    xMin = landmarks3D[:,0,:].min()-5\n", "    xMax = landmarks3D[:,0,:].max()+5\n", "    yMin = landmarks3D[:,1,:].min()-5\n", "    yMax = landmarks3D[:,1,:].max()+5\n", "    zMin = landmarks3D[:,2,:].min()-5\n", "    zMax = landmarks3D[:,2,:].max()+5\n", "    \n", "    boxCorners = np.array([[xMin,yMin,zMin],\n", "                           [xMin,yMin,zMax],\n", "                           [xMin,yMax,zMin],\n", "                           [xMin,yMax,zMax],\n", "                           [xMax,yMin,zMin],\n", "                           [xMax,yMin,zMax],\n", "                           [xMax,yMax,zMin],\n", "                           [xMax,yMax,zMax]])\n", "    \n", "    traversalOrder = [0,1,3,2,0,4,6,2,6,7,3,7,5,1,5,4]\n", "    boxTraceCoords = np.zeros((len(traversalOrder),3))\n", "    for i, corner in enumerate(traversalOrder):\n", "        boxTraceCoords[i,:] = boxCorners[corner,:]\n", "    \n", "    trace1   = go.Scatter3d(name='Jawline', x=landmarks3D[:,0,1][0:17],y=landmarks3D[:,1,1][0:17],z=landmarks3D[:,2,1][0:17],\n", "                            mode='lines+markers',marker=dict(color = 'blue',opacity=0.7,size = 5))\n", "    \n", "    trace2   = go.Scatter3d(name='Right Eyebrow',x=landmarks3D[:,0,1][17:22],y=landmarks3D[:,1,1][17:22],z=landmarks3D[:,2,1][17:22],\n", "                            mode='lines+markers',marker=dict(color = 'blue',opacity=0.7,size = 5))\n", "    \n", "    trace3   = go.Scatter3d(name='Left Eyebrow',x=landmarks3D[:,0,1][22:27],y=landmarks3D[:,1,1][22:27],z=landmarks3D[:,2,1][22:27],\n", "                            mode='lines+markers',marker=dict(color = 'blue',opacity=0.7,size = 5))\n", "    \n", "    trace4   = go.Scatter3d(name='Nose Ridge',x=landmarks3D[:,0,1][27:31],y=landmarks3D[:,1,1][27:31],z=landmarks3D[:,2,1][27:31],\n", "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n", "    \n", "    trace5   = go.Scatter3d(name='Nose Base',x=landmarks3D[:,0,1][31:36],y=landmarks3D[:,1,1][31:36],z=landmarks3D[:,2,1][31:36],\n", "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n", "    \n", "    trace6   = go.Scatter3d(name='Right Eye', x=landmarks3D[:,0,1][36:42],y=landmarks3D[:,1,1][36:42],z=landmarks3D[:,2,1][36:42],\n", "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n", "    \n", "    trace7   = go.Scatter3d(name='Left Eye', x=landmarks3D[:,0,1][42:48],y=landmarks3D[:,1,1][42:48],z=landmarks3D[:,2,1][42:48],\n", "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n", "    \n", "    trace8   = go.Scatter3d(name='Outer Mouth', x=landmarks3D[:,0,1][48:60],y=landmarks3D[:,1,1][48:60],z=landmarks3D[:,2,1][48:60],\n", "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n", "    \n", "    trace9   = go.Scatter3d(name='Inner Mouth', x=landmarks3D[:,0,1][60:68],y=landmarks3D[:,1,1][60:68],z=landmarks3D[:,2,1][60:68],\n", "                            mode='lines+markers',marker=dict(color = 'green',opacity=0.6,size = 5))\n", "        \n", "    boxTrace = go.Scatter3d(name='boundingBox', x=boxTraceCoords[:,0],y=boxTraceCoords[:,1],z=boxTraceCoords[:,2],\n", "                            mode='lines+markers',marker=dict(color = 'red', opacity=1.0,size = 5))\n", "    \n", "    data = [trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8, trace9, boxTrace]\n", "    \n", "    mfr = []\n", "    for t in range(len(landmarks3D[1,1,:])):\n", "        mfr.append({'data' :[{'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][ 0:17],'y':landmarks3D[:,1,t][ 0:17],'z':landmarks3D[:,2,t][ 0:17]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][17:22],'y':landmarks3D[:,1,t][17:22],'z':landmarks3D[:,2,t][17:22]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][22:27],'y':landmarks3D[:,1,t][22:27],'z':landmarks3D[:,2,t][22:27]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][27:31],'y':landmarks3D[:,1,t][27:31],'z':landmarks3D[:,2,t][27:31]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][31:36],'y':landmarks3D[:,1,t][31:36],'z':landmarks3D[:,2,t][31:36]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][36:42],'y':landmarks3D[:,1,t][36:42],'z':landmarks3D[:,2,t][36:42]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][42:48],'y':landmarks3D[:,1,t][42:48],'z':landmarks3D[:,2,t][42:48]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][48:60],'y':landmarks3D[:,1,t][48:60],'z':landmarks3D[:,2,t][48:60]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                              'x':landmarks3D[:,0,t][60:68],'y':landmarks3D[:,1,t][60:68],'z':landmarks3D[:,2,t][60:68]},\n", "                             {'type' : \"scatter3d\",'mode':'lines+markers',\n", "                             'x':boxTraceCoords[:,0],'y':boxTraceCoords[:,1],'z':boxTraceCoords[:,2]}]})\n", "                                 \n", "    \n", "    layout = go.Layout(width=800, height=800, title='3D Face Shape Animation',\n", "                       scene=dict(camera=dict(up     = dict(x= 0, y=-1.0, z=0),\n", "                                              center = dict(x= 0, y= 0.0, z=0),\n", "                                              eye    = dict(x= 0, y= 0.7, z=2),\n", "                                             )\n", "                                 ),\n", "                        updatemenus=[dict(type='buttons', showactive=False,\n", "                                            y=1,\n", "                                            x=1,\n", "                                            xanchor='right',\n", "                                            yanchor='top',\n", "                                            pad=dict(t=0, r=10),\n", "                                            buttons=[dict(\n", "                                                        label='Play Animation',\n", "                                                        method='animate',\n", "                                                        args=[None, dict(frame       = dict(duration=0.04, redraw=True), \n", "                                                                         transition  = dict(duration=0),\n", "                                                                         fromcurrent = True,\n", "                                                                         mode = 'immediate'\n", "                                                                        )\n", "                                                             ]\n", "                                                         )\n", "                                                    ]\n", "                                           )\n", "                                      ]\n", "                      )\n", "                                                    \n", "    fig = dict(data=data, layout=layout, frames=mfr)\n", "    py.iplot(fig)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "76f40b538327c282826ba581c16bcdb0828e489d", "_cell_guid": "c71202e6-0da8-4427-a526-c942cb9ee23e", "collapsed": true, "_kg_hide-input": true}}, {"source": ["# Load a Video and Present it's 3D keypoint Animation\n", "Press the \"Play Animation\" button to play a nice and fast animation, don't wait for the automatic animation to finish (it's too slow)"], "cell_type": "markdown", "metadata": {"_uuid": "c49c4e688437d48002da3b36491f3603281988ec", "_cell_guid": "a5f8254e-feb3-418f-9214-9475fc7614f8"}}, {"source": ["#%% load a 3D landmarks sequence and present it\n", "personToUse = 'Laura_Bush_4'\n", "videoFile = np.load(fullPaths[personToUse])\n", "landmarks3D_curr = videoFile['landmarks3D']\n", "\n", "ShowAnimation_3D(landmarks3D_curr)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "771d42a27e2be84cb8256c0b1f5618dd129fbb22", "_cell_guid": "e564b3f0-654e-437c-9b26-3715e18581a1", "collapsed": true}}, {"source": ["I don't know about you, but I think this is nice!   \n", "Really nice work [DrGuillermo](https://www.kaggle.com/drgilermo) did there!"], "cell_type": "markdown", "metadata": {"_uuid": "ca25d0c0631037b82b52f3564ad2dd8ce6a9e007", "_cell_guid": "4c66643c-a9fe-4fb5-a49c-2272848fe420"}}, {"source": ["# Build a 3D Shape Model by fitting a Multivariate Gaussian (PCA)\n", "Remember that PCA is essentially fitting a multivariate gaussian distribution with a low rank covariance matrix"], "cell_type": "markdown", "metadata": {"_uuid": "c025e32bfba1a836b693a3e56953cb3f592825b0", "_cell_guid": "01001838-4087-454e-b29b-2c584d9bd51a"}}, {"source": ["#%% build 3D shape model\n", "numComponents = 30\n", "\n", "normalizedShapesTable = np.reshape(landmarks3D_normlized, [68*3, landmarks3D_normlized.shape[2]]).T\n", "shapesModel = decomposition.PCA(n_components=numComponents, whiten=True, random_state=1).fit(normalizedShapesTable)\n", "print('Total explained percent by PCA model with %d components is %.1f%s' %(numComponents, 100*shapesModel.explained_variance_ratio_.sum(),'%'))"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "14329ba4f27554dc8dbf69953daad5736df7f707", "_cell_guid": "6291c446-6905-4972-aa3a-55636cbc46a5", "collapsed": true}}, {"source": ["# Project the original shapes onto our Shape Model and Reconstruct\n", "The code is very simple, you are more than welcome to unhide and check it out"], "cell_type": "markdown", "metadata": {"_uuid": "3fc6a3caea4aa2100714bcd9678ad4cd2e56247c", "_cell_guid": "85ad49cd-83a9-4a4f-ab00-8ead26bbcf53"}}, {"source": ["#%% interpret the shapes using our shape model (project and reconstruct)\n", "\n", "# normlize shapes (and keep the scale factors and mean coords for later reconstruction)\n", "landmarks3D_norm, scaleFactors, meanCoords  = NormlizeShapes(landmarks3D_curr)\n", "# convert to matrix form\n", "landmarks3D_norm_table = np.reshape(landmarks3D_norm, [68*3, landmarks3D_norm.shape[2]]).T\n", "# project onto shapes model and reconstruct\n", "landmarks3D_norm_table_rec = shapesModel.inverse_transform(shapesModel.transform(landmarks3D_norm_table))\n", "# convert back to shapes (numKeypoint, numDims, numFrames)\n", "landmarks3D_norm_rec = np.reshape(landmarks3D_norm_table_rec.T, [68, 3, landmarks3D_norm.shape[2]])\n", "# transform back to image coords\n", "landmarks3D_curr_rec = TransformShapeBackToImageCoords(landmarks3D_norm_rec, scaleFactors, meanCoords)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "f0f1c93dd601391a42f12c677152e1b81ca788f0", "_cell_guid": "bc2f7d98-87e5-46eb-9b7f-895599fa31c1", "collapsed": true, "_kg_hide-input": true}}, {"source": ["# Show the animation of the filtered version of the original shape"], "cell_type": "markdown", "metadata": {"_uuid": "1e018a1ed2f1fb39691d28c78c9510866ab4f37a", "_cell_guid": "589dcdd6-ea22-4255-a77e-63496156ad07"}}, {"source": ["# show the new animation\n", "ShowAnimation_3D(landmarks3D_curr_rec)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "42ff57c17bdfeaaaa724e9ff39a6731747e6d96c", "_cell_guid": "89212048-6349-4323-958b-2bcaa581b7d9", "collapsed": true}}, {"source": ["### Note how much smoother this shape is!\n", "This is just the result of applying a prior to constrain the shape at each particular frame according to the distribution of shapes across all frames of all individuals in the dataset. The power of statistics is sometimes mind blowing!\n", "Hard to decide what is more awsome, the plotly library that allwos us to show these nice animations, or math that allows us to create the smoothed even nicer versions of these animations"], "cell_type": "markdown", "metadata": {"_uuid": "e399acb265f540cf7bb5b98a054acea91eb5ba3a", "_cell_guid": "0c57f041-9fa1-453b-ae90-dd7d42e97b72"}}, {"source": ["# Plot $(x(t),y(t),z(t))$ traces for several selected keypoints"], "cell_type": "markdown", "metadata": {"_uuid": "08c54438b8e16ca80ed4f83aa72c3a1340e0d2b7", "_cell_guid": "2754dc64-ee1d-4170-ad25-7b4735479a3b"}}, {"source": ["#%% plot x(t), y(t), z(t) for several keypoints before and after filtering\n", "selectedKeypointInds    = [ 30, 33,  36, 39,  42, 45,  51, 57,  62, 66,  48, 54]\n", "selectedKeypointColors  = ['g','g', 'r','m', 'm','r', 'b','b', 'g','g', 'y','y']\n", "selectedKeypointStrings = ['nose tip', 'nose base',  'right eye outer','right eye inner',  'left eye inner','left eye outer',\n", "                           'outer mouth top','outer mouth bottom',  'inner mouth top','inner mouth bottom',\n", "                           'right mouth corner','left mouth corner']\n", "\n", "plt.figure(figsize=(13,11)); plt.suptitle('Original Traces', fontsize=22)\n", "for subplotInd, yLabel in enumerate(['x(t)','y(t)','z(t)']):\n", "    plt.subplot(3,1,subplotInd+1); plt.ylabel(yLabel,fontsize=20)\n", "    for k,c,legendLabel in zip(selectedKeypointInds,selectedKeypointColors,selectedKeypointStrings):\n", "        plt.plot(landmarks3D_curr[k,subplotInd,:],c=c,label=legendLabel)\n", "    if subplotInd == 0: \n", "        plt.legend(bbox_to_anchor=(0,1,1,0), shadow=True,\n", "                   loc=3, ncol=4, mode=\"expand\", borderaxespad=0, fontsize=12)\n", "plt.xlabel('time [frame]',fontsize=20);"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "e0c739466bf64e303ea94f1566207ab66c8a09c9", "_cell_guid": "b9389d3a-c7d9-4197-a9cb-6ca0c68721b4", "collapsed": true, "_kg_hide-input": true}}, {"source": ["# Show the \"Spatially filtered\" keypoint traces\n", "Red - Original traces  \n", "Blue - Spatially filtered"], "cell_type": "markdown", "metadata": {"_uuid": "13d7e7cee6af5c8dbca7177ca8ed2214d4f5df6f", "_cell_guid": "0638c951-df75-4413-a377-10a8aa5caed9"}}, {"source": ["plt.figure(figsize=(13,11)); plt.suptitle('Original Vs. \"Spatially\" Filtered Traces', fontsize=22)\n", "for subplotInd, yLabel in enumerate(['x(t)','y(t)','z(t)']):\n", "    plt.subplot(3,1,subplotInd+1); plt.ylabel(yLabel,fontsize=25)\n", "    plt.plot(landmarks3D_curr[selectedKeypointInds,subplotInd,:].T,c='r')\n", "    plt.plot(landmarks3D_curr_rec[selectedKeypointInds,subplotInd,:].T,c='b')\n", "plt.xlabel('time [frame]',fontsize=20);"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "8e23678ff6d5cfb24b90f92687116735650691fd", "_cell_guid": "55cd7b81-000d-4688-b883-e149b10fe3b4", "collapsed": true, "_kg_hide-input": true}}, {"source": ["The blue traces look smoother, but not that much smoother. Maybe we should explicitly smoothen them temporally as well?"], "cell_type": "markdown", "metadata": {"_uuid": "4e6983d2c23f4c476ac7a7e5170313e6ef8232fa", "_cell_guid": "9d6fd25c-b8b7-4975-af9f-e0e8b3bd1468"}}, {"source": ["# Temporally Smoothen the keypoint movement\n", "Red - Original traces  \n", "Blue - Spatially and Temporally filtered"], "cell_type": "markdown", "metadata": {"_uuid": "d052df3da6ba1ba6a134b9300ddd4b8f1320fcce", "_cell_guid": "6013194a-782e-47a5-ac1e-99fdb74b4f70"}}, {"source": ["#%% apply temporal filtering on the 3D points and show filtered signals\n", "filterHalfLength = 2\n", "temporalFilter = np.ones((1,1,2*filterHalfLength+1))\n", "temporalFilter = temporalFilter / temporalFilter.sum()\n", "\n", "startTileBlock = np.tile(landmarks3D_curr_rec[:,:,0][:,:,np.newaxis],[1,1,filterHalfLength])\n", "endTileBlock = np.tile(landmarks3D_curr_rec[:,:,-1][:,:,np.newaxis],[1,1,filterHalfLength])\n", "landmarks3D_curr_rec_padded = np.dstack((startTileBlock,landmarks3D_curr_rec,endTileBlock))\n", "landmarks3D_curr_rec_filtered = signal.convolve(landmarks3D_curr_rec_padded, temporalFilter, mode='valid', method='fft')\n", "\n", "plt.figure(figsize=(13,11)); plt.suptitle('Original Vs. Spatio-Temporally Filtered Traces', fontsize=22)\n", "for subplotInd, yLabel in enumerate(['x(t)','y(t)','z(t)']):\n", "    plt.subplot(3,1,subplotInd+1); plt.ylabel(yLabel,fontsize=20)\n", "    plt.plot(landmarks3D_curr[selectedKeypointInds,subplotInd,:].T,c='r')\n", "    plt.plot(landmarks3D_curr_rec_filtered[selectedKeypointInds,subplotInd,:].T,c='b')\n", "plt.xlabel('time [frame]',fontsize=20);"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "7e291e9fc1eb44d8d4f025111d57ce64db627704", "_cell_guid": "6e002c4f-35ba-460e-9171-897ad54a283c", "collapsed": true, "_kg_hide-input": true}}, {"source": ["Now we can see the traces are much smoother, but we need to make sure that we didn't accidentally ruin anything."], "cell_type": "markdown", "metadata": {"_uuid": "778b65b23e30633e0b45693b82eda6a3852ef45e", "_cell_guid": "905b4973-9d84-424a-9c6a-24eadfbd41c4"}}, {"source": ["# Show the animation of the new filtered version of the shape"], "cell_type": "markdown", "metadata": {"_uuid": "65b7e44d2b5e0eec1bcd68807772b4bc5bd6bd1f", "_cell_guid": "82d130dd-3b5e-4fef-95c6-afb787fcf5ec"}}, {"source": ["#%% show animation of the temporally filtered 3D points\n", "ShowAnimation_3D(landmarks3D_curr_rec_filtered)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "c8c5b781338b5288d682b2ae56cb47a3ef3e3ad5", "_cell_guid": "ee807c8c-cbc9-4355-8335-852b605084b4", "collapsed": true}}, {"source": ["This is much smoother looking. Even to a point that the animation appears quite slow, so we need to make a final verfication stage and view these points overlaid on the original video and see if we've messed something up or not."], "cell_type": "markdown", "metadata": {"_uuid": "63e140129b67f02c5b96a068453e43b33caa9deb", "_cell_guid": "e203cd1f-d460-4ae6-8c01-5493960e34e4"}}, {"source": ["# Embed the $(x,y)$ coordinates into the video itself\n", "mark the the keypoints with green"], "cell_type": "markdown", "metadata": {"_uuid": "62a8ef992f9d23654c6d0da39012917f17218e3b", "_cell_guid": "ddf87ab7-0a2d-486b-89f4-bcf6ebeff1be"}}, {"source": ["#%% helper function: create videos with keypoints overlaid for each of the 3 processing stages\n", "def CreateVideosWithMarkingsSideBySide(colorImages, landmarks3D_curr, landmarks3D_curr_rec, landmarks3D_curr_rec_filtered):\n", "    imageWithMarkings_orig   = colorImages.copy()\n", "    imageWithMarkings_sp     = colorImages.copy()\n", "    imageWithMarkings_sp_tmp = colorImages.copy()\n", "    \n", "    # paint requested channel\n", "    channelToMark = 1\n", "    for frame in range(colorImages.shape[3]):\n", "        for k in range(landmarks3D_curr.shape[0]):\n", "            for dh in [-1,0,1]:\n", "                for dw in [-1,0,1]:\n", "                    locH_orig   = int(np.round(landmarks3D_curr[k,1,frame])) + dh\n", "                    locW_orig   = int(np.round(landmarks3D_curr[k,0,frame])) + dw\n", "                    \n", "                    locH_sp     = int(np.round(landmarks3D_curr_rec[k,1,frame])) + dh\n", "                    locW_sp     = int(np.round(landmarks3D_curr_rec[k,0,frame])) + dw\n", "                    \n", "                    locH_sp_tmp = int(np.round(landmarks3D_curr_rec_filtered[k,1,frame])) + dh\n", "                    locW_sp_tmp = int(np.round(landmarks3D_curr_rec_filtered[k,0,frame])) + dw\n", "                    try:\n", "                        imageWithMarkings_orig[locH_orig,locW_orig,channelToMark,frame] = 255\n", "                        imageWithMarkings_sp[locH_sp,locW_sp,channelToMark,frame] = 255\n", "                        imageWithMarkings_sp_tmp[locH_sp_tmp,locW_sp_tmp,channelToMark,frame] = 255\n", "                    except:\n", "                        pass\n", "            \n", "    SideBySide = np.hstack((imageWithMarkings_orig,imageWithMarkings_sp,imageWithMarkings_sp_tmp))\n", "    return SideBySide"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "a2b034079a948c4c36443189bffd10d06de8339e", "_cell_guid": "d4d5d141-8b0e-4c32-9dc7-e838ed1afeb4", "collapsed": true}}, {"source": ["# Write a Video with all three stages side by side\n"], "cell_type": "markdown", "metadata": {"_uuid": "f82088e5c373c16ac5374de9d91e91ea3f7a9717", "_cell_guid": "c8607d31-868b-43f8-b26c-f4607fc85dce"}}, {"source": ["SideBySide = CreateVideosWithMarkingsSideBySide(videoFile['colorImages'], landmarks3D_curr, landmarks3D_curr_rec, landmarks3D_curr_rec_filtered)\n", "\n", "#%% show video animations\n", "def WriteColorVideo(video, filename='sample.gif', fps=20):\n", "    writer = imageio.get_writer(filename, fps=fps)\n", "    for frame in range(video.shape[-1]):\n", "        writer.append_data(video[:, :, :, frame])\n", "    writer.close()\n", "\n", "#WriteColorVideo(SideBySide,'processingStages.gif',fps=25)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "8a04d32104adb1e6f09c113013c1cf2386b507c3", "_cell_guid": "077ba547-299a-48fb-b82d-13f506edee74", "collapsed": true}}, {"source": ["It appears that the standard library I use for writing videos and gifs (**imageio** library) is not present in the kaggle kernels environment, so we'll need to find a **workaround** for now, but on your personal computers you can definatley use it."], "cell_type": "markdown", "metadata": {"_uuid": "5ba7e9f45da040f5004c694e9822a5fa187149ca", "_cell_guid": "e3ae6dba-b2a2-4383-8a2b-79704fc773c7"}}, {"source": ["# Function that writes gif files"], "cell_type": "markdown", "metadata": {"_uuid": "1cba2896a78b2b1f5a6d05847b4e08fae0973c3a", "_cell_guid": "97915735-9c4c-4799-acdd-4b27973cf480"}}, {"source": ["MSEC_PER_FRAME    = 40\n", "MSEC_REPEAT_DELAY = 500\n", "\n", "# Create an animated GIF file from a sequence of images\n", "def build_gif(inImages, fname=None, show_gif=True, save_gif=True, title=''):\n", "    fig = plt.figure(figsize=(12,5))\n", "    ax = fig.add_subplot(111)\n", "    ax.set_axis_off()\n", "    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, \n", "                        wspace=None, hspace=None)  # removes white border\n", "    \n", "    imgs = [ (ax.imshow(inImages[:,:,:,frame]), \n", "              ax.set_title(title), \n", "              ax.annotate(frame,(5,5))) for frame in range(inImages.shape[3]) ] \n", "\n", "    img_anim = animation.ArtistAnimation(fig, imgs, interval=MSEC_PER_FRAME, \n", "                                         repeat_delay=MSEC_REPEAT_DELAY, blit=False)\n", "    if save_gif:\n", "        print('Writing:', fname)\n", "        img_anim.save(fname, writer='imagemagick')\n", "    if show_gif:\n", "        plt.show();\n", "    plt.clf() # clearing the figure when done prevents a memory leak "], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "94668c4d34bb52a339a0729adb27e4db0c48f266", "_cell_guid": "23501a6a-83b4-41d9-a11d-c1620c43c6fd", "collapsed": true}}, {"source": ["The above workaround was stolen from [this script](https://www.kaggle.com/chefele/animated-images-with-outlined-nerve-area) by [Christopher Hefele](https://www.kaggle.com/chefele)"], "cell_type": "markdown", "metadata": {"_uuid": "cef5067a0f192ff333a252d0fbfc45333e20514b", "_cell_guid": "ac903cb7-a3bd-457d-844b-85dd9ea0c395"}}, {"source": ["titleStr = 'original video | spatially filtered | spatio-temporally filtered'\n", "build_gif(SideBySide, fname='smoothing_stages_side_by_side.gif', show_gif=False, save_gif=True, title=titleStr)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "d296d505737da5905d76a370a80866fff5253a3d", "_cell_guid": "7747d047-c7fd-41dc-b544-d2ecd8b33bb4", "_kg_hide-output": false, "collapsed": true}}, {"source": ["## You should be able to view the gif file under the ***Output Tab*** of the kernel"], "cell_type": "markdown", "metadata": {"_uuid": "e30561e0fa7855c355ae60cfab71de89033a8831", "_cell_guid": "d1ae5657-4d4d-4a51-b74b-a12eff4b67d8"}}, {"source": ["# Let's Repeat this process again for several additional videos"], "cell_type": "markdown", "metadata": {"_uuid": "538f85ec796be3ef8130243e8f91b3770142471a", "_cell_guid": "cac0b9e8-910a-4642-993f-d4b1060f2159"}}, {"source": ["for personToUse in ['Martin_Sheen_5','Elizabeth_Berkeley_1','Tom_Hanks_3','Reese_Witherspoon_4','Kurt_Warner_1']:\n", "\n", "    videoFile = np.load(fullPaths[personToUse])\n", "    landmarks3D_curr = videoFile['landmarks3D']\n", "    \n", "    landmarks3D_norm, scaleFactors, meanCoords  = NormlizeShapes(landmarks3D_curr)\n", "    landmarks3D_norm_table = np.reshape(landmarks3D_norm, [68*3, landmarks3D_norm.shape[2]]).T\n", "    landmarks3D_norm_table_rec = shapesModel.inverse_transform(shapesModel.transform(landmarks3D_norm_table))\n", "    landmarks3D_norm_rec = np.reshape(landmarks3D_norm_table_rec.T, [68, 3, landmarks3D_norm.shape[2]])\n", "    landmarks3D_curr_rec = TransformShapeBackToImageCoords(landmarks3D_norm_rec, scaleFactors, meanCoords)\n", "    \n", "    startTileBlock = np.tile(landmarks3D_curr_rec[:,:,0][:,:,np.newaxis],[1,1,filterHalfLength])\n", "    endTileBlock   = np.tile(landmarks3D_curr_rec[:,:,-1][:,:,np.newaxis],[1,1,filterHalfLength])\n", "    landmarks3D_curr_rec_padded = np.dstack((startTileBlock,landmarks3D_curr_rec,endTileBlock))\n", "    \n", "    landmarks3D_curr_rec_filtered = signal.convolve(landmarks3D_curr_rec_padded, temporalFilter, mode='valid', method='fft')\n", "    \n", "    SideBySide = CreateVideosWithMarkingsSideBySide(videoFile['colorImages'], landmarks3D_curr, landmarks3D_curr_rec, landmarks3D_curr_rec_filtered)\n", "    build_gif(SideBySide, fname='smoothing_stages_' + personToUse + '.gif', show_gif=False, save_gif=True, title=titleStr)"], "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_uuid": "92cf0c3c11779f697d22d203a15108de87c34fe6", "_cell_guid": "70e1128f-c69b-447d-a3d8-6b1a7ef9baba", "collapsed": true}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "3.6.3", "name": "python", "file_extension": ".py"}}, "nbformat_minor": 1}