{"cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "126350f6-71da-4ca5-b5f5-dd1f944505cc", "_uuid": "a8f52e4e890dcd596f760e3724b940040c00105b"}, "source": ["\n", "> \"Of the 95% of Japanese that eat three meals a day, most people consider dinner to be the most important. More than 80% of them usually have dinner at home with their families. But as for what they actually eat, over 60% of Japanese rely on home meal replacement (ready-to-eat food bought elsewhere and taken home) at least once or twice a month. And more than 70% enjoy dining out at least once or twice monthly. This is the picture that emerged when Trends in Japan conducted an online survey concerning attitudes among Japanese people toward eating\" [Japanese Online Survey] (http://)http://web-japan.org/trends01/article/020403fea_r.html \n", "\n", "\n", "This notebook is exploratory data analysis and divided into the following:\n", "\n", "Business Analysis:\n", "1. Geographical distribution of the store \n", "2. Number of visitors  trend  \n", "3. Visitors by genre\n", "4. Visitors by weekdays trend and group size\n", "5. Reservations trends\n", "6. Productivity by air_store_id\n", "\n", "Feature Engineering\n", "\n", "Outliers\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4403c831-b88b-4b9b-8cef-18b43e24be1d", "_uuid": "5d1df8c1c47ddc056b03de87ad2bb35742b8de0c"}, "source": ["Basic information of the dataset:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "4c02bc89-69f3-47d9-890b-1bb2d1295800", "_uuid": "389e9958fa616429b2c0a7a1b20f36c86c4b86be"}, "source": ["import numpy as np\n", "import pandas as pd\n", "from sklearn import ensemble, neighbors, linear_model, metrics, preprocessing\n", "from datetime import datetime\n", "import glob, re\n", "import time, datetime\n", "from datetime import timedelta\n", "\n", "import matplotlib.pyplot as plt\n", "plt.style.use('fivethirtyeight')\n", "import seaborn as sns\n", "color = sns.color_palette()\n", "\n", "%matplotlib inline\n", "\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")\n", "\n", "# from JdPaletto & the1owl1\n", "# JdPaletto - https://www.kaggle.com/jdpaletto/surprised-yet-part2-lb-0-503?scriptVersionId=1867420\n", "# the1owl1 - https://www.kaggle.com/the1owl/surprise-me\n", "start1 =time.time()\n", "data = {\n", "    'tra': pd.read_csv('../input/air_visit_data.csv'),\n", "    'as': pd.read_csv('../input/air_store_info.csv'),\n", "    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n", "    'ar': pd.read_csv('../input/air_reserve.csv'),\n", "    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n", "    'id': pd.read_csv('../input/store_id_relation.csv'),\n", "    'tes': pd.read_csv('../input/sample_submission.csv'),\n", "    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n", "    }\n", "\n", "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])# bring air id to hpg reserve data\n", "data['hs'] = pd.merge(data['hs'], data['id'], how='inner', on=['hpg_store_id'])# bring air id to hpg stores\n", "\n", "print('Data structure.......................')\n", "print('Training data....',data['tra'].shape)\n", "print('Unique store id in training data',len(data['tra']['air_store_id'].unique()))\n", "print('Id data....',data['id'].shape)\n", "print('Air store data....',data['as'].shape,'& unique-',data['as']['air_store_id'].unique().shape)\n", "print('Hpg store data....',data['hs'].shape,'& unique-',data['hs']['hpg_store_id'].unique().shape)\n", "print('Air reserve data....',data['ar'].shape,'& unique-',data['ar']['air_store_id'].unique().shape)\n", "print('Hpg reserve data....',data['hr'].shape,'& unique-',data['hr']['air_store_id'].unique().shape)\n", "      \n", "#converting datetime to date for reservation data\n", "for df in ['ar','hr']:\n", "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n", "    data[df]['visit_hour'] = data[df]['visit_datetime'].dt.hour\n", "    data[df]['visit_date'] = data[df]['visit_datetime'].dt.date\n", "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n", "    data[df]['reserve_hour'] = data[df]['reserve_datetime'].dt.hour\n", "    data[df]['reserve_date'] = data[df]['reserve_datetime'].dt.date\n", "    \n", "    data[df+'_hour'] = data[df]#keeping original\n", "        \n", "    #calculate reserve time difference and summarizing ar,hr to date\n", "    data[df]['reserve_day_'+df] = data[df].apply(\n", "        lambda r: (r['visit_date'] - r['reserve_date']).days, axis=1)\n", "    data[df] = data[df].groupby(['air_store_id','visit_date'], as_index=False)[[\n", "        'reserve_day_'+df, 'reserve_visitors']].sum().rename(columns={'reserve_visitors':'reserve_visitors_'+df})\n", "    \n", "#breaking down dates on training data & summarizing \n", "data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n", "data['tra']['day'] = data['tra']['visit_date'].dt.day\n", "data['tra']['dow'] = data['tra']['visit_date'].dt.weekday\n", "data['tra']['dow_name'] = data['tra']['visit_date'].dt.weekday_name\n", "data['tra']['year'] = data['tra']['visit_date'].dt.year\n", "data['tra']['month'] = data['tra']['visit_date'].dt.month\n", "data['tra']['week'] = data['tra']['visit_date'].dt.week\n", "data['tra']['quarter'] = data['tra']['visit_date'].dt.quarter\n", "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n", "data['tra']['year_mth'] = data['tra']['year'].astype(str)+'-'+data['tra']['month'].astype(str)\n", "\n", "\n", "#extracting store id and date info from test data\n", "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n", "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n", "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n", "data['tes']['day'] = data['tes']['visit_date'].dt.day\n", "data['tes']['dow'] = data['tes']['visit_date'].dt.weekday\n", "data['tes']['dow_name'] = data['tes']['visit_date'].dt.weekday_name\n", "data['tes']['year'] = data['tes']['visit_date'].dt.year\n", "data['tes']['month'] = data['tes']['visit_date'].dt.month\n", "data['tes']['week'] = data['tes']['visit_date'].dt.week\n", "data['tes']['quarter'] = data['tes']['visit_date'].dt.quarter\n", "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n", "data['tes']['year_mth'] = data['tes']['year'].astype(str)+'-'+data['tes']['month'].astype(str)\n", "\n", "#extract unique stores based on test data and populate dow 1 to 6\n", "unique_stores = data['tes']['air_store_id'].unique()#extract unique stores id from test data\n", "\n", "store_7days = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) \n", "                    for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n", "store_sum = pd.DataFrame({'air_store_id': unique_stores})\n", "\n", "# mapping train data dow to stores(test data) - min, mean, median, max, count \n", "tmp = data['tra'].groupby(['air_store_id'], as_index=False)[\n", "    'visitors'].sum().rename(columns={'visitors':'total_visitors'})\n", "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id']) \n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n", "    'visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n", "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow'])\n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n", "    'visitors'].median().rename(columns={'visitors':'median_visitors'})\n", "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow'])\n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n", "    'visitors'].max().rename(columns={'visitors':'max_visitors'})\n", "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow'])\n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)[\n", "    'visitors'].count().rename(columns={'visitors':'count_observations'})\n", "store_7days = pd.merge(store_7days, tmp, how='left', on=['air_store_id','dow']) \n", "# map stores(test) to store genre and location detail\n", "store_7days = pd.merge(store_7days, data['as'], how='left', on=['air_store_id']) \n", "#map to hpg genre and area\n", "store_7days = pd.merge(store_7days, data['hs'][['air_store_id','hpg_genre_name','hpg_area_name']], \n", "                       how='left', on=['air_store_id']) \n", "\n", "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n", "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n", "\n", "hf=data['hol']['holiday_flg']\n", "dw=data['hol']['day_of_week']\n", "data['hol']['long_wknd']=0\n", "\n", "for i in range(len(data['hol'])):\n", "    if (hf[i]==1)&(dw[i]=='Friday'):\n", "        data['hol']['long_wknd'][i]=1\n", "        data['hol']['long_wknd'][i+1]=1\n", "        data['hol']['long_wknd'][i+2]=1\n", "          \n", "    if (hf[i]==1)&(dw[i]=='Monday'):\n", "        data['hol']['long_wknd'][i]=1\n", "        data['hol']['long_wknd'][i-1]=1\n", "        data['hol']['long_wknd'][i-2]=1\n", "\n", "\n", "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n", "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n", "train = pd.merge(train, store_7days, how='left', on=['air_store_id','dow']) \n", "test = pd.merge(test, store_7days, how='left', on=['air_store_id','dow'])\n", "\n", "for df in ['ar','hr']:\n", "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n", "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n", "\n", "#col = [c for c in train if c not in ['id', 'air_store_id','visit_date','visitors']]\n", "\n", "#calculate qoq\n", "qoq= train.groupby(['air_store_id','year','quarter'])['visitors'].sum()\n", "qoq=qoq.unstack(0)\n", "qoq=pd.DataFrame(qoq.to_records())\n", "qoq=qoq.transpose()\n", "qoq.drop(['year','quarter'],inplace=True)\n", "qoq['2016Q2']=qoq[1]/qoq[0]*100\n", "qoq['2016Q3']=qoq[2]/qoq[1]*100\n", "qoq['2016Q4']=qoq[3]/qoq[2]*100\n", "qoq['2017Q1']=qoq[4]/qoq[3]*100\n", "lst=['2016Q2','2016Q3','2016Q4','2017Q1']\n", "qoq=qoq[lst]\n", "qoq['qoq_count']=qoq.apply(lambda x: x.count(), axis=1) \n", "qoq['qoq_growth']=qoq.apply(lambda x: x[x>100].count(), axis=1)\n", "qoq['qoq_growth_pct'] = round(qoq['qoq_growth'] /qoq['qoq_count'],2)\n", "qoq.index.names=['air_store_id']\n", "qoq.reset_index(inplace=True)\n", "\n", "train=pd.merge(train, qoq, how='left', on='air_store_id')\n", "\n", "train = train.fillna(0) #change to one for algo training\n", "test = test.fillna(0)\n", "#df=df.rename(columns = {'two':'new_name'})\n", "train['v_no_reservation']=train['visitors']-train['reserve_visitors_ar']-train['reserve_visitors_hr']\n", "print(round(time.time()-start1,4))"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4a834345-fd03-4ada-990d-3e33406da156", "_uuid": "3c10050050062d1c32f5b58e63b411fc157f641b"}, "source": ["Time series of the data set"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "cee5d240-95c1-4a63-afc6-24fb0dbbaa02", "_uuid": "18df6dfeb25a1c00635abfcd20c47de56df16519"}, "source": ["print('Dates................')\n", "print('train date- ,',train['visit_date'].min(),' to ',train['visit_date'].max())\n", "print('test date - ,',test['visit_date'].min(),' to ',test['visit_date'].max())\n", "print('holiday df- ,',data['hol']['visit_date'].min(),' to ',data['hol']['visit_date'].max())"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5fbcbeb7-44c6-42de-b4b5-e654e82194af", "_uuid": "a78ac86fb2950e59140a66e2f301b5c29c8c4308"}, "source": ["**1. Geographical distribution of the store and holidays in Japan**"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2a38893e-13e1-4f04-8bab-7622c719a413", "_uuid": "1d23f13b2f4b7d58fc328626a6451c993958cdb6"}, "source": ["Number of location of the stores- grouped by the same latitude + longitude"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "b417ca81-2d68-4350-a283-1942242e1660", "_uuid": "31cef9e386be7a0c1e8be687edf0437eb244b706"}, "source": ["print(len(store_7days.groupby(['latitude','longitude'])['latitude','longitude'].size().reset_index()), 'physical stores')"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "0e9f91b4-63c7-4eed-a274-8a61c9228944", "_uuid": "f55c47d2824563e0ac58f5dee5d8b87154a88944"}, "source": ["Stores location accross Japan in geographical heatmap"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "c6e619a7-6a95-4fe3-8002-914b42d88583", "_uuid": "6be96ac8b7ce47ec55cafd33b53904d0f6871091"}, "source": ["import folium\n", "from folium import plugins\n", "\n", "location =store_7days.groupby(['latitude', 'longitude']).size().reset_index()\n", "locationheat = location[['latitude', 'longitude']]\n", "locationheat = locationheat.values.tolist()\n", "\n", "map1 = folium.Map(location=[39, 139], \n", "                        tiles = \"Stamen Watercolor\",# width=1000, height=500,\n", "                        zoom_start = 5)\n", "heatmap=plugins.HeatMap(locationheat).add_to(map1)\n", "map1\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e6d433ce-a806-4d9b-a9c9-62f3878f2b90", "_uuid": "df386b20201342a6f02011931fd368b345a81ad3"}, "source": ["Store and their genres accross Japan. Probably a physical store has multiple genres with different air_store_id"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "7ec22a27-3da2-4009-9581-9a66ce5a69cf", "_uuid": "3bb5d734cedbaf7e9face6ed7e2c32952a0c9159"}, "source": ["location =store_7days.groupby(['air_store_id','air_genre_name'])['latitude','longitude'].mean().reset_index()\n", "locationlist = location[['latitude', 'longitude']]\n", "locationlist = locationlist.values.tolist()\n", "map2 = folium.Map(location=[39, 139], \n", "                        tiles = \"Stamen Toner\",# width=1000, height=500,\n", "                        zoom_start = 5)\n", "marker_cluster=plugins.MarkerCluster().add_to(map2)\n", "for point in range(0, len(location)):\n", "    folium.Marker(locationlist[point], popup=location['air_genre_name'][point], \n", "    icon=folium.Icon(color='white', icon_color='red', \n", "                     #icon='fa fa-info-circle',\n", "                     icon='fa fa-circle-o-notch fa-spin',\n", "                     angle=0, \n", "                     prefix='fa')).add_to(marker_cluster)\n", "map2"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "f613b931-790d-466d-bfe0-be2fe3a21b9b", "_uuid": "4c37b02328060171dd55d93957e89fd3023684ce"}, "source": ["Visualising holidays and weekend for the prediction period. There will be 3 consecutive holiday in May."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "5bd38be4-2973-4b6b-a275-62f0517c3cc8", "_uuid": "3f99bd1f53583d131f1bb74cec97c43d6e01a1fb"}, "source": ["data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n", "data['hol']['day_month'] = data['hol']['visit_date'].dt.day\n", "data['hol']['day'] = data['hol']['visit_date'].dt.weekday\n", "data['hol']['week'] = data['hol']['visit_date'].dt.week\n", "data['hol']['month'] = data['hol']['visit_date'].dt.month\n", "data['hol']['quarter'] = data['hol']['visit_date'].dt.quarter\n", "data['hol']['year'] = data['hol']['visit_date'].dt.year\n", "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n", "\n", "def wkn(x):\n", "    if x>4:\n", "        return 1\n", "    else:\n", "        return 0\n", "\n", "data['hol']['weekend']=data['hol']['day'].apply(wkn)\n", "\n", "hols201704=data['hol'][(data['hol']['year']==2017)&(data['hol']['month']==4)]\n", "hols=hols201704[['day_month','holiday_flg']].set_index('day_month')\n", "wknd=hols201704[['day_month','weekend']].set_index('day_month')\n", "hols201705=data['hol'][(data['hol']['year']==2017)&(data['hol']['month']==5)]\n", "hols2=hols201705[['day_month','holiday_flg']].set_index('day_month')\n", "wknd2=hols201705[['day_month','weekend']].set_index('day_month')\n", "\n", "f, ax=plt.subplots(2,1, figsize=(15,4))\n", "hols.plot(kind='bar', ax=ax[0], color='b')\n", "wknd.plot(kind='bar', ax=ax[0], color='grey')\n", "hols2.plot(kind='bar', ax=ax[1], color='b')\n", "wknd2.plot(kind='bar', ax=ax[1], color='grey')\n", "ax[0].set_title('April & May 2017 Holidays & Weekends')"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ea20fa3d-dcae-4333-a929-71b0c1dc5715", "_uuid": "a7dc3c0ce80985d533fb11cde85ea0b4a992c71d"}, "source": ["**2. Number of visitors and genres trend **"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c53a363e-012e-41e1-9b74-d047f76d1958", "_uuid": "f06196eaddee15920e2c15d127d0ca6e87a98e98"}, "source": ["Visitors and reservation time series. Walk in visitors are far more than customers with reservation. A drastic drop in number of visitors during new year due to store closure at certain places.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "f697c2bd-9916-472b-bfaa-8c69088cc588", "_uuid": "4d754a04e71d35966de08e6f3c41f9091004cdaa"}, "source": ["#Visitor each day\n", "f,ax = plt.subplots(1,1,figsize=(15,8))\n", "plt1 = train.groupby(['visit_date'], as_index=False).agg({'visitors': np.sum})\n", "plt2 = train.groupby(['visit_date'], as_index=False).agg({'reserve_visitors_ar': np.sum})\n", "plt3 = train.groupby(['visit_date'], as_index=False).agg({'reserve_visitors_hr': np.sum})\n", "plt1=plt1.set_index('visit_date')\n", "plt2=plt2.set_index('visit_date')\n", "plt3=plt3.set_index('visit_date')\n", "plt1.plot(color='salmon', kind='area', ax=ax)\n", "plt2.plot(color='cornflowerblue', kind='line', ax=ax)\n", "plt3.plot(color='y', kind='line', ax=ax)\n", "plt.ylabel(\"Sum of Visitors\")\n", "plt.title(\"Visitor and Reservations\")"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "89af1437-2023-4d95-8d01-72db34a3164d", "_uuid": "2725ba000a01971d801fbb3526d5ca05745d8052"}, "source": ["Number of air_store_id  increased by 150% in mid 2016"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "18e2bdfd-d4d8-48d6-ad45-cb102a2a3a49", "_uuid": "f0bcd7575a430cef7b7608fd2143e578fb2149fd"}, "source": ["f,ax = plt.subplots(1,1, figsize=(15,5))\n", "genre= train.groupby(['visit_date'])['air_store_id'].size()\n", "genre.plot(kind='area',  color= 'chocolate', grid=True, ax=ax, legend=True)\n", "plt.ylabel(\"Number Stores\")\n", "plt.title(\"Number Unique Store ID\")"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2a5b3c8d-8069-4ce2-bf89-89585ee3fbe8", "_uuid": "97271bef641d4497c1bfcba9196f280aa0a5dd68"}, "source": ["**3. Visitors by genre**"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "afd1027c-a656-460d-8337-083c89299b8e", "_uuid": "b010b459f8f95f8c5232738920184f5a13f30978"}, "source": ["Total visitor by air_genre_name. Izakaya & Cafe/Sweets are the two  most populr genres"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "3a0ff2f3-c502-4989-945e-946208348285", "_uuid": "35b84a8632aade488aa164f37e68d1009760804f"}, "source": ["f,ax=plt.subplots(1,1, figsize=(10,8))\n", "genre=train.groupby(['air_genre_name'],as_index=False)['visitors'].sum()\n", "genre.sort_values(by='visitors', ascending=True, inplace=True)\n", "genre['air_genre'] =[i for i,x in enumerate(genre['air_genre_name'])] \n", "genre = genre.sort_values(by='visitors', ascending=False)#.reset_index()\n", "my_range = genre['air_genre']\n", "plt.hlines(y=my_range, xmin=0, xmax=genre['visitors'], color='goldenrod',alpha=0.8) #[\u2018solid\u2019 | \u2018dashed\u2019 | \u2018dashdot\u2019 | \u2018dotted\u2019]\n", "plt.plot(genre['visitors'], my_range, \"o\",markersize=25,label='visitors',color='orangered')\n", "\n", "# Add titles and axis names\n", "plt.yticks(my_range, genre['air_genre_name'],fontsize=15)\n", "plt.title(\"Total visitors by air_genre_name\", loc='center')\n", "plt.xlabel('Score')\n", "plt.ylabel('Features')\n", "#plt.legend()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "26febeac-7ca5-44ef-a2c8-6473e7bfa693", "_uuid": "05ca2eeb2168b1a65eeb47a7c141228c9b3385cf"}, "source": ["\n", "- some of genres are new addition like - international cuisine, karaoke/party\n", "- Yakiniku/korean genre is showing increasing demand\n", "- Numbers of visitors for karaoke/party frequently surge in numbers on weekends"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "12e3e572-eb99-41a8-abfb-ead32cdfdddb", "_uuid": "54e81e390f44f47353a019f09ab6f98672aee2eb"}, "source": ["ax = sns.FacetGrid(train, col=\"air_genre_name\", col_wrap=4, size=3, hue='air_genre_name',margin_titles=True,\n", "                  aspect=1.5, palette='husl', ylim=(0,150))\n", "ax = ax.map(plt.plot, \"visit_date\", \"visitors\",  marker=\".\", linewidth = 0.5)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "637a1152-1bda-4f16-8f3c-b38f1f07dab6", "_uuid": "bab980e09478dc8d803c0c102a78b50956af748a"}, "source": ["**4. Visitors by weekdays trend and their group size**"]}, {"cell_type": "markdown", "metadata": {"_kg_hide-input": true, "_cell_guid": "b3c233bf-6b87-47fb-8e53-cb18e934a044", "_uuid": "632d0d2df2369b3b244ee7eb7b19dc94dcabeb39"}, "source": ["Friday, Saturday and Sunday are the busiest days of the week"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "b1fe1814-d360-4597-9af5-a8e1a40dcdc1", "_uuid": "b8c84c81cb799eb05f68ad3a3652f03c3e7f5011"}, "source": ["pvt=pd.pivot_table(train, index=['year','week'], columns='dow',values='visitors',aggfunc=[np.mean],fill_value=0)\n", "pvt=pd.DataFrame(pvt.to_records())\n", "pvt.columns=[pvt.replace(\"('mean', \", \"\").replace(\")\", \"\") for pvt in pvt.columns]\n", "pvt['year_week']=pvt['year'].astype(str) +'-'+ pvt['week'].astype(str)\n", "pvt=pvt.set_index('year_week')\n", "pvt.drop(['year','week'], axis=1,inplace=True)\n", "f, ax=plt.subplots(1,1, figsize=(15,8))\n", "pvt.plot(kind='line', ax=ax,cmap='inferno')\n", "plt.ylabel(\"Sum of Visitors\")\n", "plt.xlabel(\"Week\")\n", "plt.title(\"Visitors by Day of the Week \")\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "c9c61af4-2664-4ff4-aa18-e6c10a1b4cb2", "_uuid": "39aec8a483ea0100871437bcbc894079cb2d2997"}, "source": ["print('Number of total visitors- ', train['visitors'].sum())\n", "print('Number of stores- ', )\n", "print('Number of average daily visitors per air_store_id-', round(train['visitors'].mean(),2))"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "61f19b8c-7e94-4f79-b1ac-0c4a1d5b0dac", "_uuid": "fa023e6a672128118df9e014ef9347cd50f9e88f"}, "source": ["Visitors, group size and daily trend:\n", "Generally, highest number of visitors is on Friday, Saturday and Sunday. The peak day of the week is Saturday, while if it is holiday the peak day will be Thursday and Friday. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "6b398e68-8b33-4875-ad11-82917c50bb9a", "_uuid": "55195c1526f6dae7105821ede23d2c94efa4506f"}, "source": ["max_date=max(train['visit_date'])\n", "one_year = datetime.timedelta(days=364)\n", "cmap='inferno'\n", "year_ago= max_date - one_year\n", "train2=train#[train['visit_date']>year_ago]\n", "pvt=train2.groupby(['dow','dow_name'])['visitors'].mean().reset_index()\n", "\n", "train2=train.loc[(train['day']<8)&(train['holiday_flg']==1)]\n", "pvt2=train2.groupby(['dow','dow_name'])['visitors'].mean().reset_index()\n", "\n", "train3=train.loc[train['holiday_flg']==1]\n", "pvt3=train3.groupby(['dow','dow_name'])['visitors'].mean().reset_index()\n", "train4=train.loc[(train['long_wknd']==1)]\n", "pvt4=train4.groupby(['dow','dow_name'])['visitors'].mean().reset_index()\n", "\n", "pvt5=pd.pivot_table(train, index=['dow'], columns='month',values='visitors',aggfunc=[np.mean],fill_value=0)#.reset_index()\n", "pvt5=pd.DataFrame(pvt5.to_records())\n", "pvt5.columns=[pvt5.replace(\"('mean', \", \"\").replace(\")\", \"\") for pvt5 in pvt5.columns]\n", "pvt5=pvt5.set_index('dow')\n", "\n", "f, ax=plt.subplots(2,2, figsize=(15,10), sharey=False)\n", "ax[0,0].bar(pvt['dow'] ,pvt['visitors'],color='darkturquoise')\n", "ax[0,1].bar(pvt2['dow'] ,pvt2['visitors'],color='slategrey')\n", "ax[1,0].bar(pvt3['dow'] ,pvt3['visitors'],color='thistle')\n", "sns.heatmap(pvt5, ax=ax[1,1],cmap=cmap)\n", "ax[0,0].set_title('Mean Daily Visitors')\n", "ax[0,1].set_title('Mean Daily Visitors on first 7 days of the Month')\n", "ax[1,0].set_title('Mean Daily Visitors on holiday')\n", "ax[1,1].set_title('DOW vs Month mean visitors')\n", "\n", "ax[0,0].set_ylim(0,30)\n", "ax[0,1].set_ylim(0,30)\n", "ax[1,0].set_ylim(0,30)\n", "#ax[1,1].set_xlim(0,100)\n", "#plt.xlabel(\"Month\")"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "1b7b3b3e-7640-4079-8718-868b2a3b3ce8", "_uuid": "75fc032cb78a204b9942cefaed685b3628d4449b"}, "source": ["Larger mean visitors on holiday except day 5 - Saturday."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "9c008202-73be-4701-93af-52b1ebfd6746", "_uuid": "a2cba6bc6c09a0ee73e7312979783e5d8fe216d8"}, "source": ["plt1=train['visitors'].value_counts().reset_index().sort_index()\n", "fig, ax = plt.subplots(figsize=(15, 6), nrows=1, ncols=2, sharex=False, sharey=False)\n", "ax[0].bar(plt1['index'] ,plt1['visitors'],color='limegreen')\n", "ax[1]= sns.boxplot(y='visitors',x='dow', data=train,hue='holiday_flg',palette=\"Set3\")\n", "ax[1].set_title('Number of daily visitors by day of the week')\n", "ax[0].bar(plt1['index'] ,plt1['visitors'],color='limegreen')\n", "ax[0].set_title('Frequency')\n", "ax[0].set_xlim(0,100)\n", "ax[1].set_ylim(0,100)\n", "ax[1].legend(loc=1)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "54ea5665-c835-4685-98f8-027c583b5672", "_uuid": "0be13704db0fcf94f90b23e386d592493b1e8e57"}, "source": ["**5. Reservations trends**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "f94500ca-71ab-4160-9fbf-e2b684e7b3c3", "_uuid": "2a2fdda5d984b0af2a2f07775c1525dcf2c94dd9"}, "source": ["print('Total air reserve visitors - ',data['ar_hour']['reserve_visitors'].sum())\n", "print('Total hpg reserve visitors - ',data['hr_hour']['reserve_visitors'].sum())"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "b8ddc47f-e34d-453b-a281-bd5ee1c4f861", "_uuid": "af8d38a8170990139c81f52ab918f6e2b6ca6531"}, "source": ["Most of the customers are making reservation for the period of one week or visited restaurant on day 4 (Friday) & day 5 (Saturday) the most. There is noticably different reservation behaviour between air and hpg customers, where hpg visitors tend to book reservation throughout the day but air visitors doing it at later part of the day"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "3d701f45-9d78-4888-897b-fa741660e31a", "_uuid": "e300d91fd1e5e46e207e5545798748c16a481ecd"}, "source": ["data['ar_hour']['dow_reserve'] = data['ar_hour']['reserve_datetime'].dt.weekday\n", "data['ar_hour']['dow_visit'] = data['ar_hour']['visit_datetime'].dt.weekday\n", "data['hr_hour']['dow_reserve'] = data['hr_hour']['reserve_datetime'].dt.weekday\n", "data['hr_hour']['dow_visit'] = data['hr_hour']['visit_datetime'].dt.weekday\n", "air_res= data['ar_hour'].groupby(['reserve_day_ar'],as_index=False)['reserve_visitors'].sum()[:40]\n", "hpg_res= data['hr_hour'].groupby(['reserve_day_hr'],as_index=False)['reserve_visitors'].sum()[:40]\n", "air_res2=data['ar_hour'].groupby(['dow_visit',],as_index=False)['reserve_visitors'].sum()\n", "hpg_res2=data['hr_hour'].groupby(['dow_visit',],as_index=False)['reserve_visitors'].sum()\n", "air_res3=data['ar_hour'].groupby(['reserve_hour','visit_hour'])['reserve_visitors'].sum().unstack()\n", "hpg_res3=data['hr_hour'].groupby(['reserve_hour','visit_hour'])['reserve_visitors'].sum().unstack()\n", "\n", "f, ax=plt.subplots(3,2, figsize=(15,12),sharey=False)\n", "ax[0,0].bar(air_res['reserve_day_ar'] ,air_res['reserve_visitors'],color='royalblue')\n", "ax[0,1].bar(hpg_res['reserve_day_hr'] ,hpg_res['reserve_visitors'],color='tomato')\n", "ax[1,0].bar(air_res2['dow_visit'] ,air_res2['reserve_visitors'],color='royalblue')\n", "ax[1,1].bar(hpg_res2['dow_visit'] ,hpg_res2['reserve_visitors'],color='tomato')\n", "sns.heatmap(air_res3, ax=ax[2,0],cmap='inferno')\n", "sns.heatmap(hpg_res3, ax=ax[2,1],cmap='inferno')\n", "ax[0,0].set_title('Air Reservation in Number of Days')\n", "ax[0,1].set_title('Hpg Reservation in Number of Days')\n", "ax[1,0].set_title('Air reserve visitors by dow')\n", "ax[1,1].set_title('Hpg reserve visitors by dow')\n", "ax[2,0].set_title('Air Reserve Hour vs Visit hour')\n", "ax[2,1].set_title('Hpg Reserve Hour vs Visit hour')"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "6281973a-d350-4c06-8d76-e6d80f47d0b7", "_uuid": "40c4221251203f8286154d31fa477e53b6f0d064"}, "source": ["**6. Productivity by air_store_id**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "95951d4a-ce17-44cd-82ee-1b0c29301edc", "_uuid": "08d387161daca5d658c18c394c5f837bc5ec44ac"}, "source": ["store_mean= train.groupby(['air_store_id'], as_index=False)['visitors'].mean().rename(columns={'visitors':'overall_mean'})\n", "train=pd.merge(train, store_mean, how = 'left',on='air_store_id')\n", "\n", "train['vis_qtl']=pd.qcut(train['overall_mean'], 4, labels=['Quartile 4','Quartile 3','Quartile 2','Quartile 1'])\n", "quartile=train.groupby(['vis_qtl'],as_index=False).agg({'air_store_id':lambda x: len(x.unique()),\n", "                                               'mean_visitors':lambda x: x.mean(),\n", "                                               'visitors':lambda x: x.sum()})\n", "quartile.rename(columns={'air_store_id':'stores', 'visitors':'total_visitors'},inplace=True)\n", "quartile.sort_values(by='total_visitors', ascending=False,inplace=True)\n", "quartile['cumulative_visitors'] = quartile['total_visitors'].cumsum()/quartile['total_visitors'].sum()\n", "quartile"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "38fdc3d3-59c8-42ae-8029-826ef9953a97", "_uuid": "11cfc4a73d9acfaedfee3a9430300d3c5597d363"}, "source": ["We stacked and ordered the store according to average productiviy per day and arrange it form best to the lowest and cut the number of air_store_id into 4. \"air_store_id\" in Quartile 1 and Quartile 2 (412 which 50% of the total) contribute to 70% of the total visitors."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "b813e845-578f-47c5-aa11-c03bd35ec472", "_uuid": "478e8412cce0c4ddf25a8f3dc643522735b6be1c"}, "source": ["tot_visitors = quartile[['vis_qtl','total_visitors']]\n", "tot_visitors2 = quartile[['vis_qtl','cumulative_visitors']]\n", "tot_visitors.set_index('vis_qtl',inplace=True)\n", "tot_visitors2.set_index('vis_qtl',inplace=True)\n", "quartile.sort_values(by='total_visitors', ascending=False,inplace=True)\n", "f, ax=plt.subplots(1,2, figsize=(12,4))\n", "tot_visitors.plot(kind='bar',  ax=ax[0],color='y',width=0.8)\n", "tot_visitors2.plot(kind='bar',  ax=ax[1],color='darkseagreen',width=0.8)\n", "ax[0].set_title('Total visitors by Store Productivity Quartile')\n", "ax[1].set_title('%Cumulative visitors  by Store Productivity Quartile')\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "6a628a47-4ff9-4c1d-9b8d-a53fd21c6d90", "_uuid": "cae95dd079bc682d7476c92393cdac6bc3428ea7"}, "source": ["**Feature Engineering**\n", "\n", "Visualising feature engineering. We are exploring options and will test all of them in our model. "]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "64b625dc-73b2-4280-9ca4-98c378588039", "_uuid": "30dc1fcb78dc7331a6fbe06397126194313699f9"}, "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "Outliers\n", "Identifying outliers and treating them accordingly in our model building. Intuitively, area and dow are probably a good grouping to programatically find outliers. I believe that area and dow are among two most important factors that determines business traffic as it has similar holiday, celebration, culture and daily traffic.\n", "note: ol_1 shows number of observations that have number visitors 1 standard deviation above the mean for air_are_name and dow grouping."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_cell_guid": "e29c6b64-288d-4eb2-aedd-326c4af384ad", "_uuid": "4a3f5971bf0b6e2e702a3f8e9925241296beebc7"}, "source": ["# outliers based on air_area_name & dow grouping\n", "area_dow_std_df=train.groupby(['air_area_name','dow'])['visitors'].std().reset_index().rename(columns={'visitors':'std_area_dow'})\n", "area_dow_mean_df=train.groupby(['air_area_name','dow'])['visitors'].mean().reset_index().rename(columns={'visitors':'mean_area_dow'})\n", "train2=pd.merge(train, area_dow_std_df, how=\"left\", on=['air_area_name','dow'])\n", "train2=pd.merge(train2, area_dow_mean_df, how=\"left\", on=['air_area_name','dow'])\n", "\n", "x=train2['visitors']\n", "y=train2['mean_area_dow']\n", "z=train2['std_area_dow']\n", "ol_df=[]\n", "for n in range(10):\n", "    train2['ol_{}'.format(n)]= [1 if (x>y+z*n) else 0 for x, y, z in zip(x,y,z)]\n", "    ol_dfs=train2['ol_{}'.format(n)].value_counts()\n", "    ol_df.append(ol_dfs)\n", "    \n", "ol_df=pd.DataFrame(ol_df)   \n", "ol_df.index.name='outliers'\n", "\n", "f, ax=plt.subplots(1,1, figsize=(8,5))\n", "ol_df.plot(kind='barh',width=1,ax=ax, color=['dodgerblue','violet'])\n", "ax.set_title('Count of Outliers Base on multiple std from mean - grouped by air_area_name & dow')\n", "ax.set_ylabel('X* Standard Deviation From Mean')\n", "# Adding a title and a subtitle\n", "plt.text(x = 100000, y = 11, s = \"Outliers\",fontsize = 25, weight = 'bold', alpha = .75)\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"collapsed": true, "_cell_guid": "037dcc9b-a772-422b-ae08-1b692a434d2c", "_uuid": "208c003dcbe3587673ed777de9a06084c095ef45"}, "source": ["**Please Upvote if you find it useful**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "efd8a2dd-7c15-470d-bad4-dbf8e7a9b719", "_uuid": "dae439b802c6cad5ed7193d534bc8a1d3687ae86"}, "source": [], "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python"}}, "nbformat_minor": 1, "nbformat": 4}