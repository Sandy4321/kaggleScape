{"nbformat_minor": 0, "cells": [{"outputs": [], "metadata": {"_cell_guid": "558c6543-7398-38be-cb27-f039ea547cbb", "_uuid": "8b400a0d10f7a212ba8a62955c2a2cf40e6e082b"}, "execution_count": null, "source": "Image Features\n==============", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "c571eb29-4e46-e89b-0057-d1d529f2df21", "_uuid": "87315e1b57f4cbe5ab633e14ae4b0ce09440b026"}, "execution_count": null, "source": "from multiprocessing import Pool, cpu_count\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import fbeta_score\nfrom PIL import Image, ImageStat\nfrom skimage import io\nimport xgboost as xgb\nimport pandas as pd\nimport numpy as np\nimport glob, cv2\nimport random\nimport scipy\n\nrandom.seed(1)\nnp.random.seed(1)\nnp.seterr(divide='ignore', invalid='ignore')\n\ndef get_features(path):\n    try:\n        st = []\n        #pillow jpg\n        img = Image.open(path)\n        im_stats_ = ImageStat.Stat(img)\n        st += im_stats_.sum\n        st += im_stats_.mean\n        st += im_stats_.rms\n        st += im_stats_.var\n        st += im_stats_.stddev\n        img = np.array(img)[:,:,:3]\n        st += [scipy.stats.kurtosis(img[:,:,0].ravel())]\n        st += [scipy.stats.kurtosis(img[:,:,1].ravel())]\n        st += [scipy.stats.kurtosis(img[:,:,2].ravel())]\n        st += [scipy.stats.skew(img[:,:,0].ravel())]\n        st += [scipy.stats.skew(img[:,:,1].ravel())]\n        st += [scipy.stats.skew(img[:,:,2].ravel())]\n        #cv2 jpg\n        img = cv2.imread(path)\n        bw = cv2.imread(path,0)\n        st += list(cv2.calcHist([bw],[0],None,[256],[0,256]).flatten()) #bw \n        st += list(cv2.calcHist([img],[0],None,[256],[0,256]).flatten()) #r\n        st += list(cv2.calcHist([img],[1],None,[256],[0,256]).flatten()) #g\n        st += list(cv2.calcHist([img],[2],None,[256],[0,256]).flatten()) #b\n        try:\n            #skimage tif\n            p1 = path.replace('jpg','tif')\n            p1 = p1.replace('train-tif','train-tif-v2') #Why make path changes so complex that they nullify old scripts\n            p1 = p1.replace('test-tif-v2','test-tif-v3') #Why make path changes so complex that they nullify old scripts\n            imgr = io.imread(p1)\n            tf = imgr[:, :, 3]\n            st += list(cv2.calcHist([tf],[0],None,[256],[0,65536]).flatten()) #near ifrared\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 0]) / (imgr[:, :, 3] + imgr[:, :, 0])) #water ~ -1.0, barren area ~ 0.0, shrub/grass ~ 0.2-0.4, forest ~ 1.0\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 1]) / (imgr[:, :, 3] + imgr[:, :, 1]))\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n            ndvi = ((imgr[:, :, 3] - imgr[:, :, 2]) / (imgr[:, :, 3] + imgr[:, :, 2]))\n            st += list(np.histogram(ndvi,bins=20, range=(-1,1))[0])\n        except:\n            st += [-1 for i in range(256)]\n            st += [-2 for i in range(60)]\n            p1 = path.replace('jpg','tif')\n            p1 = p1.replace('train-tif','train-tif-v2') #Why make path changes so complex that they nullify old scripts\n            p1 = p1.replace('test-tif-v2','test-tif-v3') #Why make path changes so complex that they nullify old scripts\n            print('err', p1)\n        m, s = cv2.meanStdDev(img) #mean and standard deviation\n        st += list(m)\n        st += list(s)\n        st += [cv2.Laplacian(bw, cv2.CV_64F).var()] \n        st += [cv2.Laplacian(img, cv2.CV_64F).var()]\n        st += [cv2.Sobel(bw,cv2.CV_64F,1,0,ksize=5).var()]\n        st += [cv2.Sobel(bw,cv2.CV_64F,0,1,ksize=5).var()]\n        st += [cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5).var()]\n        st += [cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5).var()]\n        st += [(bw<30).sum()]\n        st += [(bw>225).sum()]\n    except:\n        print(path)\n    return [path, st]\n\ndef normalize_img(paths):\n    imf_d = {}\n    p = Pool(cpu_count())\n    ret = p.map(get_features, paths)\n    for i in range(len(ret)):\n        imf_d[ret[i][0]] = ret[i][1]\n    ret = []\n    fdata = [imf_d[f] for f in paths]\n    return fdata\n\nin_path = '../input/'\ntrain = pd.read_csv(in_path + 'train_v2.csv')[:1000]\ntrain['path'] = train['image_name'].map(lambda x: in_path + 'train-jpg/' + x + '.jpg')\ny = train['tags'].str.get_dummies(sep=' ')\nxtrain = normalize_img(train['path']); print('train...')\n\ntest_jpg = glob.glob(in_path + 'test-jpg-v2/*')[:1000]\ntest = pd.DataFrame([[p.split('/')[3].replace('.jpg',''),p] for p in test_jpg])\ntest.columns = ['image_name','path']\nxtest = normalize_img(test['path']); print('test...')", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "1b375771-34eb-9cfc-0c19-2471c780bfa3", "_uuid": "2e2b250f1ca14b89c3e90019453a71f1b71a1677"}, "execution_count": null, "source": "Model 1\n=======", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "1cf42207-a2d3-6eff-324a-af4134836b88", "_uuid": "47b49e1af0100b472a7c15644f5308fd52194455"}, "execution_count": null, "source": "etr = ExtraTreesRegressor(n_estimators=200, max_depth=30, n_jobs=-1, random_state=1)\netr.fit(xtrain, y); print('etr fit...')\n\ntrain_pred = etr.predict(xtrain)\ntrain_pred[train_pred > 0.20] = 1\ntrain_pred[train_pred < 1] = 0\nprint(fbeta_score(y,train_pred,beta=2, average='samples'))\n\npred1 = etr.predict(xtest); print('etr predict...')\netr_test = pd.DataFrame(pred1, columns=y.columns)\netr_test['image_name'] =  test[['image_name']]\n\ntags = []\nfor r in etr_test[y.columns].values:\n    r = list(r)\n    tags.append(' '.join([j[1] for j in sorted([[r[i],y.columns[i]] for i in range(len(y.columns)) if r[i]>.23], reverse=True)]))\n\ntest['tags'] = tags\ntest[['image_name','tags']].to_csv('submission_blend.csv', index=False)\ntest.head()", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "584ecb7e-d4fb-e8e4-0707-a1abef34e0f8", "_uuid": "36acc10de290612dd42e8c1d7c272b55ef77942e"}, "execution_count": null, "source": "Model 2\n=======", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "dea02b47-2b9f-7004-6dd4-63349d24f246", "_uuid": "d439467c8cbb7b10f150922a1cd6e21d78d34d34"}, "execution_count": null, "source": "xgb_train = pd.DataFrame(train[['path']], columns=['path'])\nxgb_test = pd.DataFrame(test[['image_name']], columns=['image_name'])\nprint('xgb fit...')\nfor c in y.columns:\n    model = xgb.XGBClassifier(n_estimators=200, learning_rate=0.3, max_depth=4, seed=1, base_score=0.5)\n    model.fit(np.array(xtrain), y[c])\n    xgb_train[c] = model.predict_proba(np.array(xtrain))[:, 1]\n    xgb_test[c] = model.predict_proba(np.array(xtest))[:, 1]\n    print(c)\n\ntrain_pred = xgb_train[y.columns].values\ntrain_pred[train_pred >0.20] = 1\ntrain_pred[train_pred < 1] = 0\nprint(fbeta_score(y,train_pred,beta=2, average='samples')) \nprint('xgb predict...')", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "2361e62d-85f1-d041-e3aa-b988f69075ac", "_uuid": "83fc5e713afb50ad8381869ae32049bf0eb4fd64"}, "execution_count": null, "source": "import matplotlib.pyplot as plt\n%matplotlib inline\n\nth = []\ntrain_predx = xgb_train[y.columns].values\nfor i in np.arange(0.0, 0.9, 0.01):\n    train_pred = train_predx.copy()\n    train_pred[train_pred >i] = 1\n    train_pred[train_pred < 1] = 0\n    th.append([i, fbeta_score(y,train_pred,beta=2, average='samples')])\n_ = pd.DataFrame(th, columns=['th','f2_score']).plot(kind='line', x='th', y='f2_score')", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "479d9f76-56d2-2999-e0d8-ed781c9fb9af", "_uuid": "e1a7e33e687070010e4811663a088357d1e16f34"}, "execution_count": null, "source": "Blend\n=====", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "c0505c24-f558-62f4-37fe-31e02154877d", "_uuid": "ab5e18d35930c8a9f50ae48b0761a9f333ec50e1"}, "execution_count": null, "source": "xgb_test.columns = [x+'_' if x not in ['image_name'] else x for x in xgb_test.columns]\nblend = pd.merge(etr_test, xgb_test, how='left', on='image_name')\n\nfor c in y.columns:\n    blend[c] = (blend[c] * 0.60)  + (blend[c+'_'] * 0.40)\n\nblend = blend[etr_test.columns]", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "c48167f2-ae05-dfcb-3b9b-95927dc4121c", "_uuid": "f7f5cabe7a185e917ad8e63d78f6994bc78148d5"}, "execution_count": null, "source": "Prepare Submission\n==================", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "b965d747-ed78-0741-f899-c5b875b7d3e5", "_uuid": "eb8adef9bd8cac09939ccdf0e35afd720e2f1491"}, "execution_count": null, "source": "tags = []\nfor r in blend[y.columns].values:\n    r = list(r)\n    tags.append(' '.join([j[1] for j in sorted([[r[i],y.columns[i]] for i in range(len(y.columns)) if r[i]>.20], reverse=True)]))\n\ntest['tags'] = tags\ntest[['image_name','tags']].to_csv('submission_blend.csv', index=False)\ntest.head()", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "a57263d0-0734-cbc6-ddac-cbe224e5e859", "_uuid": "e3922d79de424ec5a6c60d1c7a6439e6e22a9f64"}, "execution_count": null, "source": "Visualize Results\n=================", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "b5012d37-5260-8d83-ef71-0fe916c9953e", "_uuid": "307d6a6485677f190e601d520af575233821f8aa"}, "execution_count": null, "source": "for l in y.columns:\n    try:\n        pathsx = test[test['tags'].str.contains(str(l))==True].path.tolist()[:9]\n        plt.rcParams['figure.figsize'] = (10.0, 10.0)\n        plt.subplots_adjust(wspace=0, hspace=0)\n        fig = plt.figure()\n        fig.suptitle(l)\n        for x in range(9):\n                plt.subplot(3, 3, x+1)\n                im = Image.open(pathsx[x])\n                #im = im.resize((100, 100), Image.ANTIALIAS)\n                plt.imshow(im)\n                plt.axis('off')\n    except:\n        print(l)", "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "28d87f52-af77-13bc-8886-7814b0f0ed0a", "_uuid": "f679e5824b533b12ed506c0aa60873dee45545a1"}, "execution_count": null, "source": "Visualize Feature Importance\n============================", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "380fd559-c85b-f961-97dd-c04e0b55d240", "_uuid": "eee2f6d513d5db736c4740bde2d45a5e0fde993a"}, "execution_count": null, "source": "col = ['sum1','sum2','sum3','sum4','mean1','mean2','mean3','mean4','rms1','rms2','rms3','rms4','var1','var2','var3','var4','stddev1','stddev2','stddev3','stddev4','kurtosis1','kurtosis2','kurtosis3','skew1','skew2','skew3']\ncol += ['bw'+str(i) for i in range(256)]\ncol += ['r'+str(i) for i in range(256)]\ncol += ['g'+str(i) for i in range(256)]\ncol += ['b'+str(i) for i in range(256)]\ncol += ['infrared'+str(i) for i in range(256)]\ncol += ['nvdi'+str(i) for i in range(60)]\ncol += ['cv2mean1','cv2mean2','cv2mean3','cv2stddev1','cv2stddev2','cv2stddev3','Laplacian_bw','Laplacian_img','Sobel1_bw','Sobel2_bw','Sobel1_img','Sobel2_img','black_bw','white_bw']\nimp = etr.feature_importances_\nfeat_imp = [[imp[i], col[i]] for i in range(len(imp))]\n_ = pd.DataFrame(feat_imp, columns=['importance','column']).sort_values(['importance','column'], ascending=[False, False])[:30].plot(kind='barh', x='column', y='importance')", "cell_type": "code"}], "metadata": {"language_info": {"name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "_is_fork": false, "_change_revision": 0}, "nbformat": 4}