{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "_is_fork": false, "language_info": {"pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.1", "nbconvert_exporter": "python", "mimetype": "text/x-python"}, "_change_revision": 0}, "cells": [{"metadata": {"_uuid": "ffd578ed880603d5d6aeba1acb7c2b1ee5db20fc", "_cell_guid": "4b563cd2-1a7b-ab65-4096-7087a046ed50"}, "cell_type": "markdown", "source": ["Work in progress:\n", "<br>-- add bf0 to data for all products NOT reordered to all orders after first ordered\n", "<br>--  add the exponential time weighting - for model memory loss\n", "<br>--  add new factors to model\n", "<br>--  try flat Prior where p(reorder) is same for all products\n", "\n", "This file uses p(reordered|product_id) derived from order_products__prior data as a **Prior**. This is to be used in Bayesian Updating of our Prior: our_products_prior['prob_reordered']. Can also use a flat Prior.\n", "\n", "The notion is that after calculating Bayes Factors for each test product purchase the final probability that a product will be reordered is the **Posterior** probability.  Beginning when a product is first purchased (say order k of n total orders) then the **Posterior = BFn x BFn-1 x ... x BFk x Prior**.\n", "\n", "Many others here have noticed the correlation between reordered and add_to_cart_order and aisle. I have added an engineered factor I call reorder_count (or count of reordered items in a cart). Using these three variables, I have derived a simple Augmented Naive Bayesian Network as a model to calculate the Bayes Factors for updating.\n", "\n", "![Bayesian Network model of reordered][1]\n", "\n", "Thanks to Kareem Eissa, Nick Sarris and Paul Nguyen for code and inspiration. Thank you smalllebowski and Sagar M for your corrections! You are very generous.\n", "\n", "\n", "\n", "  [1]: http://elmtreegarden.com/wp-content/uploads/2017/07/Augmented-Naive-Bayesian-Network.png"]}, {"metadata": {"_execution_state": "idle", "_uuid": "0bea51e9703c895a1192a078d749e6b4c828bfe2", "_cell_guid": "927116ef-f2f7-7c39-61cb-738950a5cd31"}, "execution_count": null, "cell_type": "code", "source": ["\n", "import pandas as pd\n", "import numpy as np\n", "import operator\n", "\n", "# special thanks to Nick Sarris who has written a similar notebook\n", "# reading data\n", "#mdf = 'c:/Users/John/Documents/Research/entropy/python/InstaCart/data/'\n", "mdf = '../input/'\n", "print('loading prior orders')\n", "prior_orders = pd.read_csv(mdf + 'order_products__prior.csv', dtype={\n", "        'order_id': np.int32,\n", "        'product_id': np.int32,\n", "        'add_to_cart_order': np.int16,\n", "        'reordered': np.int8})\n", "print('loading orders')\n", "orders = pd.read_csv(mdf + 'orders.csv', dtype={\n", "        'order_id': np.int32,\n", "        'user_id': np.int32,\n", "        'eval_set': 'category',\n", "        'order_number': np.int16,\n", "        'order_dow': np.int8,\n", "        'order_hour_of_day': np.int8,\n", "        'days_since_prior_order': np.float32})\n", "print('loading aisles info')\n", "aisles = pd.read_csv(mdf + 'products.csv', engine='c',\n", "                           usecols = ['product_id','aisle_id'],\n", "                       dtype={'product_id': np.int32, 'aisle_id': np.int32})\n", "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n", "\n", "prior_orders.shape\n", "orders.shape"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "812eda8704d6d53ae49d3619b90ed8333c56098b", "_cell_guid": "807b5b6e-480a-47c5-bd95-ecd4b8006e8b"}, "execution_count": null, "cell_type": "code", "source": ["# removing all user_ids not in the test set from both files to save memory\n", "# the test users present ample data to make models. (and saves space)\n", "test  = orders[orders['eval_set'] == 'test' ]\n", "user_ids = test['user_id'].values\n", "order_ids = test['order_id'].values\n", "orders = orders[orders['user_id'].isin(user_ids)]\n", "\n", "#del test\n", "test.shape"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "f5946442035a0c68a9164d376cb84ae42d5910fc", "_cell_guid": "1f3b3415-a367-4df7-84df-4e1e1e30bb8a"}, "execution_count": null, "cell_type": "code", "source": ["\n", "# Calculate the Prior : p(reordered|product_id)\n", "prior = pd.DataFrame(prior_orders.groupby('product_id')['reordered']\\\n", "                     .agg([('number_of_orders',len),('sum_of_reorders','sum')]))\n", "#prior['prior_p'] = (prior['sum_of_reorders']+1)/(prior['number_of_orders']+2) # Informed Prior\n", "prior['prior_p'] = 1/2  # Flat Prior\n", "prior.drop(['number_of_orders','sum_of_reorders'], axis=1, inplace=True)\n", "print('Here is The Prior: our first guess of how probable it is that a product be reordered once it has been ordered.')\n", "\n", "prior.head(3)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "d68a0fda41a737eeb5e32a9490feb485bade050b", "_cell_guid": "e47e54fb-0c07-4335-b815-a39c5d5ca842"}, "execution_count": null, "cell_type": "code", "source": ["# merge everything into one dataframe and save any memory space\n", "\n", "comb = pd.DataFrame()\n", "comb = pd.merge(prior_orders, orders, on='order_id', how='right')\n", "# slim down comb - \n", "comb.drop(['eval_set','order_dow','order_hour_of_day'], axis=1, inplace=True)\n", "del prior_orders\n", "del orders\n", "comb = pd.merge(comb, aisles, on ='product_id', how = 'left')\n", "del aisles\n", "prior.reset_index(inplace = True)\n", "comb = pd.merge(comb, prior, on ='product_id', how = 'left')\n", "del prior\n", "print('combined data in DataFrame comb')\n", "comb.head(3)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "40c4bba5ec2869cd23dda1915da9a6b6f3bddbe0", "_cell_guid": "d22f54fe-8571-4b5b-ae17-375f30bd7ec9"}, "execution_count": null, "cell_type": "code", "source": ["\n", "# Build the factors needed for a model of probability of reordered. This model forms our\n", "# hypothesis H and allows the calculation of each Bayes Factor: BF = p(e|H)/(1-p(e|H))\n", "# where e is the test user product buying history. See DAG of model above.\n", "# discretize reorder count into categories, 9 buckets, being sure to include 0 as bucket\n", "# These bins maximize mutual information with ['reordered']. Done outside python\n", "recount = pd.DataFrame()\n", "recount['reorder_c'] = comb.groupby(comb.order_id)['reordered'].sum().fillna(0)\n", "bins = [-0.1, 0, 2,4,6,8,11,14,19,71]\n", "cat =  ['None','<=2','<=4','<=6','<=8','<=11','<=14','<=19','>19']\n", "recount['reorder_b'] = pd.cut(recount['reorder_c'], bins, labels = cat)\n", "recount.reset_index(inplace = True)\n", "comb = pd.merge(comb, recount, how = 'left', on = 'order_id')\n", "del recount\n", "\n", "# discretize 'add_to_cart_order' (atco) into categories, 8 buckets\n", "# These bins maximize mutual information with ['recount']. Done outside python\n", "bins = [0,2,3,5,7,9,12,17,80]\n", "cat = ['<=2','<=3','<=5','<=7','<=9','<=12','<=17','>17']\n", "comb['atco1'] = pd.cut(comb['add_to_cart_order'], bins, labels = cat)\n", "del comb['add_to_cart_order']\n", "print('comb ')\n", "comb.head(2)\n"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "232ae69ebb731fe5b0eb7f873b352803d51cc7d2", "_cell_guid": "cf937d1f-b100-4832-bc84-5f06d6a4d973"}, "execution_count": null, "cell_type": "code", "source": ["# these are the children Nodes of reordered:atco, aisle, recount. Build occurrence tables\n", "# first, then calculate probabilities. Then merge to add atco into comb.\n", "# \n", "atco_fac = pd.DataFrame()\n", "atco_fac = comb.groupby(['reordered', 'atco1'])['atco1'].agg(np.count_nonzero).unstack('atco1')\n", "tot = pd.DataFrame()\n", "tot = np.sum(atco_fac,axis=1)\n", "atco_fac = atco_fac.iloc[:,:].div(tot, axis=0)\n", "atco_fac = atco_fac.stack('atco1')\n", "atco_fac = pd.DataFrame(atco_fac)\n", "atco_fac.reset_index(inplace = True)\n", "atco_fac.rename(columns = {0:'atco_fac_p'}, inplace = True)\n", "comb = pd.merge(comb, atco_fac, how='left', on=('reordered', 'atco1'))\n", "\n", "# calculate other two factors' probability tables, then probability\n", "# and merge into comb\n", "\n", "aisle_fac = pd.DataFrame()\n", "aisle_fac = comb.groupby(['reordered', 'atco1', 'aisle_id'])['aisle_id']\\\n", "                .agg(np.count_nonzero).unstack('aisle_id')\n", "tot = np.sum(aisle_fac,axis=1)\n", "aisle_fac = aisle_fac.iloc[:,:].div(tot, axis=0)\n", "aisle_fac = aisle_fac.stack('aisle_id')\n", "aisle_fac = pd.DataFrame(aisle_fac)\n", "aisle_fac.reset_index(inplace = True)\n", "aisle_fac.rename(columns = {0:'aisle_fac_p'}, inplace = True)\n", "comb = pd.merge(comb, aisle_fac, how = 'left', on = ('aisle_id','reordered','atco1'))\n", "# last factor is reorder_count_factor   \n", "    \n", "recount_fac = pd.DataFrame()\n", "recount_fac = comb.groupby(['reordered', 'atco1', 'reorder_b'])['reorder_b']\\\n", "                    .agg(np.count_nonzero).unstack('reorder_b')\n", "tot = pd.DataFrame()\n", "tot = np.sum(recount_fac,axis=1)\n", "recount_fac = recount_fac.iloc[:,:].div(tot, axis=0)\n", "recount_fac.stack('reorder_b')\n", "recount_fac = pd.DataFrame(recount_fac.unstack('reordered').unstack('atco1')).reset_index()\n", "recount_fac.rename(columns = {0:'recount_fac_p'}, inplace = True)\n", "comb = pd.merge(comb, recount_fac, how = 'left', on = ('reorder_b', 'reordered', 'atco1'))\n", "\n", "recount_fac.head(3)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "c030dd3195a0820a61149a7c609d91e1c70a63e2", "_cell_guid": "97dd8e8c-70fe-471e-b4ef-5b2cfec83226"}, "execution_count": null, "cell_type": "code", "source": ["\n", "# Use the factors in comb + the prior_p to update a posterior for each product purchased.\n", "p = pd.DataFrame()\n", "p = (comb.loc[:,'atco_fac_p'] * comb.loc[:,'aisle_fac_p'] * comb.loc[:,'recount_fac_p'])\n", "p.reset_index()\n", "comb['p'] = p\n", "\n", "comb.head(3)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "95583cca40bfbfce8b238affdef44b8b3c074c5d", "_cell_guid": "5cf13cc8-8613-48b8-98f7-d0df41e1a57c"}, "execution_count": null, "cell_type": "code", "source": [" \n", "# work in progress on beta\n", "# Use a test beta = 95% per month for memory retention function of users. Akin to Recency.\n", "\n", "\n", "#split into three dataframes. Two are reordered == 1 and == 0\n", "# add third group when order_number > first_order & reordered <> 1\n", "# the trird group is when ordered=0 but we don't have data for order=0,\n", "# so we make it.It must be appended to comb_last\n", "\n", "# Calculate bf0 for products when first purchased aka reordered=0\n", "comb0 = pd.DataFrame()\n", "comb0 = comb[comb['reordered']==0]\n", "comb0.loc[:,'first_order'] = comb0['order_number']\n", "# now every product that was ordered has a posterior in usr.\n", "comb0.loc[:,'beta'] = 1\n", "comb0.loc[:,'bf'] = (comb0.loc[:,'prior_p'] * comb0.loc[:,'p']/(1 - comb0.loc[:,'p'])) # bf1\n", "# Small 'slight of hand' here. comb0.bf is really the first posterior and second prior.\n", "\n", "# Calculate beta and BF1 for the reordered products\n", "comb1 = pd.DataFrame()\n", "comb1 = comb[comb['reordered']==1]\n", "\n", "comb1.loc[:,'beta'] = (1 - .05*comb1.loc[:,'days_since_prior_order']/30)\n", "comb1.loc[:,'bf'] = (1 - comb1.loc[:,'p'])/comb1.loc[:,'p'] # bf0\n", "\n", "\n", "comb_last = pd.DataFrame()\n", "comb_last = pd.concat([comb0, comb1], axis=0).reset_index(drop=True)\n", "comb_last = comb_last[['reordered','user_id','product_id','reorder_c','order_number',\n", "                       'bf','beta','atco_fac_p', 'aisle_fac_p', 'recount_fac_p']]\n", "comb_last = comb_last.sort_values((['user_id', 'order_number', 'bf']))\n", "\n", "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n", "comb_last.head(3)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "e901e67ad4ed2a74b91a59679475f9ad8a52e19e", "_cell_guid": "fca6455e-07ef-4b06-97d4-9a63e6af972b"}, "execution_count": null, "cell_type": "code", "source": ["first_order = pd.DataFrame()\n", "first_order = comb_last[comb_last.reordered == 0]\n", "first_order.rename(columns = {'order_number':'first_o'}, inplace = True)\n", "first_order.loc[:,'last_o'] = comb_last.groupby(['user_id'])['order_number'].transform(max)\n", "first_order = first_order[['user_id','product_id','first_o','last_o']]\n", "comb_last = pd.merge(comb_last, first_order, on = ('user_id', 'product_id'), how = 'left')\n", "\n", "#com = pd.DataFrame()\n", "#com = comb_last[(comb_last.user_id == 3) & (comb_last.first_o < comb_last.order_number)]\n", "#com.groupby([('order_id', 'product_id', 'order_number')])['bf'].agg(np.sum).head(50)\n"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "0bbb9d7f6fdae1b0fcfdb1d4a38cd118a17a1200", "_cell_guid": "76824c7c-e801-4c49-be25-798ab9cb5cb8"}, "execution_count": null, "cell_type": "code", "source": ["# Calculate beta and bf0 for products not reordered after first order for all orders.\n", "# must not occur until reordered==0 (aka: when first ordered)\n", "# they do not exist in the data. there is no record of NOT Ordered.\n", "# we must produce these records and calculate p, bf0 & beta for each\n", "com = pd.DataFrame\n", "\n", "# replace nan with bf0 if first_o < order_number (after product is first ordered)\n", "com = pd.pivot_table(comb_last[(comb_last.user_id == 3) & \\\n", "                               (comb_last.first_o < comb_last.order_number)],\n", "                     values = 'bf', index = ['user_id', 'product_id'],\n", "                     columns = 'order_number', dropna=False)\n", "temp = pd.DataFrame()\n", "temp = com[(com.bf == 'nan')]\n", "p = pd.DataFrame()\n", "p.loc[:,'p'] = (temp.loc[:,'atco_fac_p'] * temp.loc[:,'aisle_fac_p'] * temp.loc[:,'recount_fac_p'])\n", "p.reset_index()\n", "temp.loc[:,'bf'] = (1 - temp.loc[:,p])/temp.loc[:,p]\n", "comb_last = pd.merge(comb_last, temp, on =[('order_id', 'product_id',\n", "                                            'order_number')]).reset_index()\n", "temp = comb_last[comb_last.beta == 'nan']\n", "temp.loc[:,'beta'] = (1 - .05*comb1.loc[:,'days_since_prior_order']/30)\n", "comb_last = pd.merge(comb_last, temp, on = [('order_id', 'product_id',\n", "                                             'order_number')]).reset_index()\n", "\n", "# replace nan with 1 if first_o > order number (before product has been ordered)\n", "com = pd.pivot_table(comb_last[(comb_last.user_id ==3) & (com.first_o < com.order_number)],\n", "                     values = 'beta', index = ['user_id', 'product_id'], \n", "                     columns = 'order_number', dropna=False)\n", "# \n", "temp = com[com.bf == 'nan']\n", "temp.loc[:,'bf'] = 1\n", "comb_last = pd.merge(comb_last, temp, on =[('order_id', 'product_id',\n", "                                            'order_number')]).reset_index()\n", "temp = comb_last[comb_last.beta == 'nan']\n", "temp.loc[:,'beta'] = 1\n", "comb_last = pd.merge(comb_last, temp, on = [('order_id', 'product_id',\n", "                                             'order_number')]).reset_index()\n", "\n", "\n", "pd.pivot_table(comb_last[comb_last.user_id ==3], values = 'bf',\n", "               index = ['user_id', 'product_id'], columns = 'order_number', dropna=False).head(15)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "7f763d66c95af14dbda83a19882812de7672498b", "collapsed": true, "_cell_guid": "f4a5593d-e095-4db3-ba74-e8827f07dd50"}, "execution_count": null, "cell_type": "code", "source": ["# Find way to introduce beta to the update. ????\n", "##  update = lambda bf(n) ,bf(n-1), beta(n): bf(n) * bf(n-1)**beta(n);\n", "\n", "# finally, perform update of every product\n", "# Calculate the posterior for every product a user has purchased\n", "usr = pd.DataFrame()\n", "usr = comb_last[comb_last.order_number >= comb_last.first_o].groupby(['user_id',\n", "                                                                      'product_id'])['bf',\n", "                                                                                     'beta']\\\n", "    .agg({['bf', 'beta']: lambda x,y: x**y}).reset_index() \n", "\n", "# Calculate the average number of reordered products per cart for each user\n", "temp = pd.DataFrame()\n", "temp = comb_last[comb_last.order_number > 1].groupby(['user_id'])['reorder_c']\\\n", "    .agg(np.mean).reset_index()\n", "user = pd.merge(usr, temp, on = 'user_id', how = 'left')\n", "\n", "user.head(5)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "e55f50762819120a35462b12fd72b0a859ad9e59", "_cell_guid": "7a2f7244-94af-4f80-be89-dcc3975deeb5"}, "execution_count": null, "cell_type": "code", "source": ["def f1(x):\n", "    return ' '.join([str(int(a)) for a in x])\n", "def f2(x):\n", "    return 'None'\n", "\n", "u = user.reset_index().sort_values(((['user_id','bf'])), ascending=False)\n", "u['cumulative'] = u.groupby('user_id').cumcount()\n", "uu = u[(round(u.reorder_c) > u.cumulative)].groupby('user_id').agg({'product_id': f1})\n", "uu.reset_index(inplace=True)\n", "uuu = u[round(u.reorder_c) == 0].groupby('user_id').agg({'product_id': f2})\n", "uuu.reset_index(inplace=True)\n", "\n", "uuuu = pd.concat([uu, uuu], axis=0).reset_index()\n", "sub = pd.merge(uuuu, test, on='user_id', how ='left').sort_values('order_id')\n", "\n", "sub.sort_values('order_id')\n", "sub[['order_id', 'product_id']].to_csv('bayesian.csv', index=False)\n", "sub[['order_id', 'product_id']].head(10)"], "outputs": []}, {"metadata": {"_execution_state": "idle", "_uuid": "d76982e5ba2e66f0061fa7ef7c2df870cac9f596", "collapsed": true, "_cell_guid": "af215e15-0acf-4319-813c-001a64467665"}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}], "nbformat_minor": 1, "nbformat": 4}