{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm\n",
    "import os, re, time, random\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import inspect\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Pandas usage in Kaggle Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal was to try to construct a coverage metric for Pandas on Ray, in other words, how much of the actual use cases of Pandas do we provide support for. In order to this, we took the following approach\n",
    "\n",
    "1. Fetch the top 1800 Python kernels from Kaggle sorted by number of votes\n",
    "2. Convert notebooks to scripts so all kernels are in .py format\n",
    "3. Use basic regex matching against known Pandas (pd.\\*) and Dataframe (df.\\*) methods\n",
    "4. Aggregate counts for most used methods for the full sample space\n",
    "5. Calculate kernel-level coverage by checking which scripts have full method implementation in our library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get urls of top kernels by vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(os.getcwd() + '/dependencies/chromedriver')\n",
    "\n",
    "browser.get(\"https://www.kaggle.com/kernels?sortBy=votes&group=everyone&pageSize=20&language=Python\")\n",
    "time.sleep(1)\n",
    "\n",
    "elem = browser.find_element_by_tag_name(\"body\")\n",
    "\n",
    "no_of_pagedowns = 150\n",
    "\n",
    "while no_of_pagedowns:\n",
    "    elem.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    no_of_pagedowns-=1\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_links = ['https://www.kaggle.com' + a['href'] + '/code' for a in soup.find_all(\"a\", class_=\"block-link__anchor\") if ('teaching-notebook-for-total-imaging-newbies' not in a['href'] and 'mentions-of-kaggle-on-hacker-news' not in a['href'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kernel_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get url of code files from kernels page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('/Users/adithya/Documents/university/research/scrapingKaggle/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_from_kernel(kernel_link):\n",
    "    if ('stkbailey' in kernel_link or \n",
    "        'mentions-of-kaggle-on-hacker-news' in kernel_link or \n",
    "        'keras-rcnn-based-overview-wip' in kernel_link or \n",
    "        'why-employees-leave-and-how-to-predict-it' in kernel_link or \n",
    "        'boosting-stacking-and-bayes-searching' in kernel_link or\n",
    "        'resnet50-features-xgboost' in kernel_link or \n",
    "        'github-commit-messages' in kernel_link):\n",
    "        return None\n",
    "    try:\n",
    "        browser.get(kernel_link)\n",
    "        innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "        soup = BeautifulSoup(innerHTML, 'html.parser')\n",
    "\n",
    "        link = soup.find_all(\"a\", class_=\"script-code-pane__download\")[0]['href']\n",
    "\n",
    "        return link\n",
    "    except Exception as e:\n",
    "        print(\"E\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def pull_partition(start, end, partition):\n",
    "    code_links_write_part = []\n",
    "    for kl in tqdm(kernel_links[start:end]):\n",
    "        code_links_write_part.append(get_code_from_kernel(kl))\n",
    "        time.sleep(1)\n",
    "\n",
    "    code_file_write_part = open('links/code_links_part' + str(partition) + '.txt', 'w')\n",
    "    for code_link in code_links_write_part:\n",
    "        code_file_write_part.write(\"%s\\n\" % code_link)\n",
    "        \n",
    "    print(\"Finished partition %d\" % partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 100\n",
    "partitions = [(STEP*i, STEP*(i+1), i) for i in range(len(kernel_links)//STEP + 1)]\n",
    "for p in partitions[17:]:\n",
    "    pull_partition(p[0], p[1], p[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_links_read = []\n",
    "for i in range(19):\n",
    "    with open('links/code_links_part' + str(i) + '.txt', 'r') as code_file_read:\n",
    "        code_links_read += code_file_read.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.kaggle.com/kernels/scriptcontent/2205465/download',\n",
       " 'https://www.kaggle.com/kernels/scriptcontent/1723057/download',\n",
       " 'https://www.kaggle.com/kernels/scriptcontent/610626/download',\n",
       " 'https://www.kaggle.com/kernels/scriptcontent/2041567/download',\n",
       " 'https://www.kaggle.com/kernels/scriptcontent/1184830/download']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_links = list(set(['https://www.kaggle.com' + cl for cl in code_links_read]))\n",
    "code_links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pull raw code file to local dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for code_link in tqdm(code_links):\n",
    "    !wget --content-disposition $code_link -P data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean non-Python files from downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"data\"):\n",
    "    if filename == \".DS_Store\":\n",
    "        pass\n",
    "    \n",
    "    name_parts = filename.split(\".\")\n",
    "    if len(name_parts) == 2:\n",
    "        name_parts.append(\"0\")\n",
    "        \n",
    "    if name_parts[1] in ['ipynb', 'py']:\n",
    "        new_name = name_parts[0] + name_parts[2] + \".\" + name_parts[1]\n",
    "        new_name = 'r' + new_name if name_parts[1] == 'py' else new_name\n",
    "        os.rename('data/' + filename, 'data/' + new_name)\n",
    "\n",
    "    else:\n",
    "        os.remove('data/' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Notebooks and Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze python script\n",
    "pd_search_tokens = [\".\" + p[0] for p in inspect.getmembers(pd) if p[1].__class__.__name__ == 'function'] + ['.DataFrame']\n",
    "df_search_tokens = [\".\" + p[0] for p in inspect.getmembers(pd.DataFrame) if p[1].__class__.__name__ == 'function']\n",
    "search_tokens = pd_search_tokens + df_search_tokens\n",
    "\n",
    "def parse_script(script_name):\n",
    "    with open(script_name) as script_file:\n",
    "        code = script_file.read().splitlines()\n",
    "\n",
    "    ps = {}\n",
    "    for line in code:\n",
    "        for token in search_tokens:\n",
    "            for m in re.finditer(token, line):\n",
    "                found = line[m.start() - 2: m.end()]\n",
    "                if '.' in found and (found[:2] == 'pd' or found[:2] == 'df'):\n",
    "                    if not (len(line) > m.end() and (line[m.end()].isalnum() or line[m.end()] == '_')):\n",
    "                        if found not in ps:\n",
    "                            ps[found] = 0\n",
    "                        ps[found] += 1\n",
    "    \n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pd.read_csv': 3, 'pd.to_datetime': 2}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_script('data/script1092.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: data/.DS_Store: No such file or directory\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3028/3028 [06:59<00:00,  7.23it/s]\n"
     ]
    }
   ],
   "source": [
    "!rm data/.DS_Store\n",
    "\n",
    "all_methods = []\n",
    "for filename in tqdm(os.listdir(\"data\")):\n",
    "    if filename.split(\".\")[1] == 'py':\n",
    "        all_methods.append(parse_script('data/' + filename))\n",
    "    else:\n",
    "        pfilename = 'data/' + filename\n",
    "        cfilename = filename.split(\".\")[0] + '.py'\n",
    "        if cfilename not in os.listdir(\"data\"):\n",
    "            !jupyter nbconvert --to=python $pfilename\n",
    "            time.sleep(1)\n",
    "        try:\n",
    "            all_methods.append(parse_script('data/' + cfilename))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1562"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_methods = [a for a in all_methods if a]\n",
    "len(all_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94020"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "methods_write = open('results/methods.txt', 'w')\n",
    "methods_write.write(json.dumps(all_methods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate total method usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'df.fillna': 1, 'pd.merge': 20, 'pd.read_csv': 7, 'pd.to_datetime': 1},\n",
       " {'pd.DataFrame': 2, 'pd.concat': 1, 'pd.get_dummies': 1, 'pd.read_table': 2},\n",
       " {'pd.read_csv': 1},\n",
       " {'pd.DataFrame': 2,\n",
       "  'pd.concat': 1,\n",
       "  'pd.get_dummies': 1,\n",
       "  'pd.read_pickle': 1,\n",
       "  'pd.read_table': 4,\n",
       "  'pd.to_pickle': 2},\n",
       " {'pd.DataFrame': 1, 'pd.read_csv': 5}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods_read = []\n",
    "with open('results/methods.txt', 'r') as method_file_read:\n",
    "    methods_read = json.loads(method_file_read.read())\n",
    "\n",
    "methods_read[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = {}\n",
    "for dict_method in all_methods:\n",
    "    for k in dict_method:\n",
    "        if k not in base:\n",
    "            base[k] = 0 \n",
    "        base[k] += dict_method[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pd.read_csv</th>\n",
       "      <td>3887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.DataFrame</th>\n",
       "      <td>2491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.merge</th>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.concat</th>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df.groupby</th>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.to_datetime</th>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df.head</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df.drop</th>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.get_dummies</th>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df.merge</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Count\n",
       "Method               \n",
       "pd.read_csv      3887\n",
       "pd.DataFrame     2491\n",
       "pd.merge         1672\n",
       "pd.concat        1061\n",
       "df.groupby        870\n",
       "pd.to_datetime    522\n",
       "df.head           431\n",
       "df.drop           427\n",
       "pd.get_dummies    425\n",
       "df.merge          248"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, c = [], []\n",
    "for method, count in base.items():\n",
    "    m.append(method)\n",
    "    c.append(count)\n",
    "    \n",
    "mFreq = pd.DataFrame(data = {'Method' : m, 'Count': c}).set_index('Method').sort_values('Count', ascending=False)\n",
    "mFreq.to_csv('results/results.csv')\n",
    "mFreq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Count</th>\n",
       "      <th>Finished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pd.read_csv</td>\n",
       "      <td>1422</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pd.DataFrame</td>\n",
       "      <td>886</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df.append</td>\n",
       "      <td>792</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df.mean</td>\n",
       "      <td>783</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df.head</td>\n",
       "      <td>783</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Method  Count  Finished\n",
       "0   pd.read_csv   1422       1.0\n",
       "1  pd.DataFrame    886       1.0\n",
       "2     df.append    792       1.0\n",
       "3       df.mean    783       1.0\n",
       "4       df.head    783       1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impl = pd.read_csv('results/annotResults.csv')\n",
    "impl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate notebook coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = ['pd.groupby', 'pd.merge', 'df.mod', 'df.ge', 'pd.isnull']\n",
    "\n",
    "def scriptCovered(script):\n",
    "    scriptMethods = [l for l in list(script.keys()) if l not in cleaned]\n",
    "    v = []\n",
    "    failed = []\n",
    "    for method in scriptMethods:\n",
    "        res = impl[impl['Method'] == method]['Finished']\n",
    "        if len(res) > 0:\n",
    "            v.append(res.values[0])\n",
    "        if len(res) == 0 or res.values[0] == 0.0:\n",
    "            failed.append(method)\n",
    "    \n",
    "    return v.count(1.0) == len(v), failed\n",
    "\n",
    "\n",
    "def processCoverage(coverageResults):\n",
    "    \"\"\"\n",
    "    Return count of covered and uncovered scripts\n",
    "            and frequency of uncovered methods\n",
    "    \"\"\"\n",
    "    status, uncoveredMethods = [c[0] for c in coverageResults], [c[1] for c in coverageResults]\n",
    "    numCovered = status.count(True)\n",
    "    perCovered = numCovered/len(coverageResults)\n",
    "    \n",
    "    uncoveredFreq = {}\n",
    "    for ums in uncoveredMethods:\n",
    "        for um in ums:\n",
    "            if um not in uncoveredFreq:\n",
    "                uncoveredFreq[um] = 0\n",
    "            uncoveredFreq[um] += 1\n",
    "            \n",
    "    return numCovered, perCovered, uncoveredFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562/1562 [00:03<00:00, 519.05it/s]\n"
     ]
    }
   ],
   "source": [
    "coverageResults = [scriptCovered(m) for m in tqdm(all_methods)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pd.notnull</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df.pivot_table</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.sort_values</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.head</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.isna</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df.unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.append</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pd.describe</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count\n",
       "pd.notnull         14\n",
       "df.pivot_table      3\n",
       "pd.sort_values      1\n",
       "pd.head             1\n",
       "pd.isna             1\n",
       "df.unique           1\n",
       "pd.append           1\n",
       "pd.describe         1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = (pd.DataFrame\n",
    "           .from_dict(data=processCoverage(coverageResults)[2], orient='index')\n",
    "           .rename(columns={0:'count'})\n",
    "           .sort_values('count', ascending=False))\n",
    "\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1475,\n",
       " 0.9443021766965429,\n",
       " {'df.pivot_table': 3,\n",
       "  'df.unique': 1,\n",
       "  'pd.append': 1,\n",
       "  'pd.describe': 1,\n",
       "  'pd.head': 1,\n",
       "  'pd.isna': 1,\n",
       "  'pd.notnull': 14,\n",
       "  'pd.sort_values': 1})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processCoverage(coverageResults)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
